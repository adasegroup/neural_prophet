{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80f12ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5bdb400",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from neuralprophet.forecaster_additional_models import LSTM\n",
    "from neuralprophet import NeuralProphet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc19f480",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "040726df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "  \"update your install command.\", FutureWarning)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from neuralprophet.hyperparameter_tuner import tune_hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffbcb0e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-05-01 00:00:00</td>\n",
       "      <td>27.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-05-01 00:05:00</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-05-01 00:10:00</td>\n",
       "      <td>26.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ds     y\n",
       "0  2017-05-01 00:00:00  27.8\n",
       "1  2017-05-01 00:05:00  27.0\n",
       "2  2017-05-01 00:10:00  26.8"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    !pip install git+https://github.com/ourownstory/neural_prophet.git # may take a while\n",
    "    #!pip install neuralprophet # much faster, but may not have the latest upgrades/bugfixes\n",
    "    data_location = \"https://raw.githubusercontent.com/ourownstory/neural_prophet/master/\"\n",
    "else:\n",
    "    data_location = \"../\"\n",
    "\n",
    "df = pd.read_csv(data_location + \"example_data/yosemite_temps.csv\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "659194bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=18489)\u001b[0m INFO - (NP.config.__post_init__) - Trend reg lambda ignored due to no changepoints.\n",
      "\u001b[2m\u001b[36m(pid=18489)\u001b[0m INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=18489)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=18489)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "\u001b[2m\u001b[36m(pid=18492)\u001b[0m INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=18492)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18489)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18489)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18489)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18492)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "\u001b[2m\u001b[36m(pid=18486)\u001b[0m INFO - (NP.config.__post_init__) - Trend reg lambda ignored due to no changepoints.\n",
      "\u001b[2m\u001b[36m(pid=18486)\u001b[0m INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=18489)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18489)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=18489)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18489)\u001b[0m 0 | season_params | ParameterDict | 6     \n",
      "\u001b[2m\u001b[36m(pid=18489)\u001b[0m 1 | ar_net        | ModuleList    | 18.0 K\n",
      "\u001b[2m\u001b[36m(pid=18489)\u001b[0m 2 | loss_func     | MSELoss       | 0     \n",
      "\u001b[2m\u001b[36m(pid=18489)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18489)\u001b[0m 18.1 K    Trainable params\n",
      "\u001b[2m\u001b[36m(pid=18489)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=18489)\u001b[0m 18.1 K    Total params\n",
      "\u001b[2m\u001b[36m(pid=18489)\u001b[0m 0.072     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=18489)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18489)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18489)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18489)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18489)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18489)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18486)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=18489)\u001b[0m {'growth': 'off', 'n_changepoints': 100, 'changepoints_range': 0.5, 'trend_reg': 10.0, 'yearly_seasonality': False, 'weekly_seasonality': True, 'daily_seasonality': False, 'seasonality_mode': 'additive', 'seasonality_reg': 1.0, 'n_lags': 10, 'd_hidden': 128, 'num_hidden_layers': 2, 'ar_sparsity': 0.1, 'learning_rate': 0.00025794771866301903, 'loss_func': 'MSE', 'normalize': 'standardize'}\n",
      "\u001b[2m\u001b[36m(pid=18492)\u001b[0m {'growth': 'linear', 'n_changepoints': 100, 'changepoints_range': 0.5, 'trend_reg': 0.0, 'yearly_seasonality': False, 'weekly_seasonality': False, 'daily_seasonality': True, 'seasonality_mode': 'multiplicative', 'seasonality_reg': 0.5, 'n_lags': 10, 'd_hidden': 8, 'num_hidden_layers': 2, 'ar_sparsity': 0.3, 'learning_rate': 0.0002926262239414852, 'loss_func': 'MSE', 'normalize': 'auto'}\n",
      "\u001b[2m\u001b[36m(pid=18491)\u001b[0m {'growth': 'off', 'n_changepoints': 100, 'changepoints_range': 0.5, 'trend_reg': 0.0, 'yearly_seasonality': False, 'weekly_seasonality': False, 'daily_seasonality': False, 'seasonality_mode': 'multiplicative', 'seasonality_reg': 0.0, 'n_lags': 10, 'd_hidden': 128, 'num_hidden_layers': 8, 'ar_sparsity': 0.1, 'learning_rate': 0.01177473387772018, 'loss_func': 'Huber', 'normalize': 'standardize'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18492)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18492)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18492)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18492)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18492)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=18492)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18492)\u001b[0m 0 | season_params | ParameterDict | 12    \n",
      "\u001b[2m\u001b[36m(pid=18492)\u001b[0m 1 | ar_net        | ModuleList    | 168   \n",
      "\u001b[2m\u001b[36m(pid=18492)\u001b[0m 2 | loss_func     | MSELoss       | 0     \n",
      "\u001b[2m\u001b[36m(pid=18492)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18492)\u001b[0m 283       Trainable params\n",
      "\u001b[2m\u001b[36m(pid=18492)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=18492)\u001b[0m 283       Total params\n",
      "\u001b[2m\u001b[36m(pid=18492)\u001b[0m 0.001     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=18492)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18492)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18492)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18492)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18492)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18492)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18486)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "\u001b[2m\u001b[36m(pid=18491)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=18491)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18491)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18491)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18491)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18491)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18491)\u001b[0m   | Name      | Type         | Params\n",
      "\u001b[2m\u001b[36m(pid=18491)\u001b[0m -------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18491)\u001b[0m 0 | ar_net    | ModuleList   | 117 K \n",
      "\u001b[2m\u001b[36m(pid=18491)\u001b[0m 1 | loss_func | SmoothL1Loss | 0     \n",
      "\u001b[2m\u001b[36m(pid=18491)\u001b[0m -------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18491)\u001b[0m 117 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=18491)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=18491)\u001b[0m 117 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=18491)\u001b[0m 0.468     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=18488)\u001b[0m INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=18487)\u001b[0m INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=18493)\u001b[0m INFO - (NP.config.__post_init__) - Note: Trend changepoint regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=18493)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=18493)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "\u001b[2m\u001b[36m(pid=18491)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18491)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18491)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18491)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18491)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18491)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18488)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=18487)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=18488)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "\u001b[2m\u001b[36m(pid=18487)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18486)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18486)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18486)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18486)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18486)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=18486)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18486)\u001b[0m 0 | season_params | ParameterDict | 24    \n",
      "\u001b[2m\u001b[36m(pid=18486)\u001b[0m 1 | ar_net        | ModuleList    | 29.9 K\n",
      "\u001b[2m\u001b[36m(pid=18486)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=18486)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18486)\u001b[0m 29.9 K    Trainable params\n",
      "\u001b[2m\u001b[36m(pid=18486)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=18486)\u001b[0m 29.9 K    Total params\n",
      "\u001b[2m\u001b[36m(pid=18486)\u001b[0m 0.120     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=18486)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18486)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18486)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18486)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18486)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18486)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18490)\u001b[0m INFO - (NP.config.__post_init__) - Trend reg lambda ignored due to no changepoints.\n",
      "\u001b[2m\u001b[36m(pid=18490)\u001b[0m INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=18490)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18487)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18487)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18487)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18493)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18493)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18493)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18490)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18488)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18488)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18488)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18493)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18493)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=18493)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18493)\u001b[0m 0 | season_params | ParameterDict | 30    \n",
      "\u001b[2m\u001b[36m(pid=18493)\u001b[0m 1 | ar_net        | ModuleList    | 760   \n",
      "\u001b[2m\u001b[36m(pid=18493)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=18493)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18493)\u001b[0m 803       Trainable params\n",
      "\u001b[2m\u001b[36m(pid=18493)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=18493)\u001b[0m 803       Total params\n",
      "\u001b[2m\u001b[36m(pid=18493)\u001b[0m 0.003     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=18493)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18493)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18493)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18493)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18493)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18493)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18487)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18487)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=18487)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18487)\u001b[0m 0 | season_params | ParameterDict | 24    \n",
      "\u001b[2m\u001b[36m(pid=18487)\u001b[0m 1 | ar_net        | ModuleList    | 249 K \n",
      "\u001b[2m\u001b[36m(pid=18487)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=18487)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18487)\u001b[0m 249 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=18487)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=18487)\u001b[0m 249 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=18487)\u001b[0m 0.997     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=18487)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18487)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18487)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18487)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18487)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18487)\u001b[0m \n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[36m(pid=18488)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18488)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=18488)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18488)\u001b[0m 0 | season_params | ParameterDict | 30    \n",
      "\u001b[2m\u001b[36m(pid=18488)\u001b[0m 1 | ar_net        | ModuleList    | 31.2 K\n",
      "\u001b[2m\u001b[36m(pid=18488)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=18488)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18488)\u001b[0m 31.2 K    Trainable params\n",
      "\u001b[2m\u001b[36m(pid=18488)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=18488)\u001b[0m 31.2 K    Total params\n",
      "\u001b[2m\u001b[36m(pid=18488)\u001b[0m 0.125     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=18488)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18488)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18488)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18488)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18488)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18488)\u001b[0m \n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18490)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18490)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18490)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18490)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18490)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=18490)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18490)\u001b[0m 0 | season_params | ParameterDict | 12    \n",
      "\u001b[2m\u001b[36m(pid=18490)\u001b[0m 1 | ar_net        | ModuleList    | 119 K \n",
      "\u001b[2m\u001b[36m(pid=18490)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=18490)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18490)\u001b[0m 119 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=18490)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=18490)\u001b[0m 119 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=18490)\u001b[0m 0.479     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=18490)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18490)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18490)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18490)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18490)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18490)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=18486)\u001b[0m {'growth': 'off', 'n_changepoints': 5, 'changepoints_range': 0.9, 'trend_reg': 10.0, 'yearly_seasonality': True, 'weekly_seasonality': False, 'daily_seasonality': True, 'seasonality_mode': 'multiplicative', 'seasonality_reg': 0.5, 'n_lags': 10, 'd_hidden': 64, 'num_hidden_layers': 8, 'ar_sparsity': 0.8, 'learning_rate': 0.05709530464716042, 'loss_func': 'Huber', 'normalize': 'soft'}\n",
      "\u001b[2m\u001b[36m(pid=18487)\u001b[0m {'growth': 'off', 'n_changepoints': 5, 'changepoints_range': 0.8, 'trend_reg': 0.0, 'yearly_seasonality': True, 'weekly_seasonality': False, 'daily_seasonality': True, 'seasonality_mode': 'multiplicative', 'seasonality_reg': 1.0, 'n_lags': 10, 'd_hidden': 128, 'num_hidden_layers': 16, 'ar_sparsity': 0.3, 'learning_rate': 0.004413941508220393, 'loss_func': 'Huber', 'normalize': 'soft'}\n",
      "\u001b[2m\u001b[36m(pid=18493)\u001b[0m {'growth': 'linear', 'n_changepoints': 10, 'changepoints_range': 0.5, 'trend_reg': 0.5, 'yearly_seasonality': True, 'weekly_seasonality': True, 'daily_seasonality': True, 'seasonality_mode': 'multiplicative', 'seasonality_reg': 0.0, 'n_lags': 30, 'd_hidden': 8, 'num_hidden_layers': 8, 'ar_sparsity': 0.3, 'learning_rate': 0.01363167399344815, 'loss_func': 'Huber', 'normalize': 'off'}\n",
      "\u001b[2m\u001b[36m(pid=18488)\u001b[0m {'growth': 'off', 'n_changepoints': 100, 'changepoints_range': 0.9, 'trend_reg': 0.0, 'yearly_seasonality': True, 'weekly_seasonality': True, 'daily_seasonality': True, 'seasonality_mode': 'multiplicative', 'seasonality_reg': 0.5, 'n_lags': 30, 'd_hidden': 64, 'num_hidden_layers': 8, 'ar_sparsity': 0.1, 'learning_rate': 0.0016671543773598275, 'loss_func': 'Huber', 'normalize': 'auto'}\n",
      "\u001b[2m\u001b[36m(pid=18490)\u001b[0m {'growth': 'off', 'n_changepoints': 5, 'changepoints_range': 0.8, 'trend_reg': 0.5, 'yearly_seasonality': True, 'weekly_seasonality': False, 'daily_seasonality': False, 'seasonality_mode': 'additive', 'seasonality_reg': 1.0, 'n_lags': 30, 'd_hidden': 128, 'num_hidden_layers': 8, 'ar_sparsity': 0.3, 'learning_rate': 0.061274546662678064, 'loss_func': 'Huber', 'normalize': 'off'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=18532)\u001b[0m INFO - (NP.config.__post_init__) - Note: Trend changepoint regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=18532)\u001b[0m INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=18532)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=18532)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18532)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18532)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18532)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18532)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18532)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=18532)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18532)\u001b[0m 0 | season_params | ParameterDict | 6     \n",
      "\u001b[2m\u001b[36m(pid=18532)\u001b[0m 1 | ar_net        | ModuleList    | 10.7 K\n",
      "\u001b[2m\u001b[36m(pid=18532)\u001b[0m 2 | loss_func     | MSELoss       | 0     \n",
      "\u001b[2m\u001b[36m(pid=18532)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18532)\u001b[0m 10.8 K    Trainable params\n",
      "\u001b[2m\u001b[36m(pid=18532)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=18532)\u001b[0m 10.8 K    Total params\n",
      "\u001b[2m\u001b[36m(pid=18532)\u001b[0m 0.043     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=18532)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18532)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18532)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18532)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18532)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18532)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=18532)\u001b[0m {'growth': 'linear', 'n_changepoints': 100, 'changepoints_range': 0.5, 'trend_reg': 1.0, 'yearly_seasonality': False, 'weekly_seasonality': True, 'daily_seasonality': False, 'seasonality_mode': 'additive', 'seasonality_reg': 0.5, 'n_lags': 100, 'd_hidden': 64, 'num_hidden_layers': 2, 'ar_sparsity': 0.1, 'learning_rate': 0.002321224873593233, 'loss_func': 'MSE', 'normalize': 'soft'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=18536)\u001b[0m INFO - (NP.config.__post_init__) - Note: Trend changepoint regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=18536)\u001b[0m INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=18536)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=18536)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18536)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18536)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18536)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18536)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18536)\u001b[0m   | Name      | Type       | Params\n",
      "\u001b[2m\u001b[36m(pid=18536)\u001b[0m -----------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18536)\u001b[0m 0 | ar_net    | ModuleList | 6.2 K \n",
      "\u001b[2m\u001b[36m(pid=18536)\u001b[0m 1 | loss_func | MSELoss    | 0     \n",
      "\u001b[2m\u001b[36m(pid=18536)\u001b[0m -----------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18536)\u001b[0m 6.2 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=18536)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=18536)\u001b[0m 6.2 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=18536)\u001b[0m 0.025     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=18536)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18536)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18536)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18536)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18536)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18536)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=18536)\u001b[0m {'growth': 'linear', 'n_changepoints': 10, 'changepoints_range': 0.9, 'trend_reg': 1.0, 'yearly_seasonality': False, 'weekly_seasonality': False, 'daily_seasonality': False, 'seasonality_mode': 'additive', 'seasonality_reg': 10.0, 'n_lags': 30, 'd_hidden': 64, 'num_hidden_layers': 2, 'ar_sparsity': 0.1, 'learning_rate': 0.0012780104541181485, 'loss_func': 'MSE', 'normalize': 'auto'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=18539)\u001b[0m INFO - (NP.config.__post_init__) - Note: Trend changepoint regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=18539)\u001b[0m INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=18539)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=18539)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18539)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18539)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18539)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18539)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18539)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=18539)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18539)\u001b[0m 0 | season_params | ParameterDict | 12    \n",
      "\u001b[2m\u001b[36m(pid=18539)\u001b[0m 1 | ar_net        | ModuleList    | 119 K \n",
      "\u001b[2m\u001b[36m(pid=18539)\u001b[0m 2 | loss_func     | MSELoss       | 0     \n",
      "\u001b[2m\u001b[36m(pid=18539)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18539)\u001b[0m 119 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=18539)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=18539)\u001b[0m 119 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=18539)\u001b[0m 0.479     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=18539)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18539)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18539)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18539)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18539)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18539)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=18539)\u001b[0m {'growth': 'linear', 'n_changepoints': 5, 'changepoints_range': 0.9, 'trend_reg': 1.0, 'yearly_seasonality': False, 'weekly_seasonality': False, 'daily_seasonality': True, 'seasonality_mode': 'additive', 'seasonality_reg': 10.0, 'n_lags': 30, 'd_hidden': 128, 'num_hidden_layers': 8, 'ar_sparsity': 0.8, 'learning_rate': 0.00038336638659065527, 'loss_func': 'MSE', 'normalize': 'minmax'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=18545)\u001b[0m INFO - (NP.config.__post_init__) - Note: Trend changepoint regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=18545)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=18545)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18545)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18545)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18545)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[36m(pid=18545)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18545)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=18545)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18545)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=18545)\u001b[0m 1 | ar_net        | ModuleList    | 1.3 K \n",
      "\u001b[2m\u001b[36m(pid=18545)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=18545)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18545)\u001b[0m 1.4 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=18545)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=18545)\u001b[0m 1.4 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=18545)\u001b[0m 0.005     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=18545)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18545)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18545)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18545)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18545)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18545)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=18545)\u001b[0m {'growth': 'linear', 'n_changepoints': 10, 'changepoints_range': 0.9, 'trend_reg': 1.0, 'yearly_seasonality': False, 'weekly_seasonality': True, 'daily_seasonality': True, 'seasonality_mode': 'additive', 'seasonality_reg': 0.0, 'n_lags': 30, 'd_hidden': 8, 'num_hidden_layers': 16, 'ar_sparsity': 0.8, 'learning_rate': 0.007816968632308399, 'loss_func': 'Huber', 'normalize': 'minmax'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=18554)\u001b[0m INFO - (NP.config.__post_init__) - Trend reg lambda ignored due to no changepoints.\n",
      "\u001b[2m\u001b[36m(pid=18554)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=18554)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18554)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18554)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18554)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18554)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18554)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=18554)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18554)\u001b[0m 0 | season_params | ParameterDict | 6     \n",
      "\u001b[2m\u001b[36m(pid=18554)\u001b[0m 1 | ar_net        | ModuleList    | 1.3 K \n",
      "\u001b[2m\u001b[36m(pid=18554)\u001b[0m 2 | loss_func     | MSELoss       | 0     \n",
      "\u001b[2m\u001b[36m(pid=18554)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18554)\u001b[0m 1.3 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=18554)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=18554)\u001b[0m 1.3 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=18554)\u001b[0m 0.005     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=18554)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18554)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18554)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18554)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18554)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18554)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=18554)\u001b[0m {'growth': 'off', 'n_changepoints': 10, 'changepoints_range': 0.5, 'trend_reg': 1.0, 'yearly_seasonality': False, 'weekly_seasonality': True, 'daily_seasonality': False, 'seasonality_mode': 'additive', 'seasonality_reg': 0.0, 'n_lags': 100, 'd_hidden': 8, 'num_hidden_layers': 8, 'ar_sparsity': 0.3, 'learning_rate': 0.0028338671889591004, 'loss_func': 'MSE', 'normalize': 'soft'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=18557)\u001b[0m INFO - (NP.config.__post_init__) - Trend reg lambda ignored due to no changepoints.\n",
      "\u001b[2m\u001b[36m(pid=18557)\u001b[0m INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=18557)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=18557)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=18557)\u001b[0m {'growth': 'off', 'n_changepoints': 100, 'changepoints_range': 0.5, 'trend_reg': 1.0, 'yearly_seasonality': True, 'weekly_seasonality': False, 'daily_seasonality': True, 'seasonality_mode': 'multiplicative', 'seasonality_reg': 1.0, 'n_lags': 100, 'd_hidden': 64, 'num_hidden_layers': 8, 'ar_sparsity': 0.8, 'learning_rate': 0.0042786934665185235, 'loss_func': 'MSE', 'normalize': 'standardize'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18557)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18557)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18557)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18557)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18557)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=18557)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18557)\u001b[0m 0 | season_params | ParameterDict | 24    \n",
      "\u001b[2m\u001b[36m(pid=18557)\u001b[0m 1 | ar_net        | ModuleList    | 35.6 K\n",
      "\u001b[2m\u001b[36m(pid=18557)\u001b[0m 2 | loss_func     | MSELoss       | 0     \n",
      "\u001b[2m\u001b[36m(pid=18557)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18557)\u001b[0m 35.7 K    Trainable params\n",
      "\u001b[2m\u001b[36m(pid=18557)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=18557)\u001b[0m 35.7 K    Total params\n",
      "\u001b[2m\u001b[36m(pid=18557)\u001b[0m 0.143     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=18557)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18557)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18557)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18557)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18557)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18557)\u001b[0m \n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=18560)\u001b[0m INFO - (NP.config.__post_init__) - Trend reg lambda ignored due to no changepoints.\n",
      "\u001b[2m\u001b[36m(pid=18560)\u001b[0m INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=18560)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=18560)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18560)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18560)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18560)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[36m(pid=18560)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18560)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=18560)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18560)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=18560)\u001b[0m 1 | ar_net        | ModuleList    | 63.2 K\n",
      "\u001b[2m\u001b[36m(pid=18560)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=18560)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18560)\u001b[0m 63.2 K    Trainable params\n",
      "\u001b[2m\u001b[36m(pid=18560)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=18560)\u001b[0m 63.2 K    Total params\n",
      "\u001b[2m\u001b[36m(pid=18560)\u001b[0m 0.253     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=18560)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18560)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18560)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18560)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18560)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18560)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=18560)\u001b[0m {'growth': 'off', 'n_changepoints': 5, 'changepoints_range': 0.9, 'trend_reg': 10.0, 'yearly_seasonality': True, 'weekly_seasonality': True, 'daily_seasonality': False, 'seasonality_mode': 'multiplicative', 'seasonality_reg': 1.0, 'n_lags': 10, 'd_hidden': 64, 'num_hidden_layers': 16, 'ar_sparsity': 0.1, 'learning_rate': 0.004509112115464473, 'loss_func': 'Huber', 'normalize': 'minmax'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=18563)\u001b[0m INFO - (NP.config.__post_init__) - Trend reg lambda ignored due to no changepoints.\n",
      "\u001b[2m\u001b[36m(pid=18566)\u001b[0m INFO - (NP.config.__post_init__) - Trend reg lambda ignored due to no changepoints.\n",
      "\u001b[2m\u001b[36m(pid=18563)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=18563)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "\u001b[2m\u001b[36m(pid=18566)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=18566)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18563)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18563)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18563)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18566)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18566)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18566)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18566)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18566)\u001b[0m   | Name      | Type       | Params\n",
      "\u001b[2m\u001b[36m(pid=18566)\u001b[0m -----------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18566)\u001b[0m 0 | ar_net    | ModuleList | 29.9 K\n",
      "\u001b[2m\u001b[36m(pid=18566)\u001b[0m 1 | loss_func | MSELoss    | 0     \n",
      "\u001b[2m\u001b[36m(pid=18566)\u001b[0m -----------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18566)\u001b[0m 29.9 K    Trainable params\n",
      "\u001b[2m\u001b[36m(pid=18566)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=18566)\u001b[0m 29.9 K    Total params\n",
      "\u001b[2m\u001b[36m(pid=18566)\u001b[0m 0.120     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=18566)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18566)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18566)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18566)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18566)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18566)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18563)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18563)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=18563)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18563)\u001b[0m 0 | season_params | ParameterDict | 30    \n",
      "\u001b[2m\u001b[36m(pid=18563)\u001b[0m 1 | ar_net        | ModuleList    | 31.2 K\n",
      "\u001b[2m\u001b[36m(pid=18563)\u001b[0m 2 | loss_func     | MSELoss       | 0     \n",
      "\u001b[2m\u001b[36m(pid=18563)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18563)\u001b[0m 31.2 K    Trainable params\n",
      "\u001b[2m\u001b[36m(pid=18563)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=18563)\u001b[0m 31.2 K    Total params\n",
      "\u001b[2m\u001b[36m(pid=18563)\u001b[0m 0.125     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=18563)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18563)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18563)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18563)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18563)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18563)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=18563)\u001b[0m {'growth': 'off', 'n_changepoints': 10, 'changepoints_range': 0.8, 'trend_reg': 0.5, 'yearly_seasonality': True, 'weekly_seasonality': True, 'daily_seasonality': True, 'seasonality_mode': 'additive', 'seasonality_reg': 0.0, 'n_lags': 30, 'd_hidden': 64, 'num_hidden_layers': 8, 'ar_sparsity': 0.1, 'learning_rate': 0.0006543945360003929, 'loss_func': 'MSE', 'normalize': 'off'}\n",
      "\u001b[2m\u001b[36m(pid=18566)\u001b[0m {'growth': 'off', 'n_changepoints': 10, 'changepoints_range': 0.9, 'trend_reg': 0.5, 'yearly_seasonality': False, 'weekly_seasonality': False, 'daily_seasonality': False, 'seasonality_mode': 'multiplicative', 'seasonality_reg': 0.0, 'n_lags': 10, 'd_hidden': 64, 'num_hidden_layers': 8, 'ar_sparsity': 0.1, 'learning_rate': 0.022149611256811454, 'loss_func': 'MSE', 'normalize': 'minmax'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=18579)\u001b[0m INFO - (NP.config.__post_init__) - Trend reg lambda ignored due to no changepoints.\n",
      "\u001b[2m\u001b[36m(pid=18579)\u001b[0m INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=18579)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=18579)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18579)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18579)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18579)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18579)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18579)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=18579)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18579)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=18579)\u001b[0m 1 | ar_net        | ModuleList    | 10.7 K\n",
      "\u001b[2m\u001b[36m(pid=18579)\u001b[0m 2 | loss_func     | MSELoss       | 0     \n",
      "\u001b[2m\u001b[36m(pid=18579)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18579)\u001b[0m 10.7 K    Trainable params\n",
      "\u001b[2m\u001b[36m(pid=18579)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=18579)\u001b[0m 10.7 K    Total params\n",
      "\u001b[2m\u001b[36m(pid=18579)\u001b[0m 0.043     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=18579)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18579)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18579)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18579)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18579)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18579)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=18579)\u001b[0m {'growth': 'off', 'n_changepoints': 100, 'changepoints_range': 0.8, 'trend_reg': 10.0, 'yearly_seasonality': True, 'weekly_seasonality': True, 'daily_seasonality': False, 'seasonality_mode': 'multiplicative', 'seasonality_reg': 1.0, 'n_lags': 100, 'd_hidden': 64, 'num_hidden_layers': 2, 'ar_sparsity': 0.3, 'learning_rate': 0.0009196093298665312, 'loss_func': 'MSE', 'normalize': 'standardize'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=18586)\u001b[0m INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=18586)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=18586)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18586)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18586)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18586)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18586)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18586)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=18586)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18586)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=18586)\u001b[0m 1 | ar_net        | ModuleList    | 600   \n",
      "\u001b[2m\u001b[36m(pid=18586)\u001b[0m 2 | loss_func     | MSELoss       | 0     \n",
      "\u001b[2m\u001b[36m(pid=18586)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18586)\u001b[0m 619       Trainable params\n",
      "\u001b[2m\u001b[36m(pid=18586)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=18586)\u001b[0m 619       Total params\n",
      "\u001b[2m\u001b[36m(pid=18586)\u001b[0m 0.002     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=18586)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18586)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18586)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18586)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18586)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18586)\u001b[0m \n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=18586)\u001b[0m {'growth': 'off', 'n_changepoints': 5, 'changepoints_range': 0.9, 'trend_reg': 0.0, 'yearly_seasonality': True, 'weekly_seasonality': True, 'daily_seasonality': False, 'seasonality_mode': 'multiplicative', 'seasonality_reg': 1.0, 'n_lags': 10, 'd_hidden': 8, 'num_hidden_layers': 8, 'ar_sparsity': 0.3, 'learning_rate': 0.009121166158922013, 'loss_func': 'MSE', 'normalize': 'auto'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=18589)\u001b[0m INFO - (NP.config.__post_init__) - Note: Trend changepoint regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=18589)\u001b[0m INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=18589)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=18589)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18589)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18589)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18589)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18589)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18589)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=18589)\u001b[0m ------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=18589)\u001b[0m {'growth': 'linear', 'n_changepoints': 5, 'changepoints_range': 0.5, 'trend_reg': 10.0, 'yearly_seasonality': True, 'weekly_seasonality': True, 'daily_seasonality': True, 'seasonality_mode': 'multiplicative', 'seasonality_reg': 10.0, 'n_lags': 100, 'd_hidden': 128, 'num_hidden_layers': 8, 'ar_sparsity': 0.3, 'learning_rate': 0.00176538236998349, 'loss_func': 'Huber', 'normalize': 'auto'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=18589)\u001b[0m 0 | season_params | ParameterDict | 30    \n",
      "\u001b[2m\u001b[36m(pid=18589)\u001b[0m 1 | ar_net        | ModuleList    | 128 K \n",
      "\u001b[2m\u001b[36m(pid=18589)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=18589)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18589)\u001b[0m 128 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=18589)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=18589)\u001b[0m 128 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=18589)\u001b[0m 0.515     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=18589)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18589)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18589)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18589)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18589)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18589)\u001b[0m \n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=18592)\u001b[0m INFO - (NP.config.__post_init__) - Note: Trend changepoint regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=18592)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=18592)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18592)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18592)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18592)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[36m(pid=18592)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18592)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=18592)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18592)\u001b[0m 0 | season_params | ParameterDict | 12    \n",
      "\u001b[2m\u001b[36m(pid=18592)\u001b[0m 1 | ar_net        | ModuleList    | 249 K \n",
      "\u001b[2m\u001b[36m(pid=18592)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=18592)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18592)\u001b[0m 249 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=18592)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=18592)\u001b[0m 249 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=18592)\u001b[0m 0.997     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=18592)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18592)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18592)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18592)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18592)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18592)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=18592)\u001b[0m {'growth': 'linear', 'n_changepoints': 100, 'changepoints_range': 0.9, 'trend_reg': 0.5, 'yearly_seasonality': False, 'weekly_seasonality': False, 'daily_seasonality': True, 'seasonality_mode': 'multiplicative', 'seasonality_reg': 0.0, 'n_lags': 10, 'd_hidden': 128, 'num_hidden_layers': 16, 'ar_sparsity': 0.3, 'learning_rate': 0.0002219720625190945, 'loss_func': 'Huber', 'normalize': 'soft'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=18595)\u001b[0m INFO - (NP.config.__post_init__) - Trend reg lambda ignored due to no changepoints.\n",
      "\u001b[2m\u001b[36m(pid=18595)\u001b[0m INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=18595)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=18595)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18595)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18595)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18595)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18595)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18595)\u001b[0m   | Name      | Type         | Params\n",
      "\u001b[2m\u001b[36m(pid=18595)\u001b[0m -------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18595)\u001b[0m 0 | ar_net    | ModuleList   | 760   \n",
      "\u001b[2m\u001b[36m(pid=18595)\u001b[0m 1 | loss_func | SmoothL1Loss | 0     \n",
      "\u001b[2m\u001b[36m(pid=18595)\u001b[0m -------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18595)\u001b[0m 761       Trainable params\n",
      "\u001b[2m\u001b[36m(pid=18595)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=18595)\u001b[0m 761       Total params\n",
      "\u001b[2m\u001b[36m(pid=18595)\u001b[0m 0.003     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=18595)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18595)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18595)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18595)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18595)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18595)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=18595)\u001b[0m {'growth': 'off', 'n_changepoints': 100, 'changepoints_range': 0.9, 'trend_reg': 1.0, 'yearly_seasonality': False, 'weekly_seasonality': False, 'daily_seasonality': False, 'seasonality_mode': 'multiplicative', 'seasonality_reg': 0.5, 'n_lags': 30, 'd_hidden': 8, 'num_hidden_layers': 8, 'ar_sparsity': 0.1, 'learning_rate': 0.016032870001225212, 'loss_func': 'Huber', 'normalize': 'minmax'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=18598)\u001b[0m INFO - (NP.config.__post_init__) - Note: Trend changepoint regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=18598)\u001b[0m INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=18598)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=18598)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18598)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18598)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18598)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18598)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18598)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=18598)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18598)\u001b[0m 0 | season_params | ParameterDict | 24    \n",
      "\u001b[2m\u001b[36m(pid=18598)\u001b[0m 1 | ar_net        | ModuleList    | 117 K \n",
      "\u001b[2m\u001b[36m(pid=18598)\u001b[0m 2 | loss_func     | MSELoss       | 0     \n",
      "\u001b[2m\u001b[36m(pid=18598)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18598)\u001b[0m 117 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=18598)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=18598)\u001b[0m 117 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=18598)\u001b[0m 0.469     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=18598)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18598)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18598)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18598)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18598)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18598)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=18598)\u001b[0m {'growth': 'linear', 'n_changepoints': 10, 'changepoints_range': 0.8, 'trend_reg': 1.0, 'yearly_seasonality': True, 'weekly_seasonality': False, 'daily_seasonality': True, 'seasonality_mode': 'additive', 'seasonality_reg': 0.5, 'n_lags': 10, 'd_hidden': 128, 'num_hidden_layers': 8, 'ar_sparsity': 0.1, 'learning_rate': 0.006094326298450639, 'loss_func': 'MSE', 'normalize': 'auto'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=18603)\u001b[0m INFO - (NP.config.__post_init__) - Trend reg lambda ignored due to no changepoints.\n",
      "\u001b[2m\u001b[36m(pid=18603)\u001b[0m INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=18603)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=18603)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18603)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18603)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18603)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18603)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18603)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=18603)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18603)\u001b[0m 0 | season_params | ParameterDict | 6     \n",
      "\u001b[2m\u001b[36m(pid=18603)\u001b[0m 1 | ar_net        | ModuleList    | 251 K \n",
      "\u001b[2m\u001b[36m(pid=18603)\u001b[0m 2 | loss_func     | MSELoss       | 0     \n",
      "\u001b[2m\u001b[36m(pid=18603)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18603)\u001b[0m 251 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=18603)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=18603)\u001b[0m 251 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=18603)\u001b[0m 1.007     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=18603)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18603)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18603)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18603)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18603)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18603)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=18603)\u001b[0m {'growth': 'off', 'n_changepoints': 10, 'changepoints_range': 0.8, 'trend_reg': 1.0, 'yearly_seasonality': False, 'weekly_seasonality': True, 'daily_seasonality': False, 'seasonality_mode': 'additive', 'seasonality_reg': 1.0, 'n_lags': 30, 'd_hidden': 128, 'num_hidden_layers': 16, 'ar_sparsity': 0.3, 'learning_rate': 0.05514465316195616, 'loss_func': 'MSE', 'normalize': 'minmax'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=18607)\u001b[0m INFO - (NP.config.__post_init__) - Note: Trend changepoint regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=18607)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=18607)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18607)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18607)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18607)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18607)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18607)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=18607)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18607)\u001b[0m 0 | season_params | ParameterDict | 24    \n",
      "\u001b[2m\u001b[36m(pid=18607)\u001b[0m 1 | ar_net        | ModuleList    | 64.4 K\n",
      "\u001b[2m\u001b[36m(pid=18607)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=18607)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18607)\u001b[0m 64.5 K    Trainable params\n",
      "\u001b[2m\u001b[36m(pid=18607)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=18607)\u001b[0m 64.5 K    Total params\n",
      "\u001b[2m\u001b[36m(pid=18607)\u001b[0m 0.258     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=18607)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18607)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18607)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18607)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18607)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18607)\u001b[0m \n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=18607)\u001b[0m {'growth': 'linear', 'n_changepoints': 5, 'changepoints_range': 0.5, 'trend_reg': 1.0, 'yearly_seasonality': True, 'weekly_seasonality': False, 'daily_seasonality': True, 'seasonality_mode': 'multiplicative', 'seasonality_reg': 0.0, 'n_lags': 30, 'd_hidden': 64, 'num_hidden_layers': 16, 'ar_sparsity': 0.3, 'learning_rate': 0.0039365203396605035, 'loss_func': 'Huber', 'normalize': 'soft'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=18613)\u001b[0m INFO - (NP.config.__post_init__) - Note: Trend changepoint regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=18613)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=18613)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18613)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18613)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18613)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[36m(pid=18613)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18613)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=18613)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18613)\u001b[0m 0 | season_params | ParameterDict | 24    \n",
      "\u001b[2m\u001b[36m(pid=18613)\u001b[0m 1 | ar_net        | ModuleList    | 251 K \n",
      "\u001b[2m\u001b[36m(pid=18613)\u001b[0m 2 | loss_func     | MSELoss       | 0     \n",
      "\u001b[2m\u001b[36m(pid=18613)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18613)\u001b[0m 251 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=18613)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=18613)\u001b[0m 251 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=18613)\u001b[0m 1.007     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=18613)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18613)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18613)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18613)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18613)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18613)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=18613)\u001b[0m {'growth': 'linear', 'n_changepoints': 5, 'changepoints_range': 0.9, 'trend_reg': 1.0, 'yearly_seasonality': True, 'weekly_seasonality': False, 'daily_seasonality': True, 'seasonality_mode': 'additive', 'seasonality_reg': 0.0, 'n_lags': 30, 'd_hidden': 128, 'num_hidden_layers': 16, 'ar_sparsity': 0.3, 'learning_rate': 0.0731075357109261, 'loss_func': 'MSE', 'normalize': 'off'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=18616)\u001b[0m INFO - (NP.config.__post_init__) - Note: Trend changepoint regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=18616)\u001b[0m INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=18616)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=18616)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18616)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18616)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18616)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18616)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18616)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=18616)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18616)\u001b[0m 0 | season_params | ParameterDict | 12    \n",
      "\u001b[2m\u001b[36m(pid=18616)\u001b[0m 1 | ar_net        | ModuleList    | 260 K \n",
      "\u001b[2m\u001b[36m(pid=18616)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=18616)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18616)\u001b[0m 260 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=18616)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=18616)\u001b[0m 260 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=18616)\u001b[0m 1.043     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=18616)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18616)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18616)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18616)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18616)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18616)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=18616)\u001b[0m {'growth': 'linear', 'n_changepoints': 100, 'changepoints_range': 0.9, 'trend_reg': 10.0, 'yearly_seasonality': True, 'weekly_seasonality': False, 'daily_seasonality': False, 'seasonality_mode': 'multiplicative', 'seasonality_reg': 10.0, 'n_lags': 100, 'd_hidden': 128, 'num_hidden_layers': 16, 'ar_sparsity': 0.1, 'learning_rate': 0.000971807400452209, 'loss_func': 'Huber', 'normalize': 'off'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[36m(pid=18619)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=18619)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18619)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18619)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18619)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18619)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18619)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=18619)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18619)\u001b[0m 0 | season_params | ParameterDict | 24    \n",
      "\u001b[2m\u001b[36m(pid=18619)\u001b[0m 1 | ar_net        | ModuleList    | 29.9 K\n",
      "\u001b[2m\u001b[36m(pid=18619)\u001b[0m 2 | loss_func     | MSELoss       | 0     \n",
      "\u001b[2m\u001b[36m(pid=18619)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18619)\u001b[0m 29.9 K    Trainable params\n",
      "\u001b[2m\u001b[36m(pid=18619)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=18619)\u001b[0m 29.9 K    Total params\n",
      "\u001b[2m\u001b[36m(pid=18619)\u001b[0m 0.120     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=18619)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18619)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18619)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18619)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18619)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18619)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=18619)\u001b[0m {'growth': 'off', 'n_changepoints': 10, 'changepoints_range': 0.9, 'trend_reg': 0.0, 'yearly_seasonality': True, 'weekly_seasonality': False, 'daily_seasonality': True, 'seasonality_mode': 'multiplicative', 'seasonality_reg': 0.0, 'n_lags': 10, 'd_hidden': 64, 'num_hidden_layers': 8, 'ar_sparsity': 0.1, 'learning_rate': 0.00020215225434823509, 'loss_func': 'MSE', 'normalize': 'standardize'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=18623)\u001b[0m INFO - (NP.config.__post_init__) - Trend reg lambda ignored due to no changepoints.\n",
      "\u001b[2m\u001b[36m(pid=18623)\u001b[0m INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=18623)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=18623)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18623)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18623)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18623)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18623)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18623)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=18623)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18623)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=18623)\u001b[0m 1 | ar_net        | ModuleList    | 29.9 K\n",
      "\u001b[2m\u001b[36m(pid=18623)\u001b[0m 2 | loss_func     | MSELoss       | 0     \n",
      "\u001b[2m\u001b[36m(pid=18623)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18623)\u001b[0m 29.9 K    Trainable params\n",
      "\u001b[2m\u001b[36m(pid=18623)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=18623)\u001b[0m 29.9 K    Total params\n",
      "\u001b[2m\u001b[36m(pid=18623)\u001b[0m 0.120     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=18623)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18623)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18623)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18623)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18623)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18623)\u001b[0m \n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=18623)\u001b[0m {'growth': 'off', 'n_changepoints': 100, 'changepoints_range': 0.5, 'trend_reg': 1.0, 'yearly_seasonality': False, 'weekly_seasonality': True, 'daily_seasonality': True, 'seasonality_mode': 'additive', 'seasonality_reg': 0.5, 'n_lags': 10, 'd_hidden': 64, 'num_hidden_layers': 8, 'ar_sparsity': 0.1, 'learning_rate': 0.09152508030082965, 'loss_func': 'MSE', 'normalize': 'soft'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=18626)\u001b[0m INFO - (NP.config.__post_init__) - Note: Trend changepoint regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=18626)\u001b[0m INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=18626)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=18626)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18626)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18626)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18626)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18626)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18626)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=18626)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18626)\u001b[0m 0 | season_params | ParameterDict | 12    \n",
      "\u001b[2m\u001b[36m(pid=18626)\u001b[0m 1 | ar_net        | ModuleList    | 29.9 K\n",
      "\u001b[2m\u001b[36m(pid=18626)\u001b[0m 2 | loss_func     | MSELoss       | 0     \n",
      "\u001b[2m\u001b[36m(pid=18626)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18626)\u001b[0m 29.9 K    Trainable params\n",
      "\u001b[2m\u001b[36m(pid=18626)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=18626)\u001b[0m 29.9 K    Total params\n",
      "\u001b[2m\u001b[36m(pid=18626)\u001b[0m 0.120     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=18626)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18626)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18626)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18626)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18626)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18626)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=18626)\u001b[0m {'growth': 'linear', 'n_changepoints': 5, 'changepoints_range': 0.8, 'trend_reg': 1.0, 'yearly_seasonality': False, 'weekly_seasonality': False, 'daily_seasonality': True, 'seasonality_mode': 'multiplicative', 'seasonality_reg': 10.0, 'n_lags': 10, 'd_hidden': 64, 'num_hidden_layers': 8, 'ar_sparsity': 0.1, 'learning_rate': 0.05373855057442426, 'loss_func': 'MSE', 'normalize': 'soft'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=18630)\u001b[0m INFO - (NP.config.__post_init__) - Note: Trend changepoint regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=18630)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=18630)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18630)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18630)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18630)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18630)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18630)\u001b[0m   | Name      | Type       | Params\n",
      "\u001b[2m\u001b[36m(pid=18630)\u001b[0m -----------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18630)\u001b[0m 0 | ar_net    | ModuleList | 29.6 K\n",
      "\u001b[2m\u001b[36m(pid=18630)\u001b[0m 1 | loss_func | MSELoss    | 0     \n",
      "\u001b[2m\u001b[36m(pid=18630)\u001b[0m -----------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18630)\u001b[0m 29.6 K    Trainable params\n",
      "\u001b[2m\u001b[36m(pid=18630)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=18630)\u001b[0m 29.6 K    Total params\n",
      "\u001b[2m\u001b[36m(pid=18630)\u001b[0m 0.118     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=18630)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18630)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18630)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18630)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18630)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18630)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=18630)\u001b[0m {'growth': 'linear', 'n_changepoints': 10, 'changepoints_range': 0.5, 'trend_reg': 1.0, 'yearly_seasonality': False, 'weekly_seasonality': False, 'daily_seasonality': False, 'seasonality_mode': 'additive', 'seasonality_reg': 0.0, 'n_lags': 100, 'd_hidden': 128, 'num_hidden_layers': 2, 'ar_sparsity': 0.1, 'learning_rate': 0.02031257152084333, 'loss_func': 'MSE', 'normalize': 'auto'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=18649)\u001b[0m INFO - (NP.config.__post_init__) - Note: Trend changepoint regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=18649)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=18649)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18649)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18649)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18649)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[36m(pid=18649)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18649)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=18649)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18649)\u001b[0m 0 | season_params | ParameterDict | 24    \n",
      "\u001b[2m\u001b[36m(pid=18649)\u001b[0m 1 | ar_net        | ModuleList    | 249 K \n",
      "\u001b[2m\u001b[36m(pid=18649)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=18649)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18649)\u001b[0m 249 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=18649)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=18649)\u001b[0m 249 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=18649)\u001b[0m 0.997     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=18649)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18649)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18649)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18649)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18649)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18649)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=18649)\u001b[0m {'growth': 'linear', 'n_changepoints': 5, 'changepoints_range': 0.5, 'trend_reg': 0.5, 'yearly_seasonality': True, 'weekly_seasonality': False, 'daily_seasonality': True, 'seasonality_mode': 'additive', 'seasonality_reg': 0.0, 'n_lags': 10, 'd_hidden': 128, 'num_hidden_layers': 16, 'ar_sparsity': 0.8, 'learning_rate': 0.027112521982611375, 'loss_func': 'Huber', 'normalize': 'standardize'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=18656)\u001b[0m INFO - (NP.config.__post_init__) - Note: Trend changepoint regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=18656)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=18656)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18656)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18656)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18656)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18656)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18656)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=18656)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18656)\u001b[0m 0 | season_params | ParameterDict | 24    \n",
      "\u001b[2m\u001b[36m(pid=18656)\u001b[0m 1 | ar_net        | ModuleList    | 117 K \n",
      "\u001b[2m\u001b[36m(pid=18656)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=18656)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18656)\u001b[0m 117 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=18656)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=18656)\u001b[0m 117 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=18656)\u001b[0m 0.469     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=18656)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18656)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18656)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18656)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18656)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18656)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=18656)\u001b[0m {'growth': 'linear', 'n_changepoints': 100, 'changepoints_range': 0.5, 'trend_reg': 1.0, 'yearly_seasonality': True, 'weekly_seasonality': False, 'daily_seasonality': True, 'seasonality_mode': 'additive', 'seasonality_reg': 0.0, 'n_lags': 10, 'd_hidden': 128, 'num_hidden_layers': 8, 'ar_sparsity': 0.3, 'learning_rate': 0.0036686370732896987, 'loss_func': 'Huber', 'normalize': 'standardize'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "2021-05-10 12:48:11,878\tWARNING util.py:162 -- The `start_trial` operation took 1.069 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=18665)\u001b[0m INFO - (NP.config.__post_init__) - Trend reg lambda ignored due to no changepoints.\n",
      "\u001b[2m\u001b[36m(pid=18665)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=18665)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18665)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18665)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18665)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18665)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18665)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=18665)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18665)\u001b[0m 0 | season_params | ParameterDict | 12    \n",
      "\u001b[2m\u001b[36m(pid=18665)\u001b[0m 1 | ar_net        | ModuleList    | 64.4 K\n",
      "\u001b[2m\u001b[36m(pid=18665)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=18665)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18665)\u001b[0m 64.5 K    Trainable params\n",
      "\u001b[2m\u001b[36m(pid=18665)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=18665)\u001b[0m 64.5 K    Total params\n",
      "\u001b[2m\u001b[36m(pid=18665)\u001b[0m 0.258     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=18665)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18665)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18665)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18665)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18665)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18665)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=18665)\u001b[0m {'growth': 'off', 'n_changepoints': 100, 'changepoints_range': 0.9, 'trend_reg': 1.0, 'yearly_seasonality': True, 'weekly_seasonality': False, 'daily_seasonality': False, 'seasonality_mode': 'additive', 'seasonality_reg': 0.0, 'n_lags': 30, 'd_hidden': 64, 'num_hidden_layers': 16, 'ar_sparsity': 0.1, 'learning_rate': 0.06720819036373527, 'loss_func': 'Huber', 'normalize': 'minmax'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[36m(pid=18669)\u001b[0m INFO - (NP.config.__post_init__) - Trend reg lambda ignored due to no changepoints.\n",
      "\u001b[2m\u001b[36m(pid=18669)\u001b[0m INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=18669)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=18669)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18669)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18669)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18669)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[36m(pid=18669)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18669)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=18669)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18669)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=18669)\u001b[0m 1 | ar_net        | ModuleList    | 249 K \n",
      "\u001b[2m\u001b[36m(pid=18669)\u001b[0m 2 | loss_func     | MSELoss       | 0     \n",
      "\u001b[2m\u001b[36m(pid=18669)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18669)\u001b[0m 249 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=18669)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=18669)\u001b[0m 249 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=18669)\u001b[0m 0.997     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=18669)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18669)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18669)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18669)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18669)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18669)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=18669)\u001b[0m {'growth': 'off', 'n_changepoints': 5, 'changepoints_range': 0.8, 'trend_reg': 0.5, 'yearly_seasonality': False, 'weekly_seasonality': True, 'daily_seasonality': True, 'seasonality_mode': 'additive', 'seasonality_reg': 1.0, 'n_lags': 10, 'd_hidden': 128, 'num_hidden_layers': 16, 'ar_sparsity': 0.1, 'learning_rate': 0.0012877049149735008, 'loss_func': 'MSE', 'normalize': 'off'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-10 12:48:32,244\tWARNING util.py:162 -- The `start_trial` operation took 1.037 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=18679)\u001b[0m INFO - (NP.config.__post_init__) - Trend reg lambda ignored due to no changepoints.\n",
      "\u001b[2m\u001b[36m(pid=18679)\u001b[0m INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=18679)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=18679)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18679)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18679)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18679)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18679)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18679)\u001b[0m   | Name      | Type       | Params\n",
      "\u001b[2m\u001b[36m(pid=18679)\u001b[0m -----------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18679)\u001b[0m 0 | ar_net    | ModuleList | 29.6 K\n",
      "\u001b[2m\u001b[36m(pid=18679)\u001b[0m 1 | loss_func | MSELoss    | 0     \n",
      "\u001b[2m\u001b[36m(pid=18679)\u001b[0m -----------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18679)\u001b[0m 29.6 K    Trainable params\n",
      "\u001b[2m\u001b[36m(pid=18679)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=18679)\u001b[0m 29.6 K    Total params\n",
      "\u001b[2m\u001b[36m(pid=18679)\u001b[0m 0.118     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=18679)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18679)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18679)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18679)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18679)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18679)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=18679)\u001b[0m {'growth': 'off', 'n_changepoints': 100, 'changepoints_range': 0.8, 'trend_reg': 0.5, 'yearly_seasonality': False, 'weekly_seasonality': False, 'daily_seasonality': False, 'seasonality_mode': 'additive', 'seasonality_reg': 1.0, 'n_lags': 100, 'd_hidden': 128, 'num_hidden_layers': 2, 'ar_sparsity': 0.1, 'learning_rate': 0.0001781762254641946, 'loss_func': 'MSE', 'normalize': 'auto'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=18683)\u001b[0m INFO - (NP.config.__post_init__) - Note: Trend changepoint regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=18683)\u001b[0m INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=18683)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=18683)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18683)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18683)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18683)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18683)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18683)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=18683)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18683)\u001b[0m 0 | season_params | ParameterDict | 6     \n",
      "\u001b[2m\u001b[36m(pid=18683)\u001b[0m 1 | ar_net        | ModuleList    | 888   \n",
      "\u001b[2m\u001b[36m(pid=18683)\u001b[0m 2 | loss_func     | MSELoss       | 0     \n",
      "\u001b[2m\u001b[36m(pid=18683)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18683)\u001b[0m 997       Trainable params\n",
      "\u001b[2m\u001b[36m(pid=18683)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=18683)\u001b[0m 997       Total params\n",
      "\u001b[2m\u001b[36m(pid=18683)\u001b[0m 0.004     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=18683)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18683)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18683)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18683)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18683)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18683)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=18683)\u001b[0m {'growth': 'linear', 'n_changepoints': 100, 'changepoints_range': 0.5, 'trend_reg': 0.5, 'yearly_seasonality': False, 'weekly_seasonality': True, 'daily_seasonality': False, 'seasonality_mode': 'additive', 'seasonality_reg': 0.5, 'n_lags': 100, 'd_hidden': 8, 'num_hidden_layers': 2, 'ar_sparsity': 0.3, 'learning_rate': 0.001631574401107655, 'loss_func': 'MSE', 'normalize': 'minmax'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[36m(pid=18686)\u001b[0m INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=18686)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=18686)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18686)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18686)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18686)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18686)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18686)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=18686)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18686)\u001b[0m 0 | season_params | ParameterDict | 30    \n",
      "\u001b[2m\u001b[36m(pid=18686)\u001b[0m 1 | ar_net        | ModuleList    | 10.7 K\n",
      "\u001b[2m\u001b[36m(pid=18686)\u001b[0m 2 | loss_func     | MSELoss       | 0     \n",
      "\u001b[2m\u001b[36m(pid=18686)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18686)\u001b[0m 10.7 K    Trainable params\n",
      "\u001b[2m\u001b[36m(pid=18686)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=18686)\u001b[0m 10.7 K    Total params\n",
      "\u001b[2m\u001b[36m(pid=18686)\u001b[0m 0.043     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=18686)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18686)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18686)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18686)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18686)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18686)\u001b[0m \n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=18686)\u001b[0m {'growth': 'linear', 'n_changepoints': 5, 'changepoints_range': 0.8, 'trend_reg': 0.0, 'yearly_seasonality': True, 'weekly_seasonality': True, 'daily_seasonality': True, 'seasonality_mode': 'additive', 'seasonality_reg': 10.0, 'n_lags': 100, 'd_hidden': 64, 'num_hidden_layers': 2, 'ar_sparsity': 0.8, 'learning_rate': 0.018781676862947815, 'loss_func': 'MSE', 'normalize': 'auto'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=18695)\u001b[0m INFO - (NP.config.__post_init__) - Trend reg lambda ignored due to no changepoints.\n",
      "\u001b[2m\u001b[36m(pid=18695)\u001b[0m INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=18695)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=18695)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18695)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18695)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18695)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18695)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18695)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=18695)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18695)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=18695)\u001b[0m 1 | ar_net        | ModuleList    | 6.2 K \n",
      "\u001b[2m\u001b[36m(pid=18695)\u001b[0m 2 | loss_func     | MSELoss       | 0     \n",
      "\u001b[2m\u001b[36m(pid=18695)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18695)\u001b[0m 6.2 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=18695)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=18695)\u001b[0m 6.2 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=18695)\u001b[0m 0.025     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=18695)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18695)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18695)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18695)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18695)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18695)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=18695)\u001b[0m {'growth': 'off', 'n_changepoints': 100, 'changepoints_range': 0.9, 'trend_reg': 0.5, 'yearly_seasonality': True, 'weekly_seasonality': True, 'daily_seasonality': False, 'seasonality_mode': 'multiplicative', 'seasonality_reg': 0.5, 'n_lags': 30, 'd_hidden': 64, 'num_hidden_layers': 2, 'ar_sparsity': 0.3, 'learning_rate': 0.0021617056005691173, 'loss_func': 'MSE', 'normalize': 'off'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=18698)\u001b[0m INFO - (NP.config.__post_init__) - Note: Trend changepoint regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=18698)\u001b[0m INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=18698)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=18698)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18698)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18698)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18698)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18698)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18698)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=18698)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18698)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=18698)\u001b[0m 1 | ar_net        | ModuleList    | 20.6 K\n",
      "\u001b[2m\u001b[36m(pid=18698)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=18698)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18698)\u001b[0m 20.6 K    Trainable params\n",
      "\u001b[2m\u001b[36m(pid=18698)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=18698)\u001b[0m 20.6 K    Total params\n",
      "\u001b[2m\u001b[36m(pid=18698)\u001b[0m 0.083     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=18698)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18698)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18698)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18698)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18698)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18698)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=18698)\u001b[0m {'growth': 'linear', 'n_changepoints': 5, 'changepoints_range': 0.8, 'trend_reg': 10.0, 'yearly_seasonality': True, 'weekly_seasonality': True, 'daily_seasonality': False, 'seasonality_mode': 'multiplicative', 'seasonality_reg': 0.5, 'n_lags': 30, 'd_hidden': 128, 'num_hidden_layers': 2, 'ar_sparsity': 0.3, 'learning_rate': 0.023518041055053677, 'loss_func': 'Huber', 'normalize': 'standardize'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=18698)\u001b[0m \r",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters found were:  {'growth': 'off', 'n_changepoints': 100, 'changepoints_range': 0.9, 'trend_reg': 1.0, 'yearly_seasonality': False, 'weekly_seasonality': False, 'daily_seasonality': False, 'seasonality_mode': 'multiplicative', 'seasonality_reg': 0.5, 'n_lags': 30, 'd_hidden': 8, 'num_hidden_layers': 8, 'ar_sparsity': 0.1, 'learning_rate': 0.016032870001225212, 'loss_func': 'Huber', 'normalize': 'minmax'}\n"
     ]
    }
   ],
   "source": [
    "freq = '5min'\n",
    "best_params, results_df = tune_hyperparameters('NP', \n",
    "                            df,\n",
    "                            freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33a941dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>config.growth</th>\n",
       "      <th>config.n_changepoints</th>\n",
       "      <th>config.changepoints_range</th>\n",
       "      <th>config.trend_reg</th>\n",
       "      <th>config.yearly_seasonality</th>\n",
       "      <th>config.weekly_seasonality</th>\n",
       "      <th>config.daily_seasonality</th>\n",
       "      <th>config.seasonality_mode</th>\n",
       "      <th>config.seasonality_reg</th>\n",
       "      <th>config.n_lags</th>\n",
       "      <th>config.d_hidden</th>\n",
       "      <th>config.num_hidden_layers</th>\n",
       "      <th>config.ar_sparsity</th>\n",
       "      <th>config.learning_rate</th>\n",
       "      <th>config.loss_func</th>\n",
       "      <th>config.normalize</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trial_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ecf09_00001</th>\n",
       "      <td>linear</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>additive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000340</td>\n",
       "      <td>Huber</td>\n",
       "      <td>auto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ecf09_00002</th>\n",
       "      <td>off</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>multiplicative</td>\n",
       "      <td>0.5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.004222</td>\n",
       "      <td>MSE</td>\n",
       "      <td>off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ecf09_00003</th>\n",
       "      <td>linear</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>10.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>additive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.001155</td>\n",
       "      <td>MSE</td>\n",
       "      <td>off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ecf09_00007</th>\n",
       "      <td>linear</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>additive</td>\n",
       "      <td>10.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.098468</td>\n",
       "      <td>Huber</td>\n",
       "      <td>standardize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ecf09_00008</th>\n",
       "      <td>linear</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>additive</td>\n",
       "      <td>10.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.031956</td>\n",
       "      <td>MSE</td>\n",
       "      <td>auto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ecf09_00009</th>\n",
       "      <td>off</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>multiplicative</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>MSE</td>\n",
       "      <td>standardize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ecf09_00010</th>\n",
       "      <td>off</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>multiplicative</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>MSE</td>\n",
       "      <td>auto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ecf09_00012</th>\n",
       "      <td>linear</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>additive</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.012236</td>\n",
       "      <td>MSE</td>\n",
       "      <td>soft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ecf09_00014</th>\n",
       "      <td>linear</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>additive</td>\n",
       "      <td>0.5</td>\n",
       "      <td>30.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>MSE</td>\n",
       "      <td>auto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ecf09_00015</th>\n",
       "      <td>linear</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>multiplicative</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.001121</td>\n",
       "      <td>Huber</td>\n",
       "      <td>standardize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ecf09_00016</th>\n",
       "      <td>linear</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>10.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>additive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>Huber</td>\n",
       "      <td>soft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ecf09_00020</th>\n",
       "      <td>linear</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>additive</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>MSE</td>\n",
       "      <td>standardize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ecf09_00021</th>\n",
       "      <td>linear</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>additive</td>\n",
       "      <td>0.5</td>\n",
       "      <td>30.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>MSE</td>\n",
       "      <td>off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ecf09_00022</th>\n",
       "      <td>linear</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>additive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.001990</td>\n",
       "      <td>Huber</td>\n",
       "      <td>auto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ecf09_00024</th>\n",
       "      <td>off</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>multiplicative</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.001992</td>\n",
       "      <td>Huber</td>\n",
       "      <td>auto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ecf09_00025</th>\n",
       "      <td>off</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>additive</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.056184</td>\n",
       "      <td>Huber</td>\n",
       "      <td>auto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ecf09_00026</th>\n",
       "      <td>off</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>additive</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.014842</td>\n",
       "      <td>MSE</td>\n",
       "      <td>standardize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ecf09_00029</th>\n",
       "      <td>linear</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>additive</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.067508</td>\n",
       "      <td>MSE</td>\n",
       "      <td>soft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ecf09_00030</th>\n",
       "      <td>linear</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>multiplicative</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>Huber</td>\n",
       "      <td>auto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ecf09_00034</th>\n",
       "      <td>off</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>multiplicative</td>\n",
       "      <td>0.5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.027429</td>\n",
       "      <td>Huber</td>\n",
       "      <td>minmax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ecf09_00036</th>\n",
       "      <td>linear</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>additive</td>\n",
       "      <td>10.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.004639</td>\n",
       "      <td>MSE</td>\n",
       "      <td>standardize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ecf09_00037</th>\n",
       "      <td>linear</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>multiplicative</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>Huber</td>\n",
       "      <td>auto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            config.growth  config.n_changepoints  config.changepoints_range  \\\n",
       "trial_id                                                                      \n",
       "NaN                   NaN                    NaN                        NaN   \n",
       "ecf09_00001        linear                   10.0                        0.9   \n",
       "ecf09_00002           off                    5.0                        0.8   \n",
       "ecf09_00003        linear                   10.0                        0.8   \n",
       "NaN                   NaN                    NaN                        NaN   \n",
       "NaN                   NaN                    NaN                        NaN   \n",
       "NaN                   NaN                    NaN                        NaN   \n",
       "ecf09_00007        linear                    5.0                        0.8   \n",
       "ecf09_00008        linear                   10.0                        0.5   \n",
       "ecf09_00009           off                    5.0                        0.5   \n",
       "ecf09_00010           off                  100.0                        0.8   \n",
       "NaN                   NaN                    NaN                        NaN   \n",
       "ecf09_00012        linear                  100.0                        0.9   \n",
       "NaN                   NaN                    NaN                        NaN   \n",
       "ecf09_00014        linear                  100.0                        0.9   \n",
       "ecf09_00015        linear                   10.0                        0.9   \n",
       "ecf09_00016        linear                    5.0                        0.8   \n",
       "NaN                   NaN                    NaN                        NaN   \n",
       "NaN                   NaN                    NaN                        NaN   \n",
       "NaN                   NaN                    NaN                        NaN   \n",
       "ecf09_00020        linear                   10.0                        0.5   \n",
       "ecf09_00021        linear                    5.0                        0.5   \n",
       "ecf09_00022        linear                   10.0                        0.8   \n",
       "NaN                   NaN                    NaN                        NaN   \n",
       "ecf09_00024           off                  100.0                        0.9   \n",
       "ecf09_00025           off                    5.0                        0.9   \n",
       "ecf09_00026           off                  100.0                        0.5   \n",
       "NaN                   NaN                    NaN                        NaN   \n",
       "NaN                   NaN                    NaN                        NaN   \n",
       "ecf09_00029        linear                   10.0                        0.5   \n",
       "ecf09_00030        linear                    5.0                        0.5   \n",
       "NaN                   NaN                    NaN                        NaN   \n",
       "NaN                   NaN                    NaN                        NaN   \n",
       "NaN                   NaN                    NaN                        NaN   \n",
       "ecf09_00034           off                    5.0                        0.8   \n",
       "NaN                   NaN                    NaN                        NaN   \n",
       "ecf09_00036        linear                    5.0                        0.9   \n",
       "ecf09_00037        linear                  100.0                        0.9   \n",
       "NaN                   NaN                    NaN                        NaN   \n",
       "NaN                   NaN                    NaN                        NaN   \n",
       "\n",
       "             config.trend_reg config.yearly_seasonality  \\\n",
       "trial_id                                                  \n",
       "NaN                       NaN                       NaN   \n",
       "ecf09_00001               0.5                      True   \n",
       "ecf09_00002               0.0                     False   \n",
       "ecf09_00003              10.0                     False   \n",
       "NaN                       NaN                       NaN   \n",
       "NaN                       NaN                       NaN   \n",
       "NaN                       NaN                       NaN   \n",
       "ecf09_00007               0.5                      True   \n",
       "ecf09_00008               0.0                      True   \n",
       "ecf09_00009               0.0                     False   \n",
       "ecf09_00010               0.0                     False   \n",
       "NaN                       NaN                       NaN   \n",
       "ecf09_00012               1.0                     False   \n",
       "NaN                       NaN                       NaN   \n",
       "ecf09_00014              10.0                      True   \n",
       "ecf09_00015              10.0                      True   \n",
       "ecf09_00016              10.0                     False   \n",
       "NaN                       NaN                       NaN   \n",
       "NaN                       NaN                       NaN   \n",
       "NaN                       NaN                       NaN   \n",
       "ecf09_00020              10.0                     False   \n",
       "ecf09_00021               0.5                      True   \n",
       "ecf09_00022              10.0                      True   \n",
       "NaN                       NaN                       NaN   \n",
       "ecf09_00024               0.0                     False   \n",
       "ecf09_00025               0.0                     False   \n",
       "ecf09_00026               0.0                      True   \n",
       "NaN                       NaN                       NaN   \n",
       "NaN                       NaN                       NaN   \n",
       "ecf09_00029               1.0                     False   \n",
       "ecf09_00030               0.0                     False   \n",
       "NaN                       NaN                       NaN   \n",
       "NaN                       NaN                       NaN   \n",
       "NaN                       NaN                       NaN   \n",
       "ecf09_00034               0.0                      True   \n",
       "NaN                       NaN                       NaN   \n",
       "ecf09_00036               1.0                      True   \n",
       "ecf09_00037              10.0                     False   \n",
       "NaN                       NaN                       NaN   \n",
       "NaN                       NaN                       NaN   \n",
       "\n",
       "            config.weekly_seasonality config.daily_seasonality  \\\n",
       "trial_id                                                         \n",
       "NaN                               NaN                      NaN   \n",
       "ecf09_00001                      True                     True   \n",
       "ecf09_00002                     False                    False   \n",
       "ecf09_00003                      True                     True   \n",
       "NaN                               NaN                      NaN   \n",
       "NaN                               NaN                      NaN   \n",
       "NaN                               NaN                      NaN   \n",
       "ecf09_00007                     False                     True   \n",
       "ecf09_00008                     False                     True   \n",
       "ecf09_00009                     False                     True   \n",
       "ecf09_00010                      True                    False   \n",
       "NaN                               NaN                      NaN   \n",
       "ecf09_00012                     False                    False   \n",
       "NaN                               NaN                      NaN   \n",
       "ecf09_00014                     False                     True   \n",
       "ecf09_00015                      True                    False   \n",
       "ecf09_00016                      True                     True   \n",
       "NaN                               NaN                      NaN   \n",
       "NaN                               NaN                      NaN   \n",
       "NaN                               NaN                      NaN   \n",
       "ecf09_00020                     False                     True   \n",
       "ecf09_00021                     False                    False   \n",
       "ecf09_00022                      True                     True   \n",
       "NaN                               NaN                      NaN   \n",
       "ecf09_00024                     False                     True   \n",
       "ecf09_00025                     False                    False   \n",
       "ecf09_00026                     False                     True   \n",
       "NaN                               NaN                      NaN   \n",
       "NaN                               NaN                      NaN   \n",
       "ecf09_00029                     False                    False   \n",
       "ecf09_00030                      True                     True   \n",
       "NaN                               NaN                      NaN   \n",
       "NaN                               NaN                      NaN   \n",
       "NaN                               NaN                      NaN   \n",
       "ecf09_00034                     False                    False   \n",
       "NaN                               NaN                      NaN   \n",
       "ecf09_00036                      True                     True   \n",
       "ecf09_00037                      True                    False   \n",
       "NaN                               NaN                      NaN   \n",
       "NaN                               NaN                      NaN   \n",
       "\n",
       "            config.seasonality_mode  config.seasonality_reg  config.n_lags  \\\n",
       "trial_id                                                                     \n",
       "NaN                             NaN                     NaN            NaN   \n",
       "ecf09_00001                additive                     0.0           10.0   \n",
       "ecf09_00002          multiplicative                     0.5          100.0   \n",
       "ecf09_00003                additive                     0.0          100.0   \n",
       "NaN                             NaN                     NaN            NaN   \n",
       "NaN                             NaN                     NaN            NaN   \n",
       "NaN                             NaN                     NaN            NaN   \n",
       "ecf09_00007                additive                    10.0           30.0   \n",
       "ecf09_00008                additive                    10.0           30.0   \n",
       "ecf09_00009          multiplicative                     1.0          100.0   \n",
       "ecf09_00010          multiplicative                     0.0           10.0   \n",
       "NaN                             NaN                     NaN            NaN   \n",
       "ecf09_00012                additive                     1.0           10.0   \n",
       "NaN                             NaN                     NaN            NaN   \n",
       "ecf09_00014                additive                     0.5           30.0   \n",
       "ecf09_00015          multiplicative                     0.0          100.0   \n",
       "ecf09_00016                additive                     0.0          100.0   \n",
       "NaN                             NaN                     NaN            NaN   \n",
       "NaN                             NaN                     NaN            NaN   \n",
       "NaN                             NaN                     NaN            NaN   \n",
       "ecf09_00020                additive                    10.0           10.0   \n",
       "ecf09_00021                additive                     0.5           30.0   \n",
       "ecf09_00022                additive                     0.0           30.0   \n",
       "NaN                             NaN                     NaN            NaN   \n",
       "ecf09_00024          multiplicative                     1.0           10.0   \n",
       "ecf09_00025                additive                    10.0          100.0   \n",
       "ecf09_00026                additive                     1.0          100.0   \n",
       "NaN                             NaN                     NaN            NaN   \n",
       "NaN                             NaN                     NaN            NaN   \n",
       "ecf09_00029                additive                    10.0           10.0   \n",
       "ecf09_00030          multiplicative                     1.0           10.0   \n",
       "NaN                             NaN                     NaN            NaN   \n",
       "NaN                             NaN                     NaN            NaN   \n",
       "NaN                             NaN                     NaN            NaN   \n",
       "ecf09_00034          multiplicative                     0.5          100.0   \n",
       "NaN                             NaN                     NaN            NaN   \n",
       "ecf09_00036                additive                    10.0           30.0   \n",
       "ecf09_00037          multiplicative                     0.5           10.0   \n",
       "NaN                             NaN                     NaN            NaN   \n",
       "NaN                             NaN                     NaN            NaN   \n",
       "\n",
       "             config.d_hidden  config.num_hidden_layers  config.ar_sparsity  \\\n",
       "trial_id                                                                     \n",
       "NaN                      NaN                       NaN                 NaN   \n",
       "ecf09_00001            128.0                      16.0                 0.1   \n",
       "ecf09_00002            128.0                       8.0                 0.3   \n",
       "ecf09_00003             64.0                       8.0                 0.3   \n",
       "NaN                      NaN                       NaN                 NaN   \n",
       "NaN                      NaN                       NaN                 NaN   \n",
       "NaN                      NaN                       NaN                 NaN   \n",
       "ecf09_00007              8.0                      16.0                 0.3   \n",
       "ecf09_00008              8.0                       8.0                 0.8   \n",
       "ecf09_00009            128.0                       2.0                 0.8   \n",
       "ecf09_00010             64.0                       2.0                 0.8   \n",
       "NaN                      NaN                       NaN                 NaN   \n",
       "ecf09_00012             64.0                      16.0                 0.3   \n",
       "NaN                      NaN                       NaN                 NaN   \n",
       "ecf09_00014             64.0                      16.0                 0.1   \n",
       "ecf09_00015            128.0                       8.0                 0.1   \n",
       "ecf09_00016            128.0                       8.0                 0.3   \n",
       "NaN                      NaN                       NaN                 NaN   \n",
       "NaN                      NaN                       NaN                 NaN   \n",
       "NaN                      NaN                       NaN                 NaN   \n",
       "ecf09_00020              8.0                       2.0                 0.3   \n",
       "ecf09_00021              8.0                       8.0                 0.1   \n",
       "ecf09_00022             64.0                       8.0                 0.8   \n",
       "NaN                      NaN                       NaN                 NaN   \n",
       "ecf09_00024             64.0                      16.0                 0.8   \n",
       "ecf09_00025              8.0                      16.0                 0.8   \n",
       "ecf09_00026            128.0                       2.0                 0.1   \n",
       "NaN                      NaN                       NaN                 NaN   \n",
       "NaN                      NaN                       NaN                 NaN   \n",
       "ecf09_00029             64.0                       8.0                 0.1   \n",
       "ecf09_00030             64.0                      16.0                 0.1   \n",
       "NaN                      NaN                       NaN                 NaN   \n",
       "NaN                      NaN                       NaN                 NaN   \n",
       "NaN                      NaN                       NaN                 NaN   \n",
       "ecf09_00034             64.0                       2.0                 0.3   \n",
       "NaN                      NaN                       NaN                 NaN   \n",
       "ecf09_00036              8.0                      16.0                 0.8   \n",
       "ecf09_00037             64.0                      16.0                 0.1   \n",
       "NaN                      NaN                       NaN                 NaN   \n",
       "NaN                      NaN                       NaN                 NaN   \n",
       "\n",
       "             config.learning_rate config.loss_func config.normalize  \n",
       "trial_id                                                             \n",
       "NaN                           NaN              NaN              NaN  \n",
       "ecf09_00001              0.000340            Huber             auto  \n",
       "ecf09_00002              0.004222              MSE              off  \n",
       "ecf09_00003              0.001155              MSE              off  \n",
       "NaN                           NaN              NaN              NaN  \n",
       "NaN                           NaN              NaN              NaN  \n",
       "NaN                           NaN              NaN              NaN  \n",
       "ecf09_00007              0.098468            Huber      standardize  \n",
       "ecf09_00008              0.031956              MSE             auto  \n",
       "ecf09_00009              0.000125              MSE      standardize  \n",
       "ecf09_00010              0.000284              MSE             auto  \n",
       "NaN                           NaN              NaN              NaN  \n",
       "ecf09_00012              0.012236              MSE             soft  \n",
       "NaN                           NaN              NaN              NaN  \n",
       "ecf09_00014              0.000179              MSE             auto  \n",
       "ecf09_00015              0.001121            Huber      standardize  \n",
       "ecf09_00016              0.000235            Huber             soft  \n",
       "NaN                           NaN              NaN              NaN  \n",
       "NaN                           NaN              NaN              NaN  \n",
       "NaN                           NaN              NaN              NaN  \n",
       "ecf09_00020              0.000466              MSE      standardize  \n",
       "ecf09_00021              0.000183              MSE              off  \n",
       "ecf09_00022              0.001990            Huber             auto  \n",
       "NaN                           NaN              NaN              NaN  \n",
       "ecf09_00024              0.001992            Huber             auto  \n",
       "ecf09_00025              0.056184            Huber             auto  \n",
       "ecf09_00026              0.014842              MSE      standardize  \n",
       "NaN                           NaN              NaN              NaN  \n",
       "NaN                           NaN              NaN              NaN  \n",
       "ecf09_00029              0.067508              MSE             soft  \n",
       "ecf09_00030              0.000145            Huber             auto  \n",
       "NaN                           NaN              NaN              NaN  \n",
       "NaN                           NaN              NaN              NaN  \n",
       "NaN                           NaN              NaN              NaN  \n",
       "ecf09_00034              0.027429            Huber           minmax  \n",
       "NaN                           NaN              NaN              NaN  \n",
       "ecf09_00036              0.004639              MSE      standardize  \n",
       "ecf09_00037              0.000257            Huber             auto  \n",
       "NaN                           NaN              NaN              NaN  \n",
       "NaN                           NaN              NaN              NaN  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df[['config.growth', 'config.n_changepoints', 'config.changepoints_range',\n",
    "       'config.trend_reg', 'config.yearly_seasonality',\n",
    "       'config.weekly_seasonality', 'config.daily_seasonality',\n",
    "       'config.seasonality_mode', 'config.seasonality_reg', 'config.n_lags',\n",
    "       'config.d_hidden', 'config.num_hidden_layers', 'config.ar_sparsity',\n",
    "       'config.learning_rate', 'config.loss_func', 'config.normalize']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9c8dc7b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'growth': 'off',\n",
       " 'n_changepoints': 100,\n",
       " 'changepoints_range': 0.8,\n",
       " 'trend_reg': 0.0,\n",
       " 'yearly_seasonality': False,\n",
       " 'weekly_seasonality': False,\n",
       " 'daily_seasonality': False,\n",
       " 'seasonality_mode': 'additive',\n",
       " 'seasonality_reg': 0.5,\n",
       " 'n_lags': 100,\n",
       " 'd_hidden': 8,\n",
       " 'num_hidden_layers': 2,\n",
       " 'ar_sparsity': 0.8,\n",
       " 'learning_rate': 0.010444235692186717,\n",
       " 'loss_func': 'Huber',\n",
       " 'normalize': 'minmax'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f50f3b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
