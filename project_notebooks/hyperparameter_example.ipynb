{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d820e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7017615",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from neuralprophet.forecaster_additional_models import LSTM\n",
    "from neuralprophet import NeuralProphet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26c6bec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55888eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "  \"update your install command.\", FutureWarning)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from neuralprophet.hyperparameter_tuner import tune_hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e86bdee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-05-01 00:00:00</td>\n",
       "      <td>27.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-05-01 00:05:00</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-05-01 00:10:00</td>\n",
       "      <td>26.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ds     y\n",
       "0  2017-05-01 00:00:00  27.8\n",
       "1  2017-05-01 00:05:00  27.0\n",
       "2  2017-05-01 00:10:00  26.8"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    !pip install git+https://github.com/ourownstory/neural_prophet.git # may take a while\n",
    "    #!pip install neuralprophet # much faster, but may not have the latest upgrades/bugfixes\n",
    "    data_location = \"https://raw.githubusercontent.com/ourownstory/neural_prophet/master/\"\n",
    "else:\n",
    "    data_location = \"../\"\n",
    "\n",
    "df = pd.read_csv(data_location + \"example_data/yosemite_temps.csv\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8c9483",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-10 02:41:13,370\tINFO services.py:1269 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8266\u001b[39m\u001b[22m\n",
      "2021-05-10 02:41:15,097\tWARNING function_runner.py:545 -- Function checkpointing is disabled. This may result in unexpected behavior when using checkpointing features or certain schedulers. To enable, set the train function arguments to be `func(config, checkpoint_dir=None)`.\n",
      "\u001b[2m\u001b[36m(pid=17050)\u001b[0m INFO - (NP.config.__post_init__) - Trend reg lambda ignored due to no changepoints.\n",
      "\u001b[2m\u001b[36m(pid=17050)\u001b[0m 2021-05-10 02:41:17,677\tERROR function_runner.py:254 -- Runner Thread raised error.\n",
      "\u001b[2m\u001b[36m(pid=17050)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=17050)\u001b[0m   File \"/Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 248, in run\n",
      "\u001b[2m\u001b[36m(pid=17050)\u001b[0m     self._entrypoint()\n",
      "\u001b[2m\u001b[36m(pid=17050)\u001b[0m   File \"/Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 316, in entrypoint\n",
      "\u001b[2m\u001b[36m(pid=17050)\u001b[0m     self._status_reporter.get_checkpoint())\n",
      "\u001b[2m\u001b[36m(pid=17050)\u001b[0m   File \"/Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 580, in _trainable_func\n",
      "\u001b[2m\u001b[36m(pid=17050)\u001b[0m     output = fn()\n",
      "\u001b[2m\u001b[36m(pid=17050)\u001b[0m   File \"/Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/tune/utils/trainable.py\", line 339, in _inner\n",
      "\u001b[2m\u001b[36m(pid=17050)\u001b[0m     inner(config, checkpoint_dir=None)\n",
      "\u001b[2m\u001b[36m(pid=17050)\u001b[0m   File \"/Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/tune/utils/trainable.py\", line 330, in inner\n",
      "\u001b[2m\u001b[36m(pid=17050)\u001b[0m     trainable(config, **fn_kwargs)\n",
      "\u001b[2m\u001b[36m(pid=17050)\u001b[0m   File \"/Users/polina/fds/neural_prophet/neuralprophet/hyperparameter_tuner.py\", line 34, in train_NP_tune\n",
      "\u001b[2m\u001b[36m(pid=17050)\u001b[0m     m = NeuralProphet(**config, epochs=num_epochs)\n",
      "\u001b[2m\u001b[36m(pid=17050)\u001b[0m   File \"/Users/polina/fds/neural_prophet/neuralprophet/forecaster.py\", line 177, in __init__\n",
      "\u001b[2m\u001b[36m(pid=17050)\u001b[0m     self.config_trend = configure.from_kwargs(configure.Trend, kwargs)\n",
      "\u001b[2m\u001b[36m(pid=17050)\u001b[0m   File \"/Users/polina/fds/neural_prophet/neuralprophet/configure.py\", line 16, in from_kwargs\n",
      "\u001b[2m\u001b[36m(pid=17050)\u001b[0m     return cls(**{k: v for k, v in kwargs.items() if k in inspect.signature(cls).parameters})\n",
      "\u001b[2m\u001b[36m(pid=17050)\u001b[0m   File \"<string>\", line 9, in __init__\n",
      "\u001b[2m\u001b[36m(pid=17050)\u001b[0m   File \"/Users/polina/fds/neural_prophet/neuralprophet/configure.py\", line 63, in __post_init__\n",
      "\u001b[2m\u001b[36m(pid=17050)\u001b[0m     if self.trend_reg_threshold > 0:\n",
      "\u001b[2m\u001b[36m(pid=17050)\u001b[0m TypeError: '>' not supported between instances of 'NoneType' and 'int'\n",
      "\u001b[2m\u001b[36m(pid=17050)\u001b[0m Exception in thread Thread-2:\n",
      "\u001b[2m\u001b[36m(pid=17050)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=17050)\u001b[0m   File \"/Users/polina/.conda/envs/neural_prophet/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "\u001b[2m\u001b[36m(pid=17050)\u001b[0m     self.run()\n",
      "\u001b[2m\u001b[36m(pid=17050)\u001b[0m   File \"/Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 267, in run\n",
      "\u001b[2m\u001b[36m(pid=17050)\u001b[0m     raise e\n",
      "\u001b[2m\u001b[36m(pid=17050)\u001b[0m   File \"/Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 248, in run\n",
      "\u001b[2m\u001b[36m(pid=17050)\u001b[0m     self._entrypoint()\n",
      "\u001b[2m\u001b[36m(pid=17050)\u001b[0m   File \"/Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 316, in entrypoint\n",
      "\u001b[2m\u001b[36m(pid=17050)\u001b[0m     self._status_reporter.get_checkpoint())\n",
      "\u001b[2m\u001b[36m(pid=17050)\u001b[0m   File \"/Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 580, in _trainable_func\n",
      "\u001b[2m\u001b[36m(pid=17050)\u001b[0m     output = fn()\n",
      "\u001b[2m\u001b[36m(pid=17050)\u001b[0m   File \"/Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/tune/utils/trainable.py\", line 339, in _inner\n",
      "\u001b[2m\u001b[36m(pid=17050)\u001b[0m     inner(config, checkpoint_dir=None)\n",
      "\u001b[2m\u001b[36m(pid=17050)\u001b[0m   File \"/Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/tune/utils/trainable.py\", line 330, in inner\n",
      "\u001b[2m\u001b[36m(pid=17050)\u001b[0m     trainable(config, **fn_kwargs)\n",
      "\u001b[2m\u001b[36m(pid=17050)\u001b[0m   File \"/Users/polina/fds/neural_prophet/neuralprophet/hyperparameter_tuner.py\", line 34, in train_NP_tune\n",
      "\u001b[2m\u001b[36m(pid=17050)\u001b[0m     m = NeuralProphet(**config, epochs=num_epochs)\n",
      "\u001b[2m\u001b[36m(pid=17050)\u001b[0m   File \"/Users/polina/fds/neural_prophet/neuralprophet/forecaster.py\", line 177, in __init__\n",
      "\u001b[2m\u001b[36m(pid=17050)\u001b[0m     self.config_trend = configure.from_kwargs(configure.Trend, kwargs)\n",
      "\u001b[2m\u001b[36m(pid=17050)\u001b[0m   File \"/Users/polina/fds/neural_prophet/neuralprophet/configure.py\", line 16, in from_kwargs\n",
      "\u001b[2m\u001b[36m(pid=17050)\u001b[0m     return cls(**{k: v for k, v in kwargs.items() if k in inspect.signature(cls).parameters})\n",
      "\u001b[2m\u001b[36m(pid=17050)\u001b[0m   File \"<string>\", line 9, in __init__\n",
      "\u001b[2m\u001b[36m(pid=17050)\u001b[0m   File \"/Users/polina/fds/neural_prophet/neuralprophet/configure.py\", line 63, in __post_init__\n",
      "\u001b[2m\u001b[36m(pid=17050)\u001b[0m     if self.trend_reg_threshold > 0:\n",
      "\u001b[2m\u001b[36m(pid=17050)\u001b[0m TypeError: '>' not supported between instances of 'NoneType' and 'int'\n",
      "\u001b[2m\u001b[36m(pid=17050)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=17047)\u001b[0m INFO - (NP.config.__post_init__) - Trend reg lambda ignored due to no changepoints.\n",
      "\u001b[2m\u001b[36m(pid=17047)\u001b[0m 2021-05-10 02:41:17,677\tERROR function_runner.py:254 -- Runner Thread raised error.\n",
      "\u001b[2m\u001b[36m(pid=17047)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=17047)\u001b[0m   File \"/Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 248, in run\n",
      "\u001b[2m\u001b[36m(pid=17047)\u001b[0m     self._entrypoint()\n",
      "\u001b[2m\u001b[36m(pid=17047)\u001b[0m   File \"/Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 316, in entrypoint\n",
      "\u001b[2m\u001b[36m(pid=17047)\u001b[0m     self._status_reporter.get_checkpoint())\n",
      "\u001b[2m\u001b[36m(pid=17047)\u001b[0m   File \"/Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 580, in _trainable_func\n",
      "\u001b[2m\u001b[36m(pid=17047)\u001b[0m     output = fn()\n",
      "\u001b[2m\u001b[36m(pid=17047)\u001b[0m   File \"/Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/tune/utils/trainable.py\", line 339, in _inner\n",
      "\u001b[2m\u001b[36m(pid=17047)\u001b[0m     inner(config, checkpoint_dir=None)\n",
      "\u001b[2m\u001b[36m(pid=17047)\u001b[0m   File \"/Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/tune/utils/trainable.py\", line 330, in inner\n",
      "\u001b[2m\u001b[36m(pid=17047)\u001b[0m     trainable(config, **fn_kwargs)\n",
      "\u001b[2m\u001b[36m(pid=17047)\u001b[0m   File \"/Users/polina/fds/neural_prophet/neuralprophet/hyperparameter_tuner.py\", line 34, in train_NP_tune\n",
      "\u001b[2m\u001b[36m(pid=17047)\u001b[0m     m = NeuralProphet(**config, epochs=num_epochs)\n",
      "\u001b[2m\u001b[36m(pid=17047)\u001b[0m   File \"/Users/polina/fds/neural_prophet/neuralprophet/forecaster.py\", line 177, in __init__\n",
      "\u001b[2m\u001b[36m(pid=17047)\u001b[0m     self.config_trend = configure.from_kwargs(configure.Trend, kwargs)\n",
      "\u001b[2m\u001b[36m(pid=17047)\u001b[0m   File \"/Users/polina/fds/neural_prophet/neuralprophet/configure.py\", line 16, in from_kwargs\n",
      "\u001b[2m\u001b[36m(pid=17047)\u001b[0m     return cls(**{k: v for k, v in kwargs.items() if k in inspect.signature(cls).parameters})\n",
      "\u001b[2m\u001b[36m(pid=17047)\u001b[0m   File \"<string>\", line 9, in __init__\n",
      "\u001b[2m\u001b[36m(pid=17047)\u001b[0m   File \"/Users/polina/fds/neural_prophet/neuralprophet/configure.py\", line 63, in __post_init__\n",
      "\u001b[2m\u001b[36m(pid=17047)\u001b[0m     if self.trend_reg_threshold > 0:\n",
      "\u001b[2m\u001b[36m(pid=17047)\u001b[0m TypeError: '>' not supported between instances of 'NoneType' and 'int'\n",
      "\u001b[2m\u001b[36m(pid=17047)\u001b[0m Exception in thread Thread-2:\n",
      "\u001b[2m\u001b[36m(pid=17047)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=17047)\u001b[0m   File \"/Users/polina/.conda/envs/neural_prophet/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "\u001b[2m\u001b[36m(pid=17047)\u001b[0m     self.run()\n",
      "\u001b[2m\u001b[36m(pid=17047)\u001b[0m   File \"/Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 267, in run\n",
      "\u001b[2m\u001b[36m(pid=17047)\u001b[0m     raise e\n",
      "\u001b[2m\u001b[36m(pid=17047)\u001b[0m   File \"/Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 248, in run\n",
      "\u001b[2m\u001b[36m(pid=17047)\u001b[0m     self._entrypoint()\n",
      "\u001b[2m\u001b[36m(pid=17047)\u001b[0m   File \"/Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 316, in entrypoint\n",
      "\u001b[2m\u001b[36m(pid=17047)\u001b[0m     self._status_reporter.get_checkpoint())\n",
      "\u001b[2m\u001b[36m(pid=17047)\u001b[0m   File \"/Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 580, in _trainable_func\n",
      "\u001b[2m\u001b[36m(pid=17047)\u001b[0m     output = fn()\n",
      "\u001b[2m\u001b[36m(pid=17047)\u001b[0m   File \"/Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/tune/utils/trainable.py\", line 339, in _inner\n",
      "\u001b[2m\u001b[36m(pid=17047)\u001b[0m     inner(config, checkpoint_dir=None)\n",
      "\u001b[2m\u001b[36m(pid=17047)\u001b[0m   File \"/Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/tune/utils/trainable.py\", line 330, in inner\n",
      "\u001b[2m\u001b[36m(pid=17047)\u001b[0m     trainable(config, **fn_kwargs)\n",
      "\u001b[2m\u001b[36m(pid=17047)\u001b[0m   File \"/Users/polina/fds/neural_prophet/neuralprophet/hyperparameter_tuner.py\", line 34, in train_NP_tune\n",
      "\u001b[2m\u001b[36m(pid=17047)\u001b[0m     m = NeuralProphet(**config, epochs=num_epochs)\n",
      "\u001b[2m\u001b[36m(pid=17047)\u001b[0m   File \"/Users/polina/fds/neural_prophet/neuralprophet/forecaster.py\", line 177, in __init__\n",
      "\u001b[2m\u001b[36m(pid=17047)\u001b[0m     self.config_trend = configure.from_kwargs(configure.Trend, kwargs)\n",
      "\u001b[2m\u001b[36m(pid=17047)\u001b[0m   File \"/Users/polina/fds/neural_prophet/neuralprophet/configure.py\", line 16, in from_kwargs\n",
      "\u001b[2m\u001b[36m(pid=17047)\u001b[0m     return cls(**{k: v for k, v in kwargs.items() if k in inspect.signature(cls).parameters})\n",
      "\u001b[2m\u001b[36m(pid=17047)\u001b[0m   File \"<string>\", line 9, in __init__\n",
      "\u001b[2m\u001b[36m(pid=17047)\u001b[0m   File \"/Users/polina/fds/neural_prophet/neuralprophet/configure.py\", line 63, in __post_init__\n",
      "\u001b[2m\u001b[36m(pid=17047)\u001b[0m     if self.trend_reg_threshold > 0:\n",
      "\u001b[2m\u001b[36m(pid=17047)\u001b[0m TypeError: '>' not supported between instances of 'NoneType' and 'int'\n",
      "\u001b[2m\u001b[36m(pid=17047)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=17051)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=17051)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=17051)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=17051)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=17051)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=17051)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=17051)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=17051)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=17051)\u001b[0m 0 | season_params | ParameterDict | 12    \n",
      "\u001b[2m\u001b[36m(pid=17051)\u001b[0m 1 | ar_net        | ModuleList    | 20.6 K\n",
      "\u001b[2m\u001b[36m(pid=17051)\u001b[0m 2 | loss_func     | MSELoss       | 0     \n",
      "\u001b[2m\u001b[36m(pid=17051)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=17051)\u001b[0m 20.6 K    Trainable params\n",
      "\u001b[2m\u001b[36m(pid=17051)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=17051)\u001b[0m 20.6 K    Total params\n",
      "\u001b[2m\u001b[36m(pid=17051)\u001b[0m 0.082     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=17051)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=17051)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=17051)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=17051)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=17051)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=17051)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=17049)\u001b[0m INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=17049)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=17046)\u001b[0m INFO - (NP.config.__post_init__) - Note: Trend changepoint regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=17046)\u001b[0m INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=17046)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=17046)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "\u001b[2m\u001b[36m(pid=17049)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "\u001b[2m\u001b[36m(pid=17048)\u001b[0m INFO - (NP.config.__post_init__) - Trend reg lambda ignored due to no changepoints.\n",
      "\u001b[2m\u001b[36m(pid=17048)\u001b[0m 2021-05-10 02:41:17,823\tERROR function_runner.py:254 -- Runner Thread raised error.\n",
      "\u001b[2m\u001b[36m(pid=17048)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=17048)\u001b[0m   File \"/Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 248, in run\n",
      "\u001b[2m\u001b[36m(pid=17048)\u001b[0m     self._entrypoint()\n",
      "\u001b[2m\u001b[36m(pid=17048)\u001b[0m   File \"/Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 316, in entrypoint\n",
      "\u001b[2m\u001b[36m(pid=17048)\u001b[0m     self._status_reporter.get_checkpoint())\n",
      "\u001b[2m\u001b[36m(pid=17048)\u001b[0m   File \"/Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 580, in _trainable_func\n",
      "\u001b[2m\u001b[36m(pid=17048)\u001b[0m     output = fn()\n",
      "\u001b[2m\u001b[36m(pid=17048)\u001b[0m   File \"/Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/tune/utils/trainable.py\", line 339, in _inner\n",
      "\u001b[2m\u001b[36m(pid=17048)\u001b[0m     inner(config, checkpoint_dir=None)\n",
      "\u001b[2m\u001b[36m(pid=17048)\u001b[0m   File \"/Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/tune/utils/trainable.py\", line 330, in inner\n",
      "\u001b[2m\u001b[36m(pid=17048)\u001b[0m     trainable(config, **fn_kwargs)\n",
      "\u001b[2m\u001b[36m(pid=17048)\u001b[0m   File \"/Users/polina/fds/neural_prophet/neuralprophet/hyperparameter_tuner.py\", line 34, in train_NP_tune\n",
      "\u001b[2m\u001b[36m(pid=17048)\u001b[0m     m = NeuralProphet(**config, epochs=num_epochs)\n",
      "\u001b[2m\u001b[36m(pid=17048)\u001b[0m   File \"/Users/polina/fds/neural_prophet/neuralprophet/forecaster.py\", line 177, in __init__\n",
      "\u001b[2m\u001b[36m(pid=17048)\u001b[0m     self.config_trend = configure.from_kwargs(configure.Trend, kwargs)\n",
      "\u001b[2m\u001b[36m(pid=17048)\u001b[0m   File \"/Users/polina/fds/neural_prophet/neuralprophet/configure.py\", line 16, in from_kwargs\n",
      "\u001b[2m\u001b[36m(pid=17048)\u001b[0m     return cls(**{k: v for k, v in kwargs.items() if k in inspect.signature(cls).parameters})\n",
      "\u001b[2m\u001b[36m(pid=17048)\u001b[0m   File \"<string>\", line 9, in __init__\n",
      "\u001b[2m\u001b[36m(pid=17048)\u001b[0m   File \"/Users/polina/fds/neural_prophet/neuralprophet/configure.py\", line 63, in __post_init__\n",
      "\u001b[2m\u001b[36m(pid=17048)\u001b[0m     if self.trend_reg_threshold > 0:\n",
      "\u001b[2m\u001b[36m(pid=17048)\u001b[0m TypeError: '>' not supported between instances of 'NoneType' and 'int'\n",
      "\u001b[2m\u001b[36m(pid=17048)\u001b[0m Exception in thread Thread-2:\n",
      "\u001b[2m\u001b[36m(pid=17048)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=17048)\u001b[0m   File \"/Users/polina/.conda/envs/neural_prophet/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "\u001b[2m\u001b[36m(pid=17048)\u001b[0m     self.run()\n",
      "\u001b[2m\u001b[36m(pid=17048)\u001b[0m   File \"/Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 267, in run\n",
      "\u001b[2m\u001b[36m(pid=17048)\u001b[0m     raise e\n",
      "\u001b[2m\u001b[36m(pid=17048)\u001b[0m   File \"/Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 248, in run\n",
      "\u001b[2m\u001b[36m(pid=17048)\u001b[0m     self._entrypoint()\n",
      "\u001b[2m\u001b[36m(pid=17048)\u001b[0m   File \"/Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 316, in entrypoint\n",
      "\u001b[2m\u001b[36m(pid=17048)\u001b[0m     self._status_reporter.get_checkpoint())\n",
      "\u001b[2m\u001b[36m(pid=17048)\u001b[0m   File \"/Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 580, in _trainable_func\n",
      "\u001b[2m\u001b[36m(pid=17048)\u001b[0m     output = fn()\n",
      "\u001b[2m\u001b[36m(pid=17048)\u001b[0m   File \"/Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/tune/utils/trainable.py\", line 339, in _inner\n",
      "\u001b[2m\u001b[36m(pid=17048)\u001b[0m     inner(config, checkpoint_dir=None)\n",
      "\u001b[2m\u001b[36m(pid=17048)\u001b[0m   File \"/Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/tune/utils/trainable.py\", line 330, in inner\n",
      "\u001b[2m\u001b[36m(pid=17048)\u001b[0m     trainable(config, **fn_kwargs)\n",
      "\u001b[2m\u001b[36m(pid=17048)\u001b[0m   File \"/Users/polina/fds/neural_prophet/neuralprophet/hyperparameter_tuner.py\", line 34, in train_NP_tune\n",
      "\u001b[2m\u001b[36m(pid=17048)\u001b[0m     m = NeuralProphet(**config, epochs=num_epochs)\n",
      "\u001b[2m\u001b[36m(pid=17048)\u001b[0m   File \"/Users/polina/fds/neural_prophet/neuralprophet/forecaster.py\", line 177, in __init__\n",
      "\u001b[2m\u001b[36m(pid=17048)\u001b[0m     self.config_trend = configure.from_kwargs(configure.Trend, kwargs)\n",
      "\u001b[2m\u001b[36m(pid=17048)\u001b[0m   File \"/Users/polina/fds/neural_prophet/neuralprophet/configure.py\", line 16, in from_kwargs\n",
      "\u001b[2m\u001b[36m(pid=17048)\u001b[0m     return cls(**{k: v for k, v in kwargs.items() if k in inspect.signature(cls).parameters})\n",
      "\u001b[2m\u001b[36m(pid=17048)\u001b[0m   File \"<string>\", line 9, in __init__\n",
      "\u001b[2m\u001b[36m(pid=17048)\u001b[0m   File \"/Users/polina/fds/neural_prophet/neuralprophet/configure.py\", line 63, in __post_init__\n",
      "\u001b[2m\u001b[36m(pid=17048)\u001b[0m     if self.trend_reg_threshold > 0:\n",
      "\u001b[2m\u001b[36m(pid=17048)\u001b[0m TypeError: '>' not supported between instances of 'NoneType' and 'int'\n",
      "\u001b[2m\u001b[36m(pid=17048)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=17045)\u001b[0m INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=17052)\u001b[0m INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "2021-05-10 02:41:17,880\tERROR trial_runner.py:732 -- Trial train_NP_tune_0b454_00004: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/tune/trial_runner.py\", line 702, in _process_trial\n",
      "    results = self.trial_executor.fetch_result(trial)\n",
      "  File \"/Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py\", line 686, in fetch_result\n",
      "    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\n",
      "  File \"/Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/_private/client_mode_hook.py\", line 47, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/worker.py\", line 1481, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TuneError): \u001b[36mray::ImplicitFunc.train_buffered()\u001b[39m (pid=17050, ip=192.168.0.7)\n",
      "  File \"python/ray/_raylet.pyx\", line 505, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 449, in ray._raylet.execute_task.function_executor\n",
      "  File \"/Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/_private/function_manager.py\", line 556, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"/Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/tune/trainable.py\", line 173, in train_buffered\n",
      "    result = self.train()\n",
      "  File \"/Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/tune/trainable.py\", line 232, in train\n",
      "    result = self.step()\n",
      "  File \"/Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 366, in step\n",
      "    self._report_thread_runner_error(block=True)\n",
      "  File \"/Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 513, in _report_thread_runner_error\n",
      "    (\"Trial raised an exception. Traceback:\\n{}\".format(err_tb_str)\n",
      "ray.tune.error.TuneError: Trial raised an exception. Traceback:\n",
      "\u001b[36mray::ImplicitFunc.train_buffered()\u001b[39m (pid=17050, ip=192.168.0.7)\n",
      "  File \"/Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 248, in run\n",
      "    self._entrypoint()\n",
      "  File \"/Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 316, in entrypoint\n",
      "    self._status_reporter.get_checkpoint())\n",
      "  File \"/Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 580, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/tune/utils/trainable.py\", line 339, in _inner\n",
      "    inner(config, checkpoint_dir=None)\n",
      "  File \"/Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/tune/utils/trainable.py\", line 330, in inner\n",
      "    trainable(config, **fn_kwargs)\n",
      "  File \"/Users/polina/fds/neural_prophet/neuralprophet/hyperparameter_tuner.py\", line 34, in train_NP_tune\n",
      "    m = NeuralProphet(**config, epochs=num_epochs)\n",
      "  File \"/Users/polina/fds/neural_prophet/neuralprophet/forecaster.py\", line 177, in __init__\n",
      "    self.config_trend = configure.from_kwargs(configure.Trend, kwargs)\n",
      "  File \"/Users/polina/fds/neural_prophet/neuralprophet/configure.py\", line 16, in from_kwargs\n",
      "    return cls(**{k: v for k, v in kwargs.items() if k in inspect.signature(cls).parameters})\n",
      "  File \"<string>\", line 9, in __init__\n",
      "  File \"/Users/polina/fds/neural_prophet/neuralprophet/configure.py\", line 63, in __post_init__\n",
      "    if self.trend_reg_threshold > 0:\n",
      "TypeError: '>' not supported between instances of 'NoneType' and 'int'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=17046)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=17046)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=17046)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=17045)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=17052)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "2021-05-10 02:41:17,960\tERROR trial_runner.py:732 -- Trial train_NP_tune_0b454_00001: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/tune/trial_runner.py\", line 702, in _process_trial\n",
      "    results = self.trial_executor.fetch_result(trial)\n",
      "  File \"/Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py\", line 686, in fetch_result\n",
      "    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\n",
      "  File \"/Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/_private/client_mode_hook.py\", line 47, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/worker.py\", line 1481, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TuneError): \u001b[36mray::ImplicitFunc.train_buffered()\u001b[39m (pid=17047, ip=192.168.0.7)\n",
      "  File \"python/ray/_raylet.pyx\", line 505, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 449, in ray._raylet.execute_task.function_executor\n",
      "  File \"/Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/_private/function_manager.py\", line 556, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"/Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/tune/trainable.py\", line 173, in train_buffered\n",
      "    result = self.train()\n",
      "  File \"/Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/tune/trainable.py\", line 232, in train\n",
      "    result = self.step()\n",
      "  File \"/Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 366, in step\n",
      "    self._report_thread_runner_error(block=True)\n",
      "  File \"/Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 513, in _report_thread_runner_error\n",
      "    (\"Trial raised an exception. Traceback:\\n{}\".format(err_tb_str)\n",
      "ray.tune.error.TuneError: Trial raised an exception. Traceback:\n",
      "\u001b[36mray::ImplicitFunc.train_buffered()\u001b[39m (pid=17047, ip=192.168.0.7)\n",
      "  File \"/Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 248, in run\n",
      "    self._entrypoint()\n",
      "  File \"/Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 316, in entrypoint\n",
      "    self._status_reporter.get_checkpoint())\n",
      "  File \"/Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 580, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/tune/utils/trainable.py\", line 339, in _inner\n",
      "    inner(config, checkpoint_dir=None)\n",
      "  File \"/Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/tune/utils/trainable.py\", line 330, in inner\n",
      "    trainable(config, **fn_kwargs)\n",
      "  File \"/Users/polina/fds/neural_prophet/neuralprophet/hyperparameter_tuner.py\", line 34, in train_NP_tune\n",
      "    m = NeuralProphet(**config, epochs=num_epochs)\n",
      "  File \"/Users/polina/fds/neural_prophet/neuralprophet/forecaster.py\", line 177, in __init__\n",
      "    self.config_trend = configure.from_kwargs(configure.Trend, kwargs)\n",
      "  File \"/Users/polina/fds/neural_prophet/neuralprophet/configure.py\", line 16, in from_kwargs\n",
      "    return cls(**{k: v for k, v in kwargs.items() if k in inspect.signature(cls).parameters})\n",
      "  File \"<string>\", line 9, in __init__\n",
      "  File \"/Users/polina/fds/neural_prophet/neuralprophet/configure.py\", line 63, in __post_init__\n",
      "    if self.trend_reg_threshold > 0:\n",
      "TypeError: '>' not supported between instances of 'NoneType' and 'int'\n",
      "\u001b[2m\u001b[36m(pid=17046)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=17046)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=17046)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=17046)\u001b[0m 0 | season_params | ParameterDict | 12    \n",
      "\u001b[2m\u001b[36m(pid=17046)\u001b[0m 1 | ar_net        | ModuleList    | 63.2 K\n",
      "\u001b[2m\u001b[36m(pid=17046)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=17046)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=17046)\u001b[0m 63.2 K    Trainable params\n",
      "\u001b[2m\u001b[36m(pid=17046)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=17046)\u001b[0m 63.2 K    Total params\n",
      "\u001b[2m\u001b[36m(pid=17046)\u001b[0m 0.253     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=17046)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=17046)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=17046)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=17046)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=17046)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=17046)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=17045)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "\u001b[2m\u001b[36m(pid=17052)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "2021-05-10 02:41:18,024\tERROR trial_runner.py:732 -- Trial train_NP_tune_0b454_00006: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/tune/trial_runner.py\", line 702, in _process_trial\n",
      "    results = self.trial_executor.fetch_result(trial)\n",
      "  File \"/Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py\", line 686, in fetch_result\n",
      "    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\n",
      "  File \"/Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/_private/client_mode_hook.py\", line 47, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/worker.py\", line 1481, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TuneError): \u001b[36mray::ImplicitFunc.train_buffered()\u001b[39m (pid=17048, ip=192.168.0.7)\n",
      "  File \"python/ray/_raylet.pyx\", line 505, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 449, in ray._raylet.execute_task.function_executor\n",
      "  File \"/Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/_private/function_manager.py\", line 556, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"/Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/tune/trainable.py\", line 173, in train_buffered\n",
      "    result = self.train()\n",
      "  File \"/Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/tune/trainable.py\", line 232, in train\n",
      "    result = self.step()\n",
      "  File \"/Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 366, in step\n",
      "    self._report_thread_runner_error(block=True)\n",
      "  File \"/Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 513, in _report_thread_runner_error\n",
      "    (\"Trial raised an exception. Traceback:\\n{}\".format(err_tb_str)\n",
      "ray.tune.error.TuneError: Trial raised an exception. Traceback:\n",
      "\u001b[36mray::ImplicitFunc.train_buffered()\u001b[39m (pid=17048, ip=192.168.0.7)\n",
      "  File \"/Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 248, in run\n",
      "    self._entrypoint()\n",
      "  File \"/Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 316, in entrypoint\n",
      "    self._status_reporter.get_checkpoint())\n",
      "  File \"/Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 580, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/tune/utils/trainable.py\", line 339, in _inner\n",
      "    inner(config, checkpoint_dir=None)\n",
      "  File \"/Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/tune/utils/trainable.py\", line 330, in inner\n",
      "    trainable(config, **fn_kwargs)\n",
      "  File \"/Users/polina/fds/neural_prophet/neuralprophet/hyperparameter_tuner.py\", line 34, in train_NP_tune\n",
      "    m = NeuralProphet(**config, epochs=num_epochs)\n",
      "  File \"/Users/polina/fds/neural_prophet/neuralprophet/forecaster.py\", line 177, in __init__\n",
      "    self.config_trend = configure.from_kwargs(configure.Trend, kwargs)\n",
      "  File \"/Users/polina/fds/neural_prophet/neuralprophet/configure.py\", line 16, in from_kwargs\n",
      "    return cls(**{k: v for k, v in kwargs.items() if k in inspect.signature(cls).parameters})\n",
      "  File \"<string>\", line 9, in __init__\n",
      "  File \"/Users/polina/fds/neural_prophet/neuralprophet/configure.py\", line 63, in __post_init__\n",
      "    if self.trend_reg_threshold > 0:\n",
      "TypeError: '>' not supported between instances of 'NoneType' and 'int'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=17049)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=17049)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=17049)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=17049)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=17049)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=17049)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=17049)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=17049)\u001b[0m 1 | ar_net        | ModuleList    | 6.2 K \n",
      "\u001b[2m\u001b[36m(pid=17049)\u001b[0m 2 | loss_func     | MSELoss       | 0     \n",
      "\u001b[2m\u001b[36m(pid=17049)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=17049)\u001b[0m 6.2 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=17049)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=17049)\u001b[0m 6.2 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=17049)\u001b[0m 0.025     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=17049)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=17049)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=17049)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=17049)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=17049)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=17049)\u001b[0m \n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=17045)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=17045)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=17045)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=17045)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=17045)\u001b[0m   | Name      | Type         | Params\n",
      "\u001b[2m\u001b[36m(pid=17045)\u001b[0m -------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=17045)\u001b[0m 0 | ar_net    | ModuleList   | 888   \n",
      "\u001b[2m\u001b[36m(pid=17045)\u001b[0m 1 | loss_func | SmoothL1Loss | 0     \n",
      "\u001b[2m\u001b[36m(pid=17045)\u001b[0m -------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=17045)\u001b[0m 889       Trainable params\n",
      "\u001b[2m\u001b[36m(pid=17045)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=17045)\u001b[0m 889       Total params\n",
      "\u001b[2m\u001b[36m(pid=17045)\u001b[0m 0.004     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=17045)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=17045)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=17045)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=17045)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=17045)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=17045)\u001b[0m \n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=17052)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=17052)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=17052)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=17052)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=17052)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=17052)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=17052)\u001b[0m 0 | season_params | ParameterDict | 12    \n",
      "\u001b[2m\u001b[36m(pid=17052)\u001b[0m 1 | ar_net        | ModuleList    | 1.2 K \n",
      "\u001b[2m\u001b[36m(pid=17052)\u001b[0m 2 | loss_func     | MSELoss       | 0     \n",
      "\u001b[2m\u001b[36m(pid=17052)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=17052)\u001b[0m 1.2 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=17052)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=17052)\u001b[0m 1.2 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=17052)\u001b[0m 0.005     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=17052)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=17052)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=17052)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=17052)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=17052)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=17052)\u001b[0m \n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "freq = '5min'\n",
    "best_params, results_df = tune_hyperparameters('NP', \n",
    "                            df,\n",
    "                            freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "871270ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>time_this_iter_s</th>\n",
       "      <th>done</th>\n",
       "      <th>timesteps_total</th>\n",
       "      <th>episodes_total</th>\n",
       "      <th>training_iteration</th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>date</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>time_total_s</th>\n",
       "      <th>...</th>\n",
       "      <th>config.daily_seasonality</th>\n",
       "      <th>config.seasonality_mode</th>\n",
       "      <th>config.seasonality_reg</th>\n",
       "      <th>config.n_lags</th>\n",
       "      <th>config.d_hidden</th>\n",
       "      <th>config.num_hidden_layers</th>\n",
       "      <th>config.ar_sparsity</th>\n",
       "      <th>config.learning_rate</th>\n",
       "      <th>config.loss_func</th>\n",
       "      <th>config.normalize</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trial_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dbe9b_00000</th>\n",
       "      <td>0.40696</td>\n",
       "      <td>2.320458</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>978838c0b549480c96b1d51def4e0cbd</td>\n",
       "      <td>2021-05-10_02-36-36</td>\n",
       "      <td>1620603396</td>\n",
       "      <td>228.920473</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>additive</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>MSE</td>\n",
       "      <td>standardize</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                loss  time_this_iter_s  done timesteps_total episodes_total  \\\n",
       "trial_id                                                                      \n",
       "dbe9b_00000  0.40696          2.320458  True            None           None   \n",
       "\n",
       "             training_iteration                     experiment_id  \\\n",
       "trial_id                                                            \n",
       "dbe9b_00000                 100  978838c0b549480c96b1d51def4e0cbd   \n",
       "\n",
       "                            date   timestamp  time_total_s  ...  \\\n",
       "trial_id                                                    ...   \n",
       "dbe9b_00000  2021-05-10_02-36-36  1620603396    228.920473  ...   \n",
       "\n",
       "             config.daily_seasonality config.seasonality_mode  \\\n",
       "trial_id                                                        \n",
       "dbe9b_00000                      True                additive   \n",
       "\n",
       "            config.seasonality_reg  config.n_lags  config.d_hidden  \\\n",
       "trial_id                                                             \n",
       "dbe9b_00000                    1.0            100              128   \n",
       "\n",
       "             config.num_hidden_layers config.ar_sparsity config.learning_rate  \\\n",
       "trial_id                                                                        \n",
       "dbe9b_00000                        16                0.8             0.000109   \n",
       "\n",
       "             config.loss_func  config.normalize  \n",
       "trial_id                                         \n",
       "dbe9b_00000               MSE       standardize  \n",
       "\n",
       "[1 rows x 33 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91d00a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
