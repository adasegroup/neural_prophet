{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ourownstory/neural_prophet/blob/master/example_notebooks/autoregression_yosemite_temps.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter optimization with Ray Tune\n",
    "\n",
    "We introduce the module for hyperparameter otpimization with Ray Tune.\n",
    "\n",
    "It supports automatic tuning, with predefined by us hyperparameter sets, as well as manual tuning with user-provided configuration of the parameters.\n",
    "\n",
    "Firstly, we will show how it works with NP model in automated mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install NeuralProphet from our repository\n",
    "!pip install git+https://github.com/adasegroup/neural_prophet.git # may take a while\n",
    "!pip install tensorboardX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from neuralprophet import NeuralProphet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralprophet.hyperparameter_tuner import tune_hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-05-01 00:00:00</td>\n",
       "      <td>27.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-05-01 00:05:00</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-05-01 00:10:00</td>\n",
       "      <td>26.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ds     y\n",
       "0  2017-05-01 00:00:00  27.8\n",
       "1  2017-05-01 00:05:00  27.0\n",
       "2  2017-05-01 00:10:00  26.8"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    data_location = \"https://raw.githubusercontent.com/adasegroup/neural_prophet/master/\"\n",
    "else:\n",
    "    data_location = \"../\"\n",
    "\n",
    "df = pd.read_csv(data_location + \"example_data/yosemite_temps.csv\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=18489)\u001b[0m INFO - (NP.config.__post_init__) - Trend reg lambda ignored due to no changepoints.\n",
      "\u001b[2m\u001b[36m(pid=18489)\u001b[0m INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=18489)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=18489)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "\u001b[2m\u001b[36m(pid=18492)\u001b[0m INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=18492)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18489)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18489)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18489)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18492)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "\u001b[2m\u001b[36m(pid=18486)\u001b[0m INFO - (NP.config.__post_init__) - Trend reg lambda ignored due to no changepoints.\n",
      "\u001b[2m\u001b[36m(pid=18486)\u001b[0m INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=18489)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18489)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=18489)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18489)\u001b[0m 0 | season_params | ParameterDict | 6     \n",
      "\u001b[2m\u001b[36m(pid=18489)\u001b[0m 1 | ar_net        | ModuleList    | 18.0 K\n",
      "\u001b[2m\u001b[36m(pid=18489)\u001b[0m 2 | loss_func     | MSELoss       | 0     \n",
      "\u001b[2m\u001b[36m(pid=18489)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18489)\u001b[0m 18.1 K    Trainable params\n",
      "\u001b[2m\u001b[36m(pid=18489)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=18489)\u001b[0m 18.1 K    Total params\n",
      "\u001b[2m\u001b[36m(pid=18489)\u001b[0m 0.072     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=18489)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18489)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18489)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18489)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18489)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18489)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18486)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=18489)\u001b[0m {'growth': 'off', 'n_changepoints': 100, 'changepoints_range': 0.5, 'trend_reg': 10.0, 'yearly_seasonality': False, 'weekly_seasonality': True, 'daily_seasonality': False, 'seasonality_mode': 'additive', 'seasonality_reg': 1.0, 'n_lags': 10, 'd_hidden': 128, 'num_hidden_layers': 2, 'ar_sparsity': 0.1, 'learning_rate': 0.00025794771866301903, 'loss_func': 'MSE', 'normalize': 'standardize'}\n",
      "\u001b[2m\u001b[36m(pid=18492)\u001b[0m {'growth': 'linear', 'n_changepoints': 100, 'changepoints_range': 0.5, 'trend_reg': 0.0, 'yearly_seasonality': False, 'weekly_seasonality': False, 'daily_seasonality': True, 'seasonality_mode': 'multiplicative', 'seasonality_reg': 0.5, 'n_lags': 10, 'd_hidden': 8, 'num_hidden_layers': 2, 'ar_sparsity': 0.3, 'learning_rate': 0.0002926262239414852, 'loss_func': 'MSE', 'normalize': 'auto'}\n",
      "\u001b[2m\u001b[36m(pid=18491)\u001b[0m {'growth': 'off', 'n_changepoints': 100, 'changepoints_range': 0.5, 'trend_reg': 0.0, 'yearly_seasonality': False, 'weekly_seasonality': False, 'daily_seasonality': False, 'seasonality_mode': 'multiplicative', 'seasonality_reg': 0.0, 'n_lags': 10, 'd_hidden': 128, 'num_hidden_layers': 8, 'ar_sparsity': 0.1, 'learning_rate': 0.01177473387772018, 'loss_func': 'Huber', 'normalize': 'standardize'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18492)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18492)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18492)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18492)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18492)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=18492)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18492)\u001b[0m 0 | season_params | ParameterDict | 12    \n",
      "\u001b[2m\u001b[36m(pid=18492)\u001b[0m 1 | ar_net        | ModuleList    | 168   \n",
      "\u001b[2m\u001b[36m(pid=18492)\u001b[0m 2 | loss_func     | MSELoss       | 0     \n",
      "\u001b[2m\u001b[36m(pid=18492)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18492)\u001b[0m 283       Trainable params\n",
      "\u001b[2m\u001b[36m(pid=18492)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=18492)\u001b[0m 283       Total params\n",
      "\u001b[2m\u001b[36m(pid=18492)\u001b[0m 0.001     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=18492)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18492)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18492)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18492)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18492)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18492)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18486)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "\u001b[2m\u001b[36m(pid=18491)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=18491)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18491)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18491)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18491)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18491)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18491)\u001b[0m   | Name      | Type         | Params\n",
      "\u001b[2m\u001b[36m(pid=18491)\u001b[0m -------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18491)\u001b[0m 0 | ar_net    | ModuleList   | 117 K \n",
      "\u001b[2m\u001b[36m(pid=18491)\u001b[0m 1 | loss_func | SmoothL1Loss | 0     \n",
      "\u001b[2m\u001b[36m(pid=18491)\u001b[0m -------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18491)\u001b[0m 117 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=18491)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=18491)\u001b[0m 117 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=18491)\u001b[0m 0.468     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=18488)\u001b[0m INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=18487)\u001b[0m INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=18493)\u001b[0m INFO - (NP.config.__post_init__) - Note: Trend changepoint regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=18493)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=18493)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "\u001b[2m\u001b[36m(pid=18491)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18491)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18491)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18491)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18491)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18491)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18488)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=18487)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=18488)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "\u001b[2m\u001b[36m(pid=18487)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18486)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18486)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18486)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18486)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18486)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=18486)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18486)\u001b[0m 0 | season_params | ParameterDict | 24    \n",
      "\u001b[2m\u001b[36m(pid=18486)\u001b[0m 1 | ar_net        | ModuleList    | 29.9 K\n",
      "\u001b[2m\u001b[36m(pid=18486)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=18486)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18486)\u001b[0m 29.9 K    Trainable params\n",
      "\u001b[2m\u001b[36m(pid=18486)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=18486)\u001b[0m 29.9 K    Total params\n",
      "\u001b[2m\u001b[36m(pid=18486)\u001b[0m 0.120     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=18486)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18486)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18486)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18486)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18486)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18486)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18490)\u001b[0m INFO - (NP.config.__post_init__) - Trend reg lambda ignored due to no changepoints.\n",
      "\u001b[2m\u001b[36m(pid=18490)\u001b[0m INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=18490)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18487)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18487)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18487)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18493)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18493)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18493)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18490)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18488)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18488)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18488)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18493)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18493)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=18493)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18493)\u001b[0m 0 | season_params | ParameterDict | 30    \n",
      "\u001b[2m\u001b[36m(pid=18493)\u001b[0m 1 | ar_net        | ModuleList    | 760   \n",
      "\u001b[2m\u001b[36m(pid=18493)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=18493)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18493)\u001b[0m 803       Trainable params\n",
      "\u001b[2m\u001b[36m(pid=18493)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=18493)\u001b[0m 803       Total params\n",
      "\u001b[2m\u001b[36m(pid=18493)\u001b[0m 0.003     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=18493)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18493)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18493)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18493)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18493)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18493)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18487)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18487)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=18487)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18487)\u001b[0m 0 | season_params | ParameterDict | 24    \n",
      "\u001b[2m\u001b[36m(pid=18487)\u001b[0m 1 | ar_net        | ModuleList    | 249 K \n",
      "\u001b[2m\u001b[36m(pid=18487)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=18487)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18487)\u001b[0m 249 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=18487)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=18487)\u001b[0m 249 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=18487)\u001b[0m 0.997     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=18487)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18487)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18487)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18487)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18487)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18487)\u001b[0m \n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[36m(pid=18488)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18488)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=18488)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18488)\u001b[0m 0 | season_params | ParameterDict | 30    \n",
      "\u001b[2m\u001b[36m(pid=18488)\u001b[0m 1 | ar_net        | ModuleList    | 31.2 K\n",
      "\u001b[2m\u001b[36m(pid=18488)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=18488)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18488)\u001b[0m 31.2 K    Trainable params\n",
      "\u001b[2m\u001b[36m(pid=18488)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=18488)\u001b[0m 31.2 K    Total params\n",
      "\u001b[2m\u001b[36m(pid=18488)\u001b[0m 0.125     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=18488)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18488)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18488)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18488)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18488)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18488)\u001b[0m \n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18490)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18490)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18490)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18490)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18490)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=18490)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18490)\u001b[0m 0 | season_params | ParameterDict | 12    \n",
      "\u001b[2m\u001b[36m(pid=18490)\u001b[0m 1 | ar_net        | ModuleList    | 119 K \n",
      "\u001b[2m\u001b[36m(pid=18490)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=18490)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18490)\u001b[0m 119 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=18490)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=18490)\u001b[0m 119 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=18490)\u001b[0m 0.479     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=18490)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18490)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18490)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18490)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18490)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18490)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=18486)\u001b[0m {'growth': 'off', 'n_changepoints': 5, 'changepoints_range': 0.9, 'trend_reg': 10.0, 'yearly_seasonality': True, 'weekly_seasonality': False, 'daily_seasonality': True, 'seasonality_mode': 'multiplicative', 'seasonality_reg': 0.5, 'n_lags': 10, 'd_hidden': 64, 'num_hidden_layers': 8, 'ar_sparsity': 0.8, 'learning_rate': 0.05709530464716042, 'loss_func': 'Huber', 'normalize': 'soft'}\n",
      "\u001b[2m\u001b[36m(pid=18487)\u001b[0m {'growth': 'off', 'n_changepoints': 5, 'changepoints_range': 0.8, 'trend_reg': 0.0, 'yearly_seasonality': True, 'weekly_seasonality': False, 'daily_seasonality': True, 'seasonality_mode': 'multiplicative', 'seasonality_reg': 1.0, 'n_lags': 10, 'd_hidden': 128, 'num_hidden_layers': 16, 'ar_sparsity': 0.3, 'learning_rate': 0.004413941508220393, 'loss_func': 'Huber', 'normalize': 'soft'}\n",
      "\u001b[2m\u001b[36m(pid=18493)\u001b[0m {'growth': 'linear', 'n_changepoints': 10, 'changepoints_range': 0.5, 'trend_reg': 0.5, 'yearly_seasonality': True, 'weekly_seasonality': True, 'daily_seasonality': True, 'seasonality_mode': 'multiplicative', 'seasonality_reg': 0.0, 'n_lags': 30, 'd_hidden': 8, 'num_hidden_layers': 8, 'ar_sparsity': 0.3, 'learning_rate': 0.01363167399344815, 'loss_func': 'Huber', 'normalize': 'off'}\n",
      "\u001b[2m\u001b[36m(pid=18488)\u001b[0m {'growth': 'off', 'n_changepoints': 100, 'changepoints_range': 0.9, 'trend_reg': 0.0, 'yearly_seasonality': True, 'weekly_seasonality': True, 'daily_seasonality': True, 'seasonality_mode': 'multiplicative', 'seasonality_reg': 0.5, 'n_lags': 30, 'd_hidden': 64, 'num_hidden_layers': 8, 'ar_sparsity': 0.1, 'learning_rate': 0.0016671543773598275, 'loss_func': 'Huber', 'normalize': 'auto'}\n",
      "\u001b[2m\u001b[36m(pid=18490)\u001b[0m {'growth': 'off', 'n_changepoints': 5, 'changepoints_range': 0.8, 'trend_reg': 0.5, 'yearly_seasonality': True, 'weekly_seasonality': False, 'daily_seasonality': False, 'seasonality_mode': 'additive', 'seasonality_reg': 1.0, 'n_lags': 30, 'd_hidden': 128, 'num_hidden_layers': 8, 'ar_sparsity': 0.3, 'learning_rate': 0.061274546662678064, 'loss_func': 'Huber', 'normalize': 'off'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=18532)\u001b[0m INFO - (NP.config.__post_init__) - Note: Trend changepoint regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=18532)\u001b[0m INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=18532)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=18532)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18532)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18532)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18532)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18532)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18532)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=18532)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18532)\u001b[0m 0 | season_params | ParameterDict | 6     \n",
      "\u001b[2m\u001b[36m(pid=18532)\u001b[0m 1 | ar_net        | ModuleList    | 10.7 K\n",
      "\u001b[2m\u001b[36m(pid=18532)\u001b[0m 2 | loss_func     | MSELoss       | 0     \n",
      "\u001b[2m\u001b[36m(pid=18532)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18532)\u001b[0m 10.8 K    Trainable params\n",
      "\u001b[2m\u001b[36m(pid=18532)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=18532)\u001b[0m 10.8 K    Total params\n",
      "\u001b[2m\u001b[36m(pid=18532)\u001b[0m 0.043     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=18532)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18532)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18532)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18532)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18532)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18532)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=18532)\u001b[0m {'growth': 'linear', 'n_changepoints': 100, 'changepoints_range': 0.5, 'trend_reg': 1.0, 'yearly_seasonality': False, 'weekly_seasonality': True, 'daily_seasonality': False, 'seasonality_mode': 'additive', 'seasonality_reg': 0.5, 'n_lags': 100, 'd_hidden': 64, 'num_hidden_layers': 2, 'ar_sparsity': 0.1, 'learning_rate': 0.002321224873593233, 'loss_func': 'MSE', 'normalize': 'soft'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=18536)\u001b[0m INFO - (NP.config.__post_init__) - Note: Trend changepoint regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=18536)\u001b[0m INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=18536)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=18536)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18536)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18536)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18536)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18536)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18536)\u001b[0m   | Name      | Type       | Params\n",
      "\u001b[2m\u001b[36m(pid=18536)\u001b[0m -----------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18536)\u001b[0m 0 | ar_net    | ModuleList | 6.2 K \n",
      "\u001b[2m\u001b[36m(pid=18536)\u001b[0m 1 | loss_func | MSELoss    | 0     \n",
      "\u001b[2m\u001b[36m(pid=18536)\u001b[0m -----------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18536)\u001b[0m 6.2 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=18536)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=18536)\u001b[0m 6.2 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=18536)\u001b[0m 0.025     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=18536)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18536)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18536)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18536)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18536)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18536)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=18536)\u001b[0m {'growth': 'linear', 'n_changepoints': 10, 'changepoints_range': 0.9, 'trend_reg': 1.0, 'yearly_seasonality': False, 'weekly_seasonality': False, 'daily_seasonality': False, 'seasonality_mode': 'additive', 'seasonality_reg': 10.0, 'n_lags': 30, 'd_hidden': 64, 'num_hidden_layers': 2, 'ar_sparsity': 0.1, 'learning_rate': 0.0012780104541181485, 'loss_func': 'MSE', 'normalize': 'auto'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=18539)\u001b[0m INFO - (NP.config.__post_init__) - Note: Trend changepoint regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=18539)\u001b[0m INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=18539)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=18539)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18539)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18539)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18539)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18539)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18539)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=18539)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18539)\u001b[0m 0 | season_params | ParameterDict | 12    \n",
      "\u001b[2m\u001b[36m(pid=18539)\u001b[0m 1 | ar_net        | ModuleList    | 119 K \n",
      "\u001b[2m\u001b[36m(pid=18539)\u001b[0m 2 | loss_func     | MSELoss       | 0     \n",
      "\u001b[2m\u001b[36m(pid=18539)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18539)\u001b[0m 119 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=18539)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=18539)\u001b[0m 119 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=18539)\u001b[0m 0.479     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=18539)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18539)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18539)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18539)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18539)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18539)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=18539)\u001b[0m {'growth': 'linear', 'n_changepoints': 5, 'changepoints_range': 0.9, 'trend_reg': 1.0, 'yearly_seasonality': False, 'weekly_seasonality': False, 'daily_seasonality': True, 'seasonality_mode': 'additive', 'seasonality_reg': 10.0, 'n_lags': 30, 'd_hidden': 128, 'num_hidden_layers': 8, 'ar_sparsity': 0.8, 'learning_rate': 0.00038336638659065527, 'loss_func': 'MSE', 'normalize': 'minmax'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=18545)\u001b[0m INFO - (NP.config.__post_init__) - Note: Trend changepoint regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=18545)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=18545)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18545)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18545)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18545)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[36m(pid=18545)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18545)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=18545)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18545)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=18545)\u001b[0m 1 | ar_net        | ModuleList    | 1.3 K \n",
      "\u001b[2m\u001b[36m(pid=18545)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=18545)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18545)\u001b[0m 1.4 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=18545)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=18545)\u001b[0m 1.4 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=18545)\u001b[0m 0.005     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=18545)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18545)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18545)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18545)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18545)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18545)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=18545)\u001b[0m {'growth': 'linear', 'n_changepoints': 10, 'changepoints_range': 0.9, 'trend_reg': 1.0, 'yearly_seasonality': False, 'weekly_seasonality': True, 'daily_seasonality': True, 'seasonality_mode': 'additive', 'seasonality_reg': 0.0, 'n_lags': 30, 'd_hidden': 8, 'num_hidden_layers': 16, 'ar_sparsity': 0.8, 'learning_rate': 0.007816968632308399, 'loss_func': 'Huber', 'normalize': 'minmax'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=18554)\u001b[0m INFO - (NP.config.__post_init__) - Trend reg lambda ignored due to no changepoints.\n",
      "\u001b[2m\u001b[36m(pid=18554)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=18554)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18554)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18554)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18554)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18554)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18554)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=18554)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18554)\u001b[0m 0 | season_params | ParameterDict | 6     \n",
      "\u001b[2m\u001b[36m(pid=18554)\u001b[0m 1 | ar_net        | ModuleList    | 1.3 K \n",
      "\u001b[2m\u001b[36m(pid=18554)\u001b[0m 2 | loss_func     | MSELoss       | 0     \n",
      "\u001b[2m\u001b[36m(pid=18554)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18554)\u001b[0m 1.3 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=18554)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=18554)\u001b[0m 1.3 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=18554)\u001b[0m 0.005     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=18554)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18554)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18554)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18554)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18554)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18554)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=18554)\u001b[0m {'growth': 'off', 'n_changepoints': 10, 'changepoints_range': 0.5, 'trend_reg': 1.0, 'yearly_seasonality': False, 'weekly_seasonality': True, 'daily_seasonality': False, 'seasonality_mode': 'additive', 'seasonality_reg': 0.0, 'n_lags': 100, 'd_hidden': 8, 'num_hidden_layers': 8, 'ar_sparsity': 0.3, 'learning_rate': 0.0028338671889591004, 'loss_func': 'MSE', 'normalize': 'soft'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=18557)\u001b[0m INFO - (NP.config.__post_init__) - Trend reg lambda ignored due to no changepoints.\n",
      "\u001b[2m\u001b[36m(pid=18557)\u001b[0m INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=18557)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=18557)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=18557)\u001b[0m {'growth': 'off', 'n_changepoints': 100, 'changepoints_range': 0.5, 'trend_reg': 1.0, 'yearly_seasonality': True, 'weekly_seasonality': False, 'daily_seasonality': True, 'seasonality_mode': 'multiplicative', 'seasonality_reg': 1.0, 'n_lags': 100, 'd_hidden': 64, 'num_hidden_layers': 8, 'ar_sparsity': 0.8, 'learning_rate': 0.0042786934665185235, 'loss_func': 'MSE', 'normalize': 'standardize'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18557)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18557)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18557)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18557)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18557)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=18557)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18557)\u001b[0m 0 | season_params | ParameterDict | 24    \n",
      "\u001b[2m\u001b[36m(pid=18557)\u001b[0m 1 | ar_net        | ModuleList    | 35.6 K\n",
      "\u001b[2m\u001b[36m(pid=18557)\u001b[0m 2 | loss_func     | MSELoss       | 0     \n",
      "\u001b[2m\u001b[36m(pid=18557)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18557)\u001b[0m 35.7 K    Trainable params\n",
      "\u001b[2m\u001b[36m(pid=18557)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=18557)\u001b[0m 35.7 K    Total params\n",
      "\u001b[2m\u001b[36m(pid=18557)\u001b[0m 0.143     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=18557)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18557)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18557)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18557)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18557)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18557)\u001b[0m \n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=18560)\u001b[0m INFO - (NP.config.__post_init__) - Trend reg lambda ignored due to no changepoints.\n",
      "\u001b[2m\u001b[36m(pid=18560)\u001b[0m INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=18560)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=18560)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18560)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18560)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18560)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[36m(pid=18560)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18560)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=18560)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18560)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=18560)\u001b[0m 1 | ar_net        | ModuleList    | 63.2 K\n",
      "\u001b[2m\u001b[36m(pid=18560)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=18560)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18560)\u001b[0m 63.2 K    Trainable params\n",
      "\u001b[2m\u001b[36m(pid=18560)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=18560)\u001b[0m 63.2 K    Total params\n",
      "\u001b[2m\u001b[36m(pid=18560)\u001b[0m 0.253     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=18560)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18560)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18560)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18560)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18560)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18560)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=18560)\u001b[0m {'growth': 'off', 'n_changepoints': 5, 'changepoints_range': 0.9, 'trend_reg': 10.0, 'yearly_seasonality': True, 'weekly_seasonality': True, 'daily_seasonality': False, 'seasonality_mode': 'multiplicative', 'seasonality_reg': 1.0, 'n_lags': 10, 'd_hidden': 64, 'num_hidden_layers': 16, 'ar_sparsity': 0.1, 'learning_rate': 0.004509112115464473, 'loss_func': 'Huber', 'normalize': 'minmax'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=18563)\u001b[0m INFO - (NP.config.__post_init__) - Trend reg lambda ignored due to no changepoints.\n",
      "\u001b[2m\u001b[36m(pid=18566)\u001b[0m INFO - (NP.config.__post_init__) - Trend reg lambda ignored due to no changepoints.\n",
      "\u001b[2m\u001b[36m(pid=18563)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=18563)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "\u001b[2m\u001b[36m(pid=18566)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=18566)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18563)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18563)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18563)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18566)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18566)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18566)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18566)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18566)\u001b[0m   | Name      | Type       | Params\n",
      "\u001b[2m\u001b[36m(pid=18566)\u001b[0m -----------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18566)\u001b[0m 0 | ar_net    | ModuleList | 29.9 K\n",
      "\u001b[2m\u001b[36m(pid=18566)\u001b[0m 1 | loss_func | MSELoss    | 0     \n",
      "\u001b[2m\u001b[36m(pid=18566)\u001b[0m -----------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18566)\u001b[0m 29.9 K    Trainable params\n",
      "\u001b[2m\u001b[36m(pid=18566)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=18566)\u001b[0m 29.9 K    Total params\n",
      "\u001b[2m\u001b[36m(pid=18566)\u001b[0m 0.120     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=18566)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18566)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18566)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18566)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18566)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18566)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18563)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18563)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=18563)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18563)\u001b[0m 0 | season_params | ParameterDict | 30    \n",
      "\u001b[2m\u001b[36m(pid=18563)\u001b[0m 1 | ar_net        | ModuleList    | 31.2 K\n",
      "\u001b[2m\u001b[36m(pid=18563)\u001b[0m 2 | loss_func     | MSELoss       | 0     \n",
      "\u001b[2m\u001b[36m(pid=18563)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18563)\u001b[0m 31.2 K    Trainable params\n",
      "\u001b[2m\u001b[36m(pid=18563)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=18563)\u001b[0m 31.2 K    Total params\n",
      "\u001b[2m\u001b[36m(pid=18563)\u001b[0m 0.125     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=18563)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18563)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18563)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18563)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18563)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18563)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=18563)\u001b[0m {'growth': 'off', 'n_changepoints': 10, 'changepoints_range': 0.8, 'trend_reg': 0.5, 'yearly_seasonality': True, 'weekly_seasonality': True, 'daily_seasonality': True, 'seasonality_mode': 'additive', 'seasonality_reg': 0.0, 'n_lags': 30, 'd_hidden': 64, 'num_hidden_layers': 8, 'ar_sparsity': 0.1, 'learning_rate': 0.0006543945360003929, 'loss_func': 'MSE', 'normalize': 'off'}\n",
      "\u001b[2m\u001b[36m(pid=18566)\u001b[0m {'growth': 'off', 'n_changepoints': 10, 'changepoints_range': 0.9, 'trend_reg': 0.5, 'yearly_seasonality': False, 'weekly_seasonality': False, 'daily_seasonality': False, 'seasonality_mode': 'multiplicative', 'seasonality_reg': 0.0, 'n_lags': 10, 'd_hidden': 64, 'num_hidden_layers': 8, 'ar_sparsity': 0.1, 'learning_rate': 0.022149611256811454, 'loss_func': 'MSE', 'normalize': 'minmax'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=18579)\u001b[0m INFO - (NP.config.__post_init__) - Trend reg lambda ignored due to no changepoints.\n",
      "\u001b[2m\u001b[36m(pid=18579)\u001b[0m INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=18579)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=18579)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18579)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18579)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18579)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18579)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18579)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=18579)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18579)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=18579)\u001b[0m 1 | ar_net        | ModuleList    | 10.7 K\n",
      "\u001b[2m\u001b[36m(pid=18579)\u001b[0m 2 | loss_func     | MSELoss       | 0     \n",
      "\u001b[2m\u001b[36m(pid=18579)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18579)\u001b[0m 10.7 K    Trainable params\n",
      "\u001b[2m\u001b[36m(pid=18579)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=18579)\u001b[0m 10.7 K    Total params\n",
      "\u001b[2m\u001b[36m(pid=18579)\u001b[0m 0.043     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=18579)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18579)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18579)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18579)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18579)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18579)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=18579)\u001b[0m {'growth': 'off', 'n_changepoints': 100, 'changepoints_range': 0.8, 'trend_reg': 10.0, 'yearly_seasonality': True, 'weekly_seasonality': True, 'daily_seasonality': False, 'seasonality_mode': 'multiplicative', 'seasonality_reg': 1.0, 'n_lags': 100, 'd_hidden': 64, 'num_hidden_layers': 2, 'ar_sparsity': 0.3, 'learning_rate': 0.0009196093298665312, 'loss_func': 'MSE', 'normalize': 'standardize'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=18586)\u001b[0m INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=18586)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=18586)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18586)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18586)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18586)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18586)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18586)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=18586)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18586)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=18586)\u001b[0m 1 | ar_net        | ModuleList    | 600   \n",
      "\u001b[2m\u001b[36m(pid=18586)\u001b[0m 2 | loss_func     | MSELoss       | 0     \n",
      "\u001b[2m\u001b[36m(pid=18586)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18586)\u001b[0m 619       Trainable params\n",
      "\u001b[2m\u001b[36m(pid=18586)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=18586)\u001b[0m 619       Total params\n",
      "\u001b[2m\u001b[36m(pid=18586)\u001b[0m 0.002     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=18586)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18586)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18586)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18586)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18586)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18586)\u001b[0m \n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=18586)\u001b[0m {'growth': 'off', 'n_changepoints': 5, 'changepoints_range': 0.9, 'trend_reg': 0.0, 'yearly_seasonality': True, 'weekly_seasonality': True, 'daily_seasonality': False, 'seasonality_mode': 'multiplicative', 'seasonality_reg': 1.0, 'n_lags': 10, 'd_hidden': 8, 'num_hidden_layers': 8, 'ar_sparsity': 0.3, 'learning_rate': 0.009121166158922013, 'loss_func': 'MSE', 'normalize': 'auto'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=18589)\u001b[0m INFO - (NP.config.__post_init__) - Note: Trend changepoint regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=18589)\u001b[0m INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=18589)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=18589)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18589)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18589)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18589)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18589)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18589)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=18589)\u001b[0m ------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=18589)\u001b[0m {'growth': 'linear', 'n_changepoints': 5, 'changepoints_range': 0.5, 'trend_reg': 10.0, 'yearly_seasonality': True, 'weekly_seasonality': True, 'daily_seasonality': True, 'seasonality_mode': 'multiplicative', 'seasonality_reg': 10.0, 'n_lags': 100, 'd_hidden': 128, 'num_hidden_layers': 8, 'ar_sparsity': 0.3, 'learning_rate': 0.00176538236998349, 'loss_func': 'Huber', 'normalize': 'auto'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=18589)\u001b[0m 0 | season_params | ParameterDict | 30    \n",
      "\u001b[2m\u001b[36m(pid=18589)\u001b[0m 1 | ar_net        | ModuleList    | 128 K \n",
      "\u001b[2m\u001b[36m(pid=18589)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=18589)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18589)\u001b[0m 128 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=18589)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=18589)\u001b[0m 128 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=18589)\u001b[0m 0.515     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=18589)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18589)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18589)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18589)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18589)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18589)\u001b[0m \n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=18592)\u001b[0m INFO - (NP.config.__post_init__) - Note: Trend changepoint regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=18592)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=18592)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18592)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18592)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18592)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[36m(pid=18592)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18592)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=18592)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18592)\u001b[0m 0 | season_params | ParameterDict | 12    \n",
      "\u001b[2m\u001b[36m(pid=18592)\u001b[0m 1 | ar_net        | ModuleList    | 249 K \n",
      "\u001b[2m\u001b[36m(pid=18592)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=18592)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18592)\u001b[0m 249 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=18592)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=18592)\u001b[0m 249 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=18592)\u001b[0m 0.997     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=18592)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18592)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18592)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18592)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18592)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18592)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=18592)\u001b[0m {'growth': 'linear', 'n_changepoints': 100, 'changepoints_range': 0.9, 'trend_reg': 0.5, 'yearly_seasonality': False, 'weekly_seasonality': False, 'daily_seasonality': True, 'seasonality_mode': 'multiplicative', 'seasonality_reg': 0.0, 'n_lags': 10, 'd_hidden': 128, 'num_hidden_layers': 16, 'ar_sparsity': 0.3, 'learning_rate': 0.0002219720625190945, 'loss_func': 'Huber', 'normalize': 'soft'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=18595)\u001b[0m INFO - (NP.config.__post_init__) - Trend reg lambda ignored due to no changepoints.\n",
      "\u001b[2m\u001b[36m(pid=18595)\u001b[0m INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=18595)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=18595)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18595)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18595)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18595)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18595)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18595)\u001b[0m   | Name      | Type         | Params\n",
      "\u001b[2m\u001b[36m(pid=18595)\u001b[0m -------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18595)\u001b[0m 0 | ar_net    | ModuleList   | 760   \n",
      "\u001b[2m\u001b[36m(pid=18595)\u001b[0m 1 | loss_func | SmoothL1Loss | 0     \n",
      "\u001b[2m\u001b[36m(pid=18595)\u001b[0m -------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18595)\u001b[0m 761       Trainable params\n",
      "\u001b[2m\u001b[36m(pid=18595)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=18595)\u001b[0m 761       Total params\n",
      "\u001b[2m\u001b[36m(pid=18595)\u001b[0m 0.003     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=18595)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18595)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18595)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18595)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18595)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18595)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=18595)\u001b[0m {'growth': 'off', 'n_changepoints': 100, 'changepoints_range': 0.9, 'trend_reg': 1.0, 'yearly_seasonality': False, 'weekly_seasonality': False, 'daily_seasonality': False, 'seasonality_mode': 'multiplicative', 'seasonality_reg': 0.5, 'n_lags': 30, 'd_hidden': 8, 'num_hidden_layers': 8, 'ar_sparsity': 0.1, 'learning_rate': 0.016032870001225212, 'loss_func': 'Huber', 'normalize': 'minmax'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=18598)\u001b[0m INFO - (NP.config.__post_init__) - Note: Trend changepoint regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=18598)\u001b[0m INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=18598)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=18598)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18598)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18598)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18598)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18598)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18598)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=18598)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18598)\u001b[0m 0 | season_params | ParameterDict | 24    \n",
      "\u001b[2m\u001b[36m(pid=18598)\u001b[0m 1 | ar_net        | ModuleList    | 117 K \n",
      "\u001b[2m\u001b[36m(pid=18598)\u001b[0m 2 | loss_func     | MSELoss       | 0     \n",
      "\u001b[2m\u001b[36m(pid=18598)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18598)\u001b[0m 117 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=18598)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=18598)\u001b[0m 117 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=18598)\u001b[0m 0.469     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=18598)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18598)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18598)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18598)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18598)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18598)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=18598)\u001b[0m {'growth': 'linear', 'n_changepoints': 10, 'changepoints_range': 0.8, 'trend_reg': 1.0, 'yearly_seasonality': True, 'weekly_seasonality': False, 'daily_seasonality': True, 'seasonality_mode': 'additive', 'seasonality_reg': 0.5, 'n_lags': 10, 'd_hidden': 128, 'num_hidden_layers': 8, 'ar_sparsity': 0.1, 'learning_rate': 0.006094326298450639, 'loss_func': 'MSE', 'normalize': 'auto'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=18603)\u001b[0m INFO - (NP.config.__post_init__) - Trend reg lambda ignored due to no changepoints.\n",
      "\u001b[2m\u001b[36m(pid=18603)\u001b[0m INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=18603)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=18603)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18603)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18603)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18603)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18603)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18603)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=18603)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18603)\u001b[0m 0 | season_params | ParameterDict | 6     \n",
      "\u001b[2m\u001b[36m(pid=18603)\u001b[0m 1 | ar_net        | ModuleList    | 251 K \n",
      "\u001b[2m\u001b[36m(pid=18603)\u001b[0m 2 | loss_func     | MSELoss       | 0     \n",
      "\u001b[2m\u001b[36m(pid=18603)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18603)\u001b[0m 251 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=18603)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=18603)\u001b[0m 251 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=18603)\u001b[0m 1.007     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=18603)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18603)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18603)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18603)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18603)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18603)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=18603)\u001b[0m {'growth': 'off', 'n_changepoints': 10, 'changepoints_range': 0.8, 'trend_reg': 1.0, 'yearly_seasonality': False, 'weekly_seasonality': True, 'daily_seasonality': False, 'seasonality_mode': 'additive', 'seasonality_reg': 1.0, 'n_lags': 30, 'd_hidden': 128, 'num_hidden_layers': 16, 'ar_sparsity': 0.3, 'learning_rate': 0.05514465316195616, 'loss_func': 'MSE', 'normalize': 'minmax'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=18607)\u001b[0m INFO - (NP.config.__post_init__) - Note: Trend changepoint regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=18607)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=18607)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18607)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18607)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18607)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18607)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18607)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=18607)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18607)\u001b[0m 0 | season_params | ParameterDict | 24    \n",
      "\u001b[2m\u001b[36m(pid=18607)\u001b[0m 1 | ar_net        | ModuleList    | 64.4 K\n",
      "\u001b[2m\u001b[36m(pid=18607)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=18607)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18607)\u001b[0m 64.5 K    Trainable params\n",
      "\u001b[2m\u001b[36m(pid=18607)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=18607)\u001b[0m 64.5 K    Total params\n",
      "\u001b[2m\u001b[36m(pid=18607)\u001b[0m 0.258     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=18607)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18607)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18607)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18607)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18607)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18607)\u001b[0m \n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=18607)\u001b[0m {'growth': 'linear', 'n_changepoints': 5, 'changepoints_range': 0.5, 'trend_reg': 1.0, 'yearly_seasonality': True, 'weekly_seasonality': False, 'daily_seasonality': True, 'seasonality_mode': 'multiplicative', 'seasonality_reg': 0.0, 'n_lags': 30, 'd_hidden': 64, 'num_hidden_layers': 16, 'ar_sparsity': 0.3, 'learning_rate': 0.0039365203396605035, 'loss_func': 'Huber', 'normalize': 'soft'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=18613)\u001b[0m INFO - (NP.config.__post_init__) - Note: Trend changepoint regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=18613)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=18613)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18613)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18613)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18613)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[36m(pid=18613)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18613)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=18613)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18613)\u001b[0m 0 | season_params | ParameterDict | 24    \n",
      "\u001b[2m\u001b[36m(pid=18613)\u001b[0m 1 | ar_net        | ModuleList    | 251 K \n",
      "\u001b[2m\u001b[36m(pid=18613)\u001b[0m 2 | loss_func     | MSELoss       | 0     \n",
      "\u001b[2m\u001b[36m(pid=18613)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18613)\u001b[0m 251 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=18613)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=18613)\u001b[0m 251 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=18613)\u001b[0m 1.007     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=18613)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18613)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18613)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18613)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18613)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18613)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=18613)\u001b[0m {'growth': 'linear', 'n_changepoints': 5, 'changepoints_range': 0.9, 'trend_reg': 1.0, 'yearly_seasonality': True, 'weekly_seasonality': False, 'daily_seasonality': True, 'seasonality_mode': 'additive', 'seasonality_reg': 0.0, 'n_lags': 30, 'd_hidden': 128, 'num_hidden_layers': 16, 'ar_sparsity': 0.3, 'learning_rate': 0.0731075357109261, 'loss_func': 'MSE', 'normalize': 'off'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=18616)\u001b[0m INFO - (NP.config.__post_init__) - Note: Trend changepoint regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=18616)\u001b[0m INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=18616)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=18616)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18616)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18616)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18616)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18616)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18616)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=18616)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18616)\u001b[0m 0 | season_params | ParameterDict | 12    \n",
      "\u001b[2m\u001b[36m(pid=18616)\u001b[0m 1 | ar_net        | ModuleList    | 260 K \n",
      "\u001b[2m\u001b[36m(pid=18616)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=18616)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18616)\u001b[0m 260 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=18616)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=18616)\u001b[0m 260 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=18616)\u001b[0m 1.043     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=18616)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18616)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18616)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18616)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18616)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18616)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=18616)\u001b[0m {'growth': 'linear', 'n_changepoints': 100, 'changepoints_range': 0.9, 'trend_reg': 10.0, 'yearly_seasonality': True, 'weekly_seasonality': False, 'daily_seasonality': False, 'seasonality_mode': 'multiplicative', 'seasonality_reg': 10.0, 'n_lags': 100, 'd_hidden': 128, 'num_hidden_layers': 16, 'ar_sparsity': 0.1, 'learning_rate': 0.000971807400452209, 'loss_func': 'Huber', 'normalize': 'off'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[36m(pid=18619)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=18619)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18619)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18619)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18619)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18619)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18619)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=18619)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18619)\u001b[0m 0 | season_params | ParameterDict | 24    \n",
      "\u001b[2m\u001b[36m(pid=18619)\u001b[0m 1 | ar_net        | ModuleList    | 29.9 K\n",
      "\u001b[2m\u001b[36m(pid=18619)\u001b[0m 2 | loss_func     | MSELoss       | 0     \n",
      "\u001b[2m\u001b[36m(pid=18619)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18619)\u001b[0m 29.9 K    Trainable params\n",
      "\u001b[2m\u001b[36m(pid=18619)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=18619)\u001b[0m 29.9 K    Total params\n",
      "\u001b[2m\u001b[36m(pid=18619)\u001b[0m 0.120     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=18619)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18619)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18619)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18619)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18619)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18619)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=18619)\u001b[0m {'growth': 'off', 'n_changepoints': 10, 'changepoints_range': 0.9, 'trend_reg': 0.0, 'yearly_seasonality': True, 'weekly_seasonality': False, 'daily_seasonality': True, 'seasonality_mode': 'multiplicative', 'seasonality_reg': 0.0, 'n_lags': 10, 'd_hidden': 64, 'num_hidden_layers': 8, 'ar_sparsity': 0.1, 'learning_rate': 0.00020215225434823509, 'loss_func': 'MSE', 'normalize': 'standardize'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=18623)\u001b[0m INFO - (NP.config.__post_init__) - Trend reg lambda ignored due to no changepoints.\n",
      "\u001b[2m\u001b[36m(pid=18623)\u001b[0m INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=18623)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=18623)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18623)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18623)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18623)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18623)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18623)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=18623)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18623)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=18623)\u001b[0m 1 | ar_net        | ModuleList    | 29.9 K\n",
      "\u001b[2m\u001b[36m(pid=18623)\u001b[0m 2 | loss_func     | MSELoss       | 0     \n",
      "\u001b[2m\u001b[36m(pid=18623)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18623)\u001b[0m 29.9 K    Trainable params\n",
      "\u001b[2m\u001b[36m(pid=18623)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=18623)\u001b[0m 29.9 K    Total params\n",
      "\u001b[2m\u001b[36m(pid=18623)\u001b[0m 0.120     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=18623)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18623)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18623)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18623)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18623)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18623)\u001b[0m \n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=18623)\u001b[0m {'growth': 'off', 'n_changepoints': 100, 'changepoints_range': 0.5, 'trend_reg': 1.0, 'yearly_seasonality': False, 'weekly_seasonality': True, 'daily_seasonality': True, 'seasonality_mode': 'additive', 'seasonality_reg': 0.5, 'n_lags': 10, 'd_hidden': 64, 'num_hidden_layers': 8, 'ar_sparsity': 0.1, 'learning_rate': 0.09152508030082965, 'loss_func': 'MSE', 'normalize': 'soft'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=18626)\u001b[0m INFO - (NP.config.__post_init__) - Note: Trend changepoint regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=18626)\u001b[0m INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=18626)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=18626)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18626)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18626)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18626)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18626)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18626)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=18626)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18626)\u001b[0m 0 | season_params | ParameterDict | 12    \n",
      "\u001b[2m\u001b[36m(pid=18626)\u001b[0m 1 | ar_net        | ModuleList    | 29.9 K\n",
      "\u001b[2m\u001b[36m(pid=18626)\u001b[0m 2 | loss_func     | MSELoss       | 0     \n",
      "\u001b[2m\u001b[36m(pid=18626)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18626)\u001b[0m 29.9 K    Trainable params\n",
      "\u001b[2m\u001b[36m(pid=18626)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=18626)\u001b[0m 29.9 K    Total params\n",
      "\u001b[2m\u001b[36m(pid=18626)\u001b[0m 0.120     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=18626)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18626)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18626)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18626)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18626)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18626)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=18626)\u001b[0m {'growth': 'linear', 'n_changepoints': 5, 'changepoints_range': 0.8, 'trend_reg': 1.0, 'yearly_seasonality': False, 'weekly_seasonality': False, 'daily_seasonality': True, 'seasonality_mode': 'multiplicative', 'seasonality_reg': 10.0, 'n_lags': 10, 'd_hidden': 64, 'num_hidden_layers': 8, 'ar_sparsity': 0.1, 'learning_rate': 0.05373855057442426, 'loss_func': 'MSE', 'normalize': 'soft'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=18630)\u001b[0m INFO - (NP.config.__post_init__) - Note: Trend changepoint regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=18630)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=18630)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18630)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18630)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18630)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18630)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18630)\u001b[0m   | Name      | Type       | Params\n",
      "\u001b[2m\u001b[36m(pid=18630)\u001b[0m -----------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18630)\u001b[0m 0 | ar_net    | ModuleList | 29.6 K\n",
      "\u001b[2m\u001b[36m(pid=18630)\u001b[0m 1 | loss_func | MSELoss    | 0     \n",
      "\u001b[2m\u001b[36m(pid=18630)\u001b[0m -----------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18630)\u001b[0m 29.6 K    Trainable params\n",
      "\u001b[2m\u001b[36m(pid=18630)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=18630)\u001b[0m 29.6 K    Total params\n",
      "\u001b[2m\u001b[36m(pid=18630)\u001b[0m 0.118     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=18630)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18630)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18630)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18630)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18630)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18630)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=18630)\u001b[0m {'growth': 'linear', 'n_changepoints': 10, 'changepoints_range': 0.5, 'trend_reg': 1.0, 'yearly_seasonality': False, 'weekly_seasonality': False, 'daily_seasonality': False, 'seasonality_mode': 'additive', 'seasonality_reg': 0.0, 'n_lags': 100, 'd_hidden': 128, 'num_hidden_layers': 2, 'ar_sparsity': 0.1, 'learning_rate': 0.02031257152084333, 'loss_func': 'MSE', 'normalize': 'auto'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=18649)\u001b[0m INFO - (NP.config.__post_init__) - Note: Trend changepoint regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=18649)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=18649)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18649)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18649)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18649)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[36m(pid=18649)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18649)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=18649)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18649)\u001b[0m 0 | season_params | ParameterDict | 24    \n",
      "\u001b[2m\u001b[36m(pid=18649)\u001b[0m 1 | ar_net        | ModuleList    | 249 K \n",
      "\u001b[2m\u001b[36m(pid=18649)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=18649)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18649)\u001b[0m 249 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=18649)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=18649)\u001b[0m 249 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=18649)\u001b[0m 0.997     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=18649)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18649)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18649)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18649)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18649)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18649)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=18649)\u001b[0m {'growth': 'linear', 'n_changepoints': 5, 'changepoints_range': 0.5, 'trend_reg': 0.5, 'yearly_seasonality': True, 'weekly_seasonality': False, 'daily_seasonality': True, 'seasonality_mode': 'additive', 'seasonality_reg': 0.0, 'n_lags': 10, 'd_hidden': 128, 'num_hidden_layers': 16, 'ar_sparsity': 0.8, 'learning_rate': 0.027112521982611375, 'loss_func': 'Huber', 'normalize': 'standardize'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=18656)\u001b[0m INFO - (NP.config.__post_init__) - Note: Trend changepoint regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=18656)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=18656)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18656)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18656)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18656)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18656)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18656)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=18656)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18656)\u001b[0m 0 | season_params | ParameterDict | 24    \n",
      "\u001b[2m\u001b[36m(pid=18656)\u001b[0m 1 | ar_net        | ModuleList    | 117 K \n",
      "\u001b[2m\u001b[36m(pid=18656)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=18656)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18656)\u001b[0m 117 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=18656)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=18656)\u001b[0m 117 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=18656)\u001b[0m 0.469     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=18656)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18656)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18656)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18656)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18656)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18656)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=18656)\u001b[0m {'growth': 'linear', 'n_changepoints': 100, 'changepoints_range': 0.5, 'trend_reg': 1.0, 'yearly_seasonality': True, 'weekly_seasonality': False, 'daily_seasonality': True, 'seasonality_mode': 'additive', 'seasonality_reg': 0.0, 'n_lags': 10, 'd_hidden': 128, 'num_hidden_layers': 8, 'ar_sparsity': 0.3, 'learning_rate': 0.0036686370732896987, 'loss_func': 'Huber', 'normalize': 'standardize'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "2021-05-10 12:48:11,878\tWARNING util.py:162 -- The `start_trial` operation took 1.069 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=18665)\u001b[0m INFO - (NP.config.__post_init__) - Trend reg lambda ignored due to no changepoints.\n",
      "\u001b[2m\u001b[36m(pid=18665)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=18665)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18665)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18665)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18665)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18665)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18665)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=18665)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18665)\u001b[0m 0 | season_params | ParameterDict | 12    \n",
      "\u001b[2m\u001b[36m(pid=18665)\u001b[0m 1 | ar_net        | ModuleList    | 64.4 K\n",
      "\u001b[2m\u001b[36m(pid=18665)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=18665)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18665)\u001b[0m 64.5 K    Trainable params\n",
      "\u001b[2m\u001b[36m(pid=18665)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=18665)\u001b[0m 64.5 K    Total params\n",
      "\u001b[2m\u001b[36m(pid=18665)\u001b[0m 0.258     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=18665)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18665)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18665)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18665)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18665)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18665)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=18665)\u001b[0m {'growth': 'off', 'n_changepoints': 100, 'changepoints_range': 0.9, 'trend_reg': 1.0, 'yearly_seasonality': True, 'weekly_seasonality': False, 'daily_seasonality': False, 'seasonality_mode': 'additive', 'seasonality_reg': 0.0, 'n_lags': 30, 'd_hidden': 64, 'num_hidden_layers': 16, 'ar_sparsity': 0.1, 'learning_rate': 0.06720819036373527, 'loss_func': 'Huber', 'normalize': 'minmax'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[36m(pid=18669)\u001b[0m INFO - (NP.config.__post_init__) - Trend reg lambda ignored due to no changepoints.\n",
      "\u001b[2m\u001b[36m(pid=18669)\u001b[0m INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=18669)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=18669)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18669)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18669)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18669)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[36m(pid=18669)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18669)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=18669)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18669)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=18669)\u001b[0m 1 | ar_net        | ModuleList    | 249 K \n",
      "\u001b[2m\u001b[36m(pid=18669)\u001b[0m 2 | loss_func     | MSELoss       | 0     \n",
      "\u001b[2m\u001b[36m(pid=18669)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18669)\u001b[0m 249 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=18669)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=18669)\u001b[0m 249 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=18669)\u001b[0m 0.997     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=18669)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18669)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18669)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18669)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18669)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18669)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=18669)\u001b[0m {'growth': 'off', 'n_changepoints': 5, 'changepoints_range': 0.8, 'trend_reg': 0.5, 'yearly_seasonality': False, 'weekly_seasonality': True, 'daily_seasonality': True, 'seasonality_mode': 'additive', 'seasonality_reg': 1.0, 'n_lags': 10, 'd_hidden': 128, 'num_hidden_layers': 16, 'ar_sparsity': 0.1, 'learning_rate': 0.0012877049149735008, 'loss_func': 'MSE', 'normalize': 'off'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-10 12:48:32,244\tWARNING util.py:162 -- The `start_trial` operation took 1.037 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=18679)\u001b[0m INFO - (NP.config.__post_init__) - Trend reg lambda ignored due to no changepoints.\n",
      "\u001b[2m\u001b[36m(pid=18679)\u001b[0m INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=18679)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=18679)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18679)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18679)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18679)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18679)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18679)\u001b[0m   | Name      | Type       | Params\n",
      "\u001b[2m\u001b[36m(pid=18679)\u001b[0m -----------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18679)\u001b[0m 0 | ar_net    | ModuleList | 29.6 K\n",
      "\u001b[2m\u001b[36m(pid=18679)\u001b[0m 1 | loss_func | MSELoss    | 0     \n",
      "\u001b[2m\u001b[36m(pid=18679)\u001b[0m -----------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18679)\u001b[0m 29.6 K    Trainable params\n",
      "\u001b[2m\u001b[36m(pid=18679)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=18679)\u001b[0m 29.6 K    Total params\n",
      "\u001b[2m\u001b[36m(pid=18679)\u001b[0m 0.118     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=18679)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18679)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18679)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18679)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18679)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18679)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=18679)\u001b[0m {'growth': 'off', 'n_changepoints': 100, 'changepoints_range': 0.8, 'trend_reg': 0.5, 'yearly_seasonality': False, 'weekly_seasonality': False, 'daily_seasonality': False, 'seasonality_mode': 'additive', 'seasonality_reg': 1.0, 'n_lags': 100, 'd_hidden': 128, 'num_hidden_layers': 2, 'ar_sparsity': 0.1, 'learning_rate': 0.0001781762254641946, 'loss_func': 'MSE', 'normalize': 'auto'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=18683)\u001b[0m INFO - (NP.config.__post_init__) - Note: Trend changepoint regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=18683)\u001b[0m INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=18683)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=18683)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18683)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18683)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18683)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18683)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18683)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=18683)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18683)\u001b[0m 0 | season_params | ParameterDict | 6     \n",
      "\u001b[2m\u001b[36m(pid=18683)\u001b[0m 1 | ar_net        | ModuleList    | 888   \n",
      "\u001b[2m\u001b[36m(pid=18683)\u001b[0m 2 | loss_func     | MSELoss       | 0     \n",
      "\u001b[2m\u001b[36m(pid=18683)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18683)\u001b[0m 997       Trainable params\n",
      "\u001b[2m\u001b[36m(pid=18683)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=18683)\u001b[0m 997       Total params\n",
      "\u001b[2m\u001b[36m(pid=18683)\u001b[0m 0.004     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=18683)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18683)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18683)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18683)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18683)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18683)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=18683)\u001b[0m {'growth': 'linear', 'n_changepoints': 100, 'changepoints_range': 0.5, 'trend_reg': 0.5, 'yearly_seasonality': False, 'weekly_seasonality': True, 'daily_seasonality': False, 'seasonality_mode': 'additive', 'seasonality_reg': 0.5, 'n_lags': 100, 'd_hidden': 8, 'num_hidden_layers': 2, 'ar_sparsity': 0.3, 'learning_rate': 0.001631574401107655, 'loss_func': 'MSE', 'normalize': 'minmax'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[36m(pid=18686)\u001b[0m INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=18686)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=18686)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18686)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18686)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18686)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18686)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18686)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=18686)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18686)\u001b[0m 0 | season_params | ParameterDict | 30    \n",
      "\u001b[2m\u001b[36m(pid=18686)\u001b[0m 1 | ar_net        | ModuleList    | 10.7 K\n",
      "\u001b[2m\u001b[36m(pid=18686)\u001b[0m 2 | loss_func     | MSELoss       | 0     \n",
      "\u001b[2m\u001b[36m(pid=18686)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18686)\u001b[0m 10.7 K    Trainable params\n",
      "\u001b[2m\u001b[36m(pid=18686)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=18686)\u001b[0m 10.7 K    Total params\n",
      "\u001b[2m\u001b[36m(pid=18686)\u001b[0m 0.043     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=18686)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18686)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18686)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18686)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18686)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18686)\u001b[0m \n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=18686)\u001b[0m {'growth': 'linear', 'n_changepoints': 5, 'changepoints_range': 0.8, 'trend_reg': 0.0, 'yearly_seasonality': True, 'weekly_seasonality': True, 'daily_seasonality': True, 'seasonality_mode': 'additive', 'seasonality_reg': 10.0, 'n_lags': 100, 'd_hidden': 64, 'num_hidden_layers': 2, 'ar_sparsity': 0.8, 'learning_rate': 0.018781676862947815, 'loss_func': 'MSE', 'normalize': 'auto'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=18695)\u001b[0m INFO - (NP.config.__post_init__) - Trend reg lambda ignored due to no changepoints.\n",
      "\u001b[2m\u001b[36m(pid=18695)\u001b[0m INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=18695)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=18695)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18695)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18695)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18695)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18695)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18695)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=18695)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18695)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=18695)\u001b[0m 1 | ar_net        | ModuleList    | 6.2 K \n",
      "\u001b[2m\u001b[36m(pid=18695)\u001b[0m 2 | loss_func     | MSELoss       | 0     \n",
      "\u001b[2m\u001b[36m(pid=18695)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18695)\u001b[0m 6.2 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=18695)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=18695)\u001b[0m 6.2 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=18695)\u001b[0m 0.025     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=18695)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18695)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18695)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18695)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18695)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18695)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=18695)\u001b[0m {'growth': 'off', 'n_changepoints': 100, 'changepoints_range': 0.9, 'trend_reg': 0.5, 'yearly_seasonality': True, 'weekly_seasonality': True, 'daily_seasonality': False, 'seasonality_mode': 'multiplicative', 'seasonality_reg': 0.5, 'n_lags': 30, 'd_hidden': 64, 'num_hidden_layers': 2, 'ar_sparsity': 0.3, 'learning_rate': 0.0021617056005691173, 'loss_func': 'MSE', 'normalize': 'off'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=18698)\u001b[0m INFO - (NP.config.__post_init__) - Note: Trend changepoint regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=18698)\u001b[0m INFO - (NP.config.__post_init__) - Note: Fourier-based seasonality regularization is experimental.\n",
      "\u001b[2m\u001b[36m(pid=18698)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=18698)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18698)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18698)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=18698)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=18698)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18698)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=18698)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18698)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=18698)\u001b[0m 1 | ar_net        | ModuleList    | 20.6 K\n",
      "\u001b[2m\u001b[36m(pid=18698)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=18698)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=18698)\u001b[0m 20.6 K    Trainable params\n",
      "\u001b[2m\u001b[36m(pid=18698)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=18698)\u001b[0m 20.6 K    Total params\n",
      "\u001b[2m\u001b[36m(pid=18698)\u001b[0m 0.083     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=18698)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18698)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18698)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=18698)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=18698)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=18698)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=18698)\u001b[0m {'growth': 'linear', 'n_changepoints': 5, 'changepoints_range': 0.8, 'trend_reg': 10.0, 'yearly_seasonality': True, 'weekly_seasonality': True, 'daily_seasonality': False, 'seasonality_mode': 'multiplicative', 'seasonality_reg': 0.5, 'n_lags': 30, 'd_hidden': 128, 'num_hidden_layers': 2, 'ar_sparsity': 0.3, 'learning_rate': 0.023518041055053677, 'loss_func': 'Huber', 'normalize': 'standardize'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters found were:  {'growth': 'off', 'n_changepoints': 100, 'changepoints_range': 0.9, 'trend_reg': 1.0, 'yearly_seasonality': False, 'weekly_seasonality': False, 'daily_seasonality': False, 'seasonality_mode': 'multiplicative', 'seasonality_reg': 0.5, 'n_lags': 30, 'd_hidden': 8, 'num_hidden_layers': 8, 'ar_sparsity': 0.1, 'learning_rate': 0.016032870001225212, 'loss_func': 'Huber', 'normalize': 'minmax'}\n"
     ]
    }
   ],
   "source": [
    "freq = '5min'\n",
    "best_params, results_df = tune_hyperparameters('NP',\n",
    "                                               df,\n",
    "                                               freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function by default outputs the dictionary of best hyperparameters chosen. It additionally will output the dataframe with detailed result of each trial if return_results is set to True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>config.growth</th>\n",
       "      <th>config.n_changepoints</th>\n",
       "      <th>config.changepoints_range</th>\n",
       "      <th>config.trend_reg</th>\n",
       "      <th>config.yearly_seasonality</th>\n",
       "      <th>config.weekly_seasonality</th>\n",
       "      <th>config.daily_seasonality</th>\n",
       "      <th>config.seasonality_mode</th>\n",
       "      <th>config.seasonality_reg</th>\n",
       "      <th>config.n_lags</th>\n",
       "      <th>config.d_hidden</th>\n",
       "      <th>config.num_hidden_layers</th>\n",
       "      <th>config.ar_sparsity</th>\n",
       "      <th>config.learning_rate</th>\n",
       "      <th>config.loss_func</th>\n",
       "      <th>config.normalize</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trial_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ecf09_00001</th>\n",
       "      <td>linear</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>additive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000340</td>\n",
       "      <td>Huber</td>\n",
       "      <td>auto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ecf09_00002</th>\n",
       "      <td>off</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>multiplicative</td>\n",
       "      <td>0.5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.004222</td>\n",
       "      <td>MSE</td>\n",
       "      <td>off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ecf09_00003</th>\n",
       "      <td>linear</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>10.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>additive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.001155</td>\n",
       "      <td>MSE</td>\n",
       "      <td>off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ecf09_00007</th>\n",
       "      <td>linear</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>additive</td>\n",
       "      <td>10.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.098468</td>\n",
       "      <td>Huber</td>\n",
       "      <td>standardize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ecf09_00008</th>\n",
       "      <td>linear</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>additive</td>\n",
       "      <td>10.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.031956</td>\n",
       "      <td>MSE</td>\n",
       "      <td>auto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ecf09_00009</th>\n",
       "      <td>off</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>multiplicative</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>MSE</td>\n",
       "      <td>standardize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ecf09_00010</th>\n",
       "      <td>off</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>multiplicative</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>MSE</td>\n",
       "      <td>auto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ecf09_00012</th>\n",
       "      <td>linear</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>additive</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.012236</td>\n",
       "      <td>MSE</td>\n",
       "      <td>soft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ecf09_00014</th>\n",
       "      <td>linear</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>additive</td>\n",
       "      <td>0.5</td>\n",
       "      <td>30.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>MSE</td>\n",
       "      <td>auto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ecf09_00015</th>\n",
       "      <td>linear</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>multiplicative</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.001121</td>\n",
       "      <td>Huber</td>\n",
       "      <td>standardize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ecf09_00016</th>\n",
       "      <td>linear</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>10.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>additive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>Huber</td>\n",
       "      <td>soft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ecf09_00020</th>\n",
       "      <td>linear</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>additive</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>MSE</td>\n",
       "      <td>standardize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ecf09_00021</th>\n",
       "      <td>linear</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>additive</td>\n",
       "      <td>0.5</td>\n",
       "      <td>30.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>MSE</td>\n",
       "      <td>off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ecf09_00022</th>\n",
       "      <td>linear</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>additive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.001990</td>\n",
       "      <td>Huber</td>\n",
       "      <td>auto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ecf09_00024</th>\n",
       "      <td>off</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>multiplicative</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.001992</td>\n",
       "      <td>Huber</td>\n",
       "      <td>auto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ecf09_00025</th>\n",
       "      <td>off</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>additive</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.056184</td>\n",
       "      <td>Huber</td>\n",
       "      <td>auto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ecf09_00026</th>\n",
       "      <td>off</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>additive</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.014842</td>\n",
       "      <td>MSE</td>\n",
       "      <td>standardize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ecf09_00029</th>\n",
       "      <td>linear</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>additive</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.067508</td>\n",
       "      <td>MSE</td>\n",
       "      <td>soft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ecf09_00030</th>\n",
       "      <td>linear</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>multiplicative</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>Huber</td>\n",
       "      <td>auto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ecf09_00034</th>\n",
       "      <td>off</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>multiplicative</td>\n",
       "      <td>0.5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.027429</td>\n",
       "      <td>Huber</td>\n",
       "      <td>minmax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ecf09_00036</th>\n",
       "      <td>linear</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>additive</td>\n",
       "      <td>10.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.004639</td>\n",
       "      <td>MSE</td>\n",
       "      <td>standardize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ecf09_00037</th>\n",
       "      <td>linear</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>multiplicative</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>Huber</td>\n",
       "      <td>auto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            config.growth  config.n_changepoints  config.changepoints_range  \\\n",
       "trial_id                                                                      \n",
       "NaN                   NaN                    NaN                        NaN   \n",
       "ecf09_00001        linear                   10.0                        0.9   \n",
       "ecf09_00002           off                    5.0                        0.8   \n",
       "ecf09_00003        linear                   10.0                        0.8   \n",
       "NaN                   NaN                    NaN                        NaN   \n",
       "NaN                   NaN                    NaN                        NaN   \n",
       "NaN                   NaN                    NaN                        NaN   \n",
       "ecf09_00007        linear                    5.0                        0.8   \n",
       "ecf09_00008        linear                   10.0                        0.5   \n",
       "ecf09_00009           off                    5.0                        0.5   \n",
       "ecf09_00010           off                  100.0                        0.8   \n",
       "NaN                   NaN                    NaN                        NaN   \n",
       "ecf09_00012        linear                  100.0                        0.9   \n",
       "NaN                   NaN                    NaN                        NaN   \n",
       "ecf09_00014        linear                  100.0                        0.9   \n",
       "ecf09_00015        linear                   10.0                        0.9   \n",
       "ecf09_00016        linear                    5.0                        0.8   \n",
       "NaN                   NaN                    NaN                        NaN   \n",
       "NaN                   NaN                    NaN                        NaN   \n",
       "NaN                   NaN                    NaN                        NaN   \n",
       "ecf09_00020        linear                   10.0                        0.5   \n",
       "ecf09_00021        linear                    5.0                        0.5   \n",
       "ecf09_00022        linear                   10.0                        0.8   \n",
       "NaN                   NaN                    NaN                        NaN   \n",
       "ecf09_00024           off                  100.0                        0.9   \n",
       "ecf09_00025           off                    5.0                        0.9   \n",
       "ecf09_00026           off                  100.0                        0.5   \n",
       "NaN                   NaN                    NaN                        NaN   \n",
       "NaN                   NaN                    NaN                        NaN   \n",
       "ecf09_00029        linear                   10.0                        0.5   \n",
       "ecf09_00030        linear                    5.0                        0.5   \n",
       "NaN                   NaN                    NaN                        NaN   \n",
       "NaN                   NaN                    NaN                        NaN   \n",
       "NaN                   NaN                    NaN                        NaN   \n",
       "ecf09_00034           off                    5.0                        0.8   \n",
       "NaN                   NaN                    NaN                        NaN   \n",
       "ecf09_00036        linear                    5.0                        0.9   \n",
       "ecf09_00037        linear                  100.0                        0.9   \n",
       "NaN                   NaN                    NaN                        NaN   \n",
       "NaN                   NaN                    NaN                        NaN   \n",
       "\n",
       "             config.trend_reg config.yearly_seasonality  \\\n",
       "trial_id                                                  \n",
       "NaN                       NaN                       NaN   \n",
       "ecf09_00001               0.5                      True   \n",
       "ecf09_00002               0.0                     False   \n",
       "ecf09_00003              10.0                     False   \n",
       "NaN                       NaN                       NaN   \n",
       "NaN                       NaN                       NaN   \n",
       "NaN                       NaN                       NaN   \n",
       "ecf09_00007               0.5                      True   \n",
       "ecf09_00008               0.0                      True   \n",
       "ecf09_00009               0.0                     False   \n",
       "ecf09_00010               0.0                     False   \n",
       "NaN                       NaN                       NaN   \n",
       "ecf09_00012               1.0                     False   \n",
       "NaN                       NaN                       NaN   \n",
       "ecf09_00014              10.0                      True   \n",
       "ecf09_00015              10.0                      True   \n",
       "ecf09_00016              10.0                     False   \n",
       "NaN                       NaN                       NaN   \n",
       "NaN                       NaN                       NaN   \n",
       "NaN                       NaN                       NaN   \n",
       "ecf09_00020              10.0                     False   \n",
       "ecf09_00021               0.5                      True   \n",
       "ecf09_00022              10.0                      True   \n",
       "NaN                       NaN                       NaN   \n",
       "ecf09_00024               0.0                     False   \n",
       "ecf09_00025               0.0                     False   \n",
       "ecf09_00026               0.0                      True   \n",
       "NaN                       NaN                       NaN   \n",
       "NaN                       NaN                       NaN   \n",
       "ecf09_00029               1.0                     False   \n",
       "ecf09_00030               0.0                     False   \n",
       "NaN                       NaN                       NaN   \n",
       "NaN                       NaN                       NaN   \n",
       "NaN                       NaN                       NaN   \n",
       "ecf09_00034               0.0                      True   \n",
       "NaN                       NaN                       NaN   \n",
       "ecf09_00036               1.0                      True   \n",
       "ecf09_00037              10.0                     False   \n",
       "NaN                       NaN                       NaN   \n",
       "NaN                       NaN                       NaN   \n",
       "\n",
       "            config.weekly_seasonality config.daily_seasonality  \\\n",
       "trial_id                                                         \n",
       "NaN                               NaN                      NaN   \n",
       "ecf09_00001                      True                     True   \n",
       "ecf09_00002                     False                    False   \n",
       "ecf09_00003                      True                     True   \n",
       "NaN                               NaN                      NaN   \n",
       "NaN                               NaN                      NaN   \n",
       "NaN                               NaN                      NaN   \n",
       "ecf09_00007                     False                     True   \n",
       "ecf09_00008                     False                     True   \n",
       "ecf09_00009                     False                     True   \n",
       "ecf09_00010                      True                    False   \n",
       "NaN                               NaN                      NaN   \n",
       "ecf09_00012                     False                    False   \n",
       "NaN                               NaN                      NaN   \n",
       "ecf09_00014                     False                     True   \n",
       "ecf09_00015                      True                    False   \n",
       "ecf09_00016                      True                     True   \n",
       "NaN                               NaN                      NaN   \n",
       "NaN                               NaN                      NaN   \n",
       "NaN                               NaN                      NaN   \n",
       "ecf09_00020                     False                     True   \n",
       "ecf09_00021                     False                    False   \n",
       "ecf09_00022                      True                     True   \n",
       "NaN                               NaN                      NaN   \n",
       "ecf09_00024                     False                     True   \n",
       "ecf09_00025                     False                    False   \n",
       "ecf09_00026                     False                     True   \n",
       "NaN                               NaN                      NaN   \n",
       "NaN                               NaN                      NaN   \n",
       "ecf09_00029                     False                    False   \n",
       "ecf09_00030                      True                     True   \n",
       "NaN                               NaN                      NaN   \n",
       "NaN                               NaN                      NaN   \n",
       "NaN                               NaN                      NaN   \n",
       "ecf09_00034                     False                    False   \n",
       "NaN                               NaN                      NaN   \n",
       "ecf09_00036                      True                     True   \n",
       "ecf09_00037                      True                    False   \n",
       "NaN                               NaN                      NaN   \n",
       "NaN                               NaN                      NaN   \n",
       "\n",
       "            config.seasonality_mode  config.seasonality_reg  config.n_lags  \\\n",
       "trial_id                                                                     \n",
       "NaN                             NaN                     NaN            NaN   \n",
       "ecf09_00001                additive                     0.0           10.0   \n",
       "ecf09_00002          multiplicative                     0.5          100.0   \n",
       "ecf09_00003                additive                     0.0          100.0   \n",
       "NaN                             NaN                     NaN            NaN   \n",
       "NaN                             NaN                     NaN            NaN   \n",
       "NaN                             NaN                     NaN            NaN   \n",
       "ecf09_00007                additive                    10.0           30.0   \n",
       "ecf09_00008                additive                    10.0           30.0   \n",
       "ecf09_00009          multiplicative                     1.0          100.0   \n",
       "ecf09_00010          multiplicative                     0.0           10.0   \n",
       "NaN                             NaN                     NaN            NaN   \n",
       "ecf09_00012                additive                     1.0           10.0   \n",
       "NaN                             NaN                     NaN            NaN   \n",
       "ecf09_00014                additive                     0.5           30.0   \n",
       "ecf09_00015          multiplicative                     0.0          100.0   \n",
       "ecf09_00016                additive                     0.0          100.0   \n",
       "NaN                             NaN                     NaN            NaN   \n",
       "NaN                             NaN                     NaN            NaN   \n",
       "NaN                             NaN                     NaN            NaN   \n",
       "ecf09_00020                additive                    10.0           10.0   \n",
       "ecf09_00021                additive                     0.5           30.0   \n",
       "ecf09_00022                additive                     0.0           30.0   \n",
       "NaN                             NaN                     NaN            NaN   \n",
       "ecf09_00024          multiplicative                     1.0           10.0   \n",
       "ecf09_00025                additive                    10.0          100.0   \n",
       "ecf09_00026                additive                     1.0          100.0   \n",
       "NaN                             NaN                     NaN            NaN   \n",
       "NaN                             NaN                     NaN            NaN   \n",
       "ecf09_00029                additive                    10.0           10.0   \n",
       "ecf09_00030          multiplicative                     1.0           10.0   \n",
       "NaN                             NaN                     NaN            NaN   \n",
       "NaN                             NaN                     NaN            NaN   \n",
       "NaN                             NaN                     NaN            NaN   \n",
       "ecf09_00034          multiplicative                     0.5          100.0   \n",
       "NaN                             NaN                     NaN            NaN   \n",
       "ecf09_00036                additive                    10.0           30.0   \n",
       "ecf09_00037          multiplicative                     0.5           10.0   \n",
       "NaN                             NaN                     NaN            NaN   \n",
       "NaN                             NaN                     NaN            NaN   \n",
       "\n",
       "             config.d_hidden  config.num_hidden_layers  config.ar_sparsity  \\\n",
       "trial_id                                                                     \n",
       "NaN                      NaN                       NaN                 NaN   \n",
       "ecf09_00001            128.0                      16.0                 0.1   \n",
       "ecf09_00002            128.0                       8.0                 0.3   \n",
       "ecf09_00003             64.0                       8.0                 0.3   \n",
       "NaN                      NaN                       NaN                 NaN   \n",
       "NaN                      NaN                       NaN                 NaN   \n",
       "NaN                      NaN                       NaN                 NaN   \n",
       "ecf09_00007              8.0                      16.0                 0.3   \n",
       "ecf09_00008              8.0                       8.0                 0.8   \n",
       "ecf09_00009            128.0                       2.0                 0.8   \n",
       "ecf09_00010             64.0                       2.0                 0.8   \n",
       "NaN                      NaN                       NaN                 NaN   \n",
       "ecf09_00012             64.0                      16.0                 0.3   \n",
       "NaN                      NaN                       NaN                 NaN   \n",
       "ecf09_00014             64.0                      16.0                 0.1   \n",
       "ecf09_00015            128.0                       8.0                 0.1   \n",
       "ecf09_00016            128.0                       8.0                 0.3   \n",
       "NaN                      NaN                       NaN                 NaN   \n",
       "NaN                      NaN                       NaN                 NaN   \n",
       "NaN                      NaN                       NaN                 NaN   \n",
       "ecf09_00020              8.0                       2.0                 0.3   \n",
       "ecf09_00021              8.0                       8.0                 0.1   \n",
       "ecf09_00022             64.0                       8.0                 0.8   \n",
       "NaN                      NaN                       NaN                 NaN   \n",
       "ecf09_00024             64.0                      16.0                 0.8   \n",
       "ecf09_00025              8.0                      16.0                 0.8   \n",
       "ecf09_00026            128.0                       2.0                 0.1   \n",
       "NaN                      NaN                       NaN                 NaN   \n",
       "NaN                      NaN                       NaN                 NaN   \n",
       "ecf09_00029             64.0                       8.0                 0.1   \n",
       "ecf09_00030             64.0                      16.0                 0.1   \n",
       "NaN                      NaN                       NaN                 NaN   \n",
       "NaN                      NaN                       NaN                 NaN   \n",
       "NaN                      NaN                       NaN                 NaN   \n",
       "ecf09_00034             64.0                       2.0                 0.3   \n",
       "NaN                      NaN                       NaN                 NaN   \n",
       "ecf09_00036              8.0                      16.0                 0.8   \n",
       "ecf09_00037             64.0                      16.0                 0.1   \n",
       "NaN                      NaN                       NaN                 NaN   \n",
       "NaN                      NaN                       NaN                 NaN   \n",
       "\n",
       "             config.learning_rate config.loss_func config.normalize  \n",
       "trial_id                                                             \n",
       "NaN                           NaN              NaN              NaN  \n",
       "ecf09_00001              0.000340            Huber             auto  \n",
       "ecf09_00002              0.004222              MSE              off  \n",
       "ecf09_00003              0.001155              MSE              off  \n",
       "NaN                           NaN              NaN              NaN  \n",
       "NaN                           NaN              NaN              NaN  \n",
       "NaN                           NaN              NaN              NaN  \n",
       "ecf09_00007              0.098468            Huber      standardize  \n",
       "ecf09_00008              0.031956              MSE             auto  \n",
       "ecf09_00009              0.000125              MSE      standardize  \n",
       "ecf09_00010              0.000284              MSE             auto  \n",
       "NaN                           NaN              NaN              NaN  \n",
       "ecf09_00012              0.012236              MSE             soft  \n",
       "NaN                           NaN              NaN              NaN  \n",
       "ecf09_00014              0.000179              MSE             auto  \n",
       "ecf09_00015              0.001121            Huber      standardize  \n",
       "ecf09_00016              0.000235            Huber             soft  \n",
       "NaN                           NaN              NaN              NaN  \n",
       "NaN                           NaN              NaN              NaN  \n",
       "NaN                           NaN              NaN              NaN  \n",
       "ecf09_00020              0.000466              MSE      standardize  \n",
       "ecf09_00021              0.000183              MSE              off  \n",
       "ecf09_00022              0.001990            Huber             auto  \n",
       "NaN                           NaN              NaN              NaN  \n",
       "ecf09_00024              0.001992            Huber             auto  \n",
       "ecf09_00025              0.056184            Huber             auto  \n",
       "ecf09_00026              0.014842              MSE      standardize  \n",
       "NaN                           NaN              NaN              NaN  \n",
       "NaN                           NaN              NaN              NaN  \n",
       "ecf09_00029              0.067508              MSE             soft  \n",
       "ecf09_00030              0.000145            Huber             auto  \n",
       "NaN                           NaN              NaN              NaN  \n",
       "NaN                           NaN              NaN              NaN  \n",
       "NaN                           NaN              NaN              NaN  \n",
       "ecf09_00034              0.027429            Huber           minmax  \n",
       "NaN                           NaN              NaN              NaN  \n",
       "ecf09_00036              0.004639              MSE      standardize  \n",
       "ecf09_00037              0.000257            Huber             auto  \n",
       "NaN                           NaN              NaN              NaN  \n",
       "NaN                           NaN              NaN              NaN  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df[['config.growth', 'config.n_changepoints', 'config.changepoints_range',\n",
    "       'config.trend_reg', 'config.yearly_seasonality',\n",
    "       'config.weekly_seasonality', 'config.daily_seasonality',\n",
    "       'config.seasonality_mode', 'config.seasonality_reg', 'config.n_lags',\n",
    "       'config.d_hidden', 'config.num_hidden_layers', 'config.ar_sparsity',\n",
    "       'config.learning_rate', 'config.loss_func', 'config.normalize']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'growth': 'off',\n",
       " 'n_changepoints': 100,\n",
       " 'changepoints_range': 0.8,\n",
       " 'trend_reg': 0.0,\n",
       " 'yearly_seasonality': False,\n",
       " 'weekly_seasonality': False,\n",
       " 'daily_seasonality': False,\n",
       " 'seasonality_mode': 'additive',\n",
       " 'seasonality_reg': 0.5,\n",
       " 'n_lags': 100,\n",
       " 'd_hidden': 8,\n",
       " 'num_hidden_layers': 2,\n",
       " 'ar_sparsity': 0.8,\n",
       " 'learning_rate': 0.010444235692186717,\n",
       " 'loss_func': 'Huber',\n",
       " 'normalize': 'minmax'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dictionary can further be used in initialization of NeuralProphet model.\n",
    "\n",
    "This function has also additional parameters:\n",
    "- **num_epochs**: Max possible number of epochs to train each model.\n",
    "- **num_samples**: Number of samples from hyperparameter spaces to check.\n",
    "- **resources_per_trial**: Resources per trial setting for ray.tune.run, {'cpu': 1, 'gpu': 2} for example\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual mode\n",
    "\n",
    "In case of manual mode, a user must provide a config dictionary with hyperparameter spaces in compatability with Ray Tune api.\n",
    "\n",
    "We provide a minimal example below, for more information on Search Spaces withit this link https://docs.ray.io/en/master/tune/api_docs/search_space.html?highlight=tune.choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import tune\n",
    "\n",
    "config = {'n_lags': tune.grid_search([10, 20, 30]),\n",
    "          'learning_rate': tune.loguniform(1e-4, 1e-1),\n",
    "          'num_hidden_layers': tune.choice([2, 8, 16])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-11 00:14:32,768\tINFO services.py:1269 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
      "2021-05-11 00:14:34,595\tWARNING function_runner.py:545 -- Function checkpointing is disabled. This may result in unexpected behavior when using checkpointing features or certain schedulers. To enable, set the train function arguments to be `func(config, checkpoint_dir=None)`.\n",
      "\u001b[2m\u001b[36m(pid=1261)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1261)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1261)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1261)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1261)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1261)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1261)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1261)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1261)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1261)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1261)\u001b[0m 1 | ar_net        | ModuleList    | 1.1 K \n",
      "\u001b[2m\u001b[36m(pid=1261)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1261)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1261)\u001b[0m 1.1 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1261)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1261)\u001b[0m 1.1 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1261)\u001b[0m 0.004     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1261)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1261)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1261)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1261)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1261)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1261)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1263)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1263)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1263)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1261)\u001b[0m {'n_lags': 10, 'learning_rate': 0.00015556502370375923, 'num_hidden_layers': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1265)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1265)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1265)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "\u001b[2m\u001b[36m(pid=1264)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1267)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1267)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1267)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "\u001b[2m\u001b[36m(pid=1264)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1264)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "\u001b[2m\u001b[36m(pid=1260)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1260)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1260)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "\u001b[2m\u001b[36m(pid=1262)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1262)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1262)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "\u001b[2m\u001b[36m(pid=1266)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1266)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1266)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1265)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1265)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1265)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1263)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1263)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1263)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1263)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1263)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1263)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1263)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1263)\u001b[0m 1 | ar_net        | ModuleList    | 3.7 K \n",
      "\u001b[2m\u001b[36m(pid=1263)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1263)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1263)\u001b[0m 3.7 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1263)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1263)\u001b[0m 3.7 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1263)\u001b[0m 0.015     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1263)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1263)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1263)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1263)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1263)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1263)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1265)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1265)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1265)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1265)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1265)\u001b[0m 1 | ar_net        | ModuleList    | 924   \n",
      "\u001b[2m\u001b[36m(pid=1265)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1265)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1265)\u001b[0m 955       Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1265)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1265)\u001b[0m 955       Total params\n",
      "\u001b[2m\u001b[36m(pid=1265)\u001b[0m 0.004     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1265)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1265)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1265)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1265)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1265)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1265)\u001b[0m \n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1264)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1264)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1264)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1264)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1264)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1264)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1264)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1264)\u001b[0m 1 | ar_net        | ModuleList    | 924   \n",
      "\u001b[2m\u001b[36m(pid=1264)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1264)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1264)\u001b[0m 955       Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1264)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1264)\u001b[0m 955       Total params\n",
      "\u001b[2m\u001b[36m(pid=1264)\u001b[0m 0.004     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1264)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1264)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1264)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1264)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1264)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1264)\u001b[0m \n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1267)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1267)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1267)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1267)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1267)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1267)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1267)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1267)\u001b[0m 1 | ar_net        | ModuleList    | 2.0 K \n",
      "\u001b[2m\u001b[36m(pid=1267)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1267)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1267)\u001b[0m 2.0 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1267)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1267)\u001b[0m 2.0 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1267)\u001b[0m 0.008     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1267)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1267)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1267)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1267)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1267)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1267)\u001b[0m \n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1260)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1260)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1260)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1260)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1260)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1260)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1260)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1260)\u001b[0m 1 | ar_net        | ModuleList    | 7.9 K \n",
      "\u001b[2m\u001b[36m(pid=1260)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1260)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1260)\u001b[0m 8.0 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1260)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1260)\u001b[0m 8.0 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1260)\u001b[0m 0.032     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1260)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1260)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1260)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1260)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1260)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1260)\u001b[0m \n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1262)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1262)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1262)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1262)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1262)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1262)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1262)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1262)\u001b[0m 1 | ar_net        | ModuleList    | 2.1 K \n",
      "\u001b[2m\u001b[36m(pid=1262)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1262)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1262)\u001b[0m 2.1 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1262)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1262)\u001b[0m 2.1 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1262)\u001b[0m 0.009     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1262)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1262)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1262)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1262)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1262)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1262)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1265)\u001b[0m {'n_lags': 20, 'learning_rate': 0.0009797678796626623, 'num_hidden_layers': 2}\n",
      "\u001b[2m\u001b[36m(pid=1260)\u001b[0m {'n_lags': 30, 'learning_rate': 0.02355130060756577, 'num_hidden_layers': 8}\n",
      "\u001b[2m\u001b[36m(pid=1264)\u001b[0m {'n_lags': 20, 'learning_rate': 0.020016476301778063, 'num_hidden_layers': 2}\n",
      "\u001b[2m\u001b[36m(pid=1267)\u001b[0m {'n_lags': 30, 'learning_rate': 0.012420692727338386, 'num_hidden_layers': 2}\n",
      "\u001b[2m\u001b[36m(pid=1263)\u001b[0m {'n_lags': 20, 'learning_rate': 0.0017272300024959082, 'num_hidden_layers': 8}\n",
      "\u001b[2m\u001b[36m(pid=1262)\u001b[0m {'n_lags': 10, 'learning_rate': 0.04563978294862115, 'num_hidden_layers': 16}\n",
      "\u001b[2m\u001b[36m(pid=1266)\u001b[0m {'n_lags': 10, 'learning_rate': 0.038388510686423835, 'num_hidden_layers': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1266)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1266)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1266)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1266)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1266)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1266)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1266)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1266)\u001b[0m 1 | ar_net        | ModuleList    | 1.1 K \n",
      "\u001b[2m\u001b[36m(pid=1266)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1266)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1266)\u001b[0m 1.1 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1266)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1266)\u001b[0m 1.1 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1266)\u001b[0m 0.004     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1266)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1266)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1266)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1266)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1266)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1266)\u001b[0m \n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=1302)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1302)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1302)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1302)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1302)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1302)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1302)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1302)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1302)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1302)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1302)\u001b[0m 1 | ar_net        | ModuleList    | 1.1 K \n",
      "\u001b[2m\u001b[36m(pid=1302)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1302)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1302)\u001b[0m 1.1 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1302)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1302)\u001b[0m 1.1 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1302)\u001b[0m 0.004     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1302)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1302)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1302)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1302)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1302)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1302)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1302)\u001b[0m {'n_lags': 10, 'learning_rate': 0.05796961053401701, 'num_hidden_layers': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[36m(pid=1303)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1303)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1303)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1303)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1303)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1303)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1303)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1303)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1303)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1303)\u001b[0m 1 | ar_net        | ModuleList    | 7.9 K \n",
      "\u001b[2m\u001b[36m(pid=1303)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1303)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1303)\u001b[0m 8.0 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1303)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1303)\u001b[0m 8.0 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1303)\u001b[0m 0.032     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1303)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1303)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1303)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1303)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1303)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1303)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1303)\u001b[0m {'n_lags': 30, 'learning_rate': 0.00033667456628150397, 'num_hidden_layers': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=1319)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1319)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1319)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1319)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1319)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1319)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1319)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1319)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1319)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1319)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1319)\u001b[0m 1 | ar_net        | ModuleList    | 7.4 K \n",
      "\u001b[2m\u001b[36m(pid=1319)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1319)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1319)\u001b[0m 7.4 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1319)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1319)\u001b[0m 7.4 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1319)\u001b[0m 0.030     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1319)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1319)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1319)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1319)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1319)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1319)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1319)\u001b[0m {'n_lags': 20, 'learning_rate': 0.00021808328677797788, 'num_hidden_layers': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=1325)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1325)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1325)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1325)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1325)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1325)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1325)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1325)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1325)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1325)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1325)\u001b[0m 1 | ar_net        | ModuleList    | 7.9 K \n",
      "\u001b[2m\u001b[36m(pid=1325)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1325)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1325)\u001b[0m 8.0 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1325)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1325)\u001b[0m 8.0 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1325)\u001b[0m 0.032     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1325)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1325)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1325)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1325)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1325)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1325)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1325)\u001b[0m {'n_lags': 30, 'learning_rate': 0.010756660110007669, 'num_hidden_layers': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=1328)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1328)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1328)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1328)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1328)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1328)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1328)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1328)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1328)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1328)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1328)\u001b[0m 1 | ar_net        | ModuleList    | 1.1 K \n",
      "\u001b[2m\u001b[36m(pid=1328)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1328)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1328)\u001b[0m 1.1 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1328)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1328)\u001b[0m 1.1 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1328)\u001b[0m 0.004     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1328)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1328)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1328)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1328)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1328)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1328)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1328)\u001b[0m {'n_lags': 10, 'learning_rate': 0.0012924758642068991, 'num_hidden_layers': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=1331)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1331)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1331)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1331)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1331)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1331)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1331)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1331)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1331)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1331)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1331)\u001b[0m 1 | ar_net        | ModuleList    | 924   \n",
      "\u001b[2m\u001b[36m(pid=1331)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1331)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1331)\u001b[0m 955       Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1331)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1331)\u001b[0m 955       Total params\n",
      "\u001b[2m\u001b[36m(pid=1331)\u001b[0m 0.004     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1331)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1331)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1331)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1331)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1331)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1331)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1331)\u001b[0m {'n_lags': 20, 'learning_rate': 0.05500438649913678, 'num_hidden_layers': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=1337)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1337)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1337)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1337)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1337)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1337)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1337)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1337)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1337)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1337)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1337)\u001b[0m 1 | ar_net        | ModuleList    | 2.1 K \n",
      "\u001b[2m\u001b[36m(pid=1337)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1337)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1337)\u001b[0m 2.1 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1337)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1337)\u001b[0m 2.1 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1337)\u001b[0m 0.009     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1337)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1337)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1337)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1337)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1337)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1337)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1337)\u001b[0m {'n_lags': 10, 'learning_rate': 0.0033669160648954893, 'num_hidden_layers': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[36m(pid=1342)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1342)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1342)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1342)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1342)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1342)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1342)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1342)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1342)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1342)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1342)\u001b[0m 1 | ar_net        | ModuleList    | 15.9 K\n",
      "\u001b[2m\u001b[36m(pid=1342)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1342)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1342)\u001b[0m 15.9 K    Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1342)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1342)\u001b[0m 15.9 K    Total params\n",
      "\u001b[2m\u001b[36m(pid=1342)\u001b[0m 0.064     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1342)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1342)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1342)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1342)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1342)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1342)\u001b[0m \n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1342)\u001b[0m {'n_lags': 30, 'learning_rate': 0.02043186311455808, 'num_hidden_layers': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1349)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1349)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1349)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1349)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1349)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1349)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1349)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1349)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1349)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1349)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1349)\u001b[0m 1 | ar_net        | ModuleList    | 924   \n",
      "\u001b[2m\u001b[36m(pid=1349)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1349)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1349)\u001b[0m 955       Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1349)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1349)\u001b[0m 955       Total params\n",
      "\u001b[2m\u001b[36m(pid=1349)\u001b[0m 0.004     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1349)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1349)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1349)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1349)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1349)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1349)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1349)\u001b[0m {'n_lags': 20, 'learning_rate': 0.0250816586900489, 'num_hidden_layers': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "2021-05-11 00:17:14,461\tWARNING util.py:162 -- The `start_trial` operation took 1.028 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=1352)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1352)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1352)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1352)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1352)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1352)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1352)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1352)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1352)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1352)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1352)\u001b[0m 1 | ar_net        | ModuleList    | 7.9 K \n",
      "\u001b[2m\u001b[36m(pid=1352)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1352)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1352)\u001b[0m 8.0 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1352)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1352)\u001b[0m 8.0 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1352)\u001b[0m 0.032     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1352)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1352)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1352)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1352)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1352)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1352)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1352)\u001b[0m {'n_lags': 30, 'learning_rate': 0.0168185943796047, 'num_hidden_layers': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "2021-05-11 00:17:19,755\tWARNING util.py:162 -- The `start_trial` operation took 1.021 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=1355)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1355)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1355)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1355)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1355)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1355)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1355)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1355)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1355)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1355)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1355)\u001b[0m 1 | ar_net        | ModuleList    | 1.1 K \n",
      "\u001b[2m\u001b[36m(pid=1355)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1355)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1355)\u001b[0m 1.1 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1355)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1355)\u001b[0m 1.1 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1355)\u001b[0m 0.004     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1355)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1355)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1355)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1355)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1355)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1355)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1355)\u001b[0m {'n_lags': 10, 'learning_rate': 0.0005379980203217289, 'num_hidden_layers': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=1358)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1358)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1358)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1358)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1358)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1358)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1358)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1358)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1358)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1358)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1358)\u001b[0m 1 | ar_net        | ModuleList    | 7.4 K \n",
      "\u001b[2m\u001b[36m(pid=1358)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1358)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1358)\u001b[0m 7.4 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1358)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1358)\u001b[0m 7.4 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1358)\u001b[0m 0.030     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1358)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1358)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1358)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1358)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1358)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1358)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1358)\u001b[0m {'n_lags': 20, 'learning_rate': 0.0011772946725364293, 'num_hidden_layers': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=1361)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1361)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1361)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1361)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1361)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1361)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1361)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1361)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1361)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1361)\u001b[0m 1 | ar_net        | ModuleList    | 2.0 K \n",
      "\u001b[2m\u001b[36m(pid=1361)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1361)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1361)\u001b[0m 2.0 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1361)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1361)\u001b[0m 2.0 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1361)\u001b[0m 0.008     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1361)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1361)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1361)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1361)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1361)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1361)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1361)\u001b[0m {'n_lags': 30, 'learning_rate': 0.00105038370886048, 'num_hidden_layers': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=1368)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1368)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1368)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1368)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1368)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1368)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1368)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1368)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1368)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1368)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1368)\u001b[0m 1 | ar_net        | ModuleList    | 1.1 K \n",
      "\u001b[2m\u001b[36m(pid=1368)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1368)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1368)\u001b[0m 1.1 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1368)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1368)\u001b[0m 1.1 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1368)\u001b[0m 0.004     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1368)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1368)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1368)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1368)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1368)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1368)\u001b[0m \n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1368)\u001b[0m {'n_lags': 10, 'learning_rate': 0.0013102171125634167, 'num_hidden_layers': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=1377)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1377)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1377)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1377)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1377)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1377)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1377)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1377)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1377)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1377)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1377)\u001b[0m 1 | ar_net        | ModuleList    | 3.7 K \n",
      "\u001b[2m\u001b[36m(pid=1377)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1377)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1377)\u001b[0m 3.7 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1377)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1377)\u001b[0m 3.7 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1377)\u001b[0m 0.015     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1377)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1377)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1377)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1377)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1377)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1377)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1377)\u001b[0m {'n_lags': 20, 'learning_rate': 0.0013458980612308749, 'num_hidden_layers': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "2021-05-11 00:17:46,663\tWARNING util.py:162 -- The `start_trial` operation took 1.024 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(pid=1380)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1380)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1380)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1380)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1380)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1380)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1380)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1380)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1380)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1380)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1380)\u001b[0m 1 | ar_net        | ModuleList    | 15.9 K\n",
      "\u001b[2m\u001b[36m(pid=1380)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1380)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1380)\u001b[0m 15.9 K    Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1380)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1380)\u001b[0m 15.9 K    Total params\n",
      "\u001b[2m\u001b[36m(pid=1380)\u001b[0m 0.064     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1380)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1380)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1380)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1380)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1380)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1380)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1380)\u001b[0m {'n_lags': 30, 'learning_rate': 0.0006172789722203179, 'num_hidden_layers': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=1387)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1387)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1387)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1387)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1387)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1387)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1387)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1387)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1387)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1387)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1387)\u001b[0m 1 | ar_net        | ModuleList    | 1.1 K \n",
      "\u001b[2m\u001b[36m(pid=1387)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1387)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1387)\u001b[0m 1.1 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1387)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1387)\u001b[0m 1.1 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1387)\u001b[0m 0.004     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1387)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1387)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1387)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1387)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1387)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1387)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1387)\u001b[0m {'n_lags': 10, 'learning_rate': 0.025701695870263296, 'num_hidden_layers': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "2021-05-11 00:17:58,652\tWARNING util.py:162 -- The `start_trial` operation took 1.027 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(pid=1390)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1390)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1390)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1390)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1390)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1390)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1390)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1390)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1390)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1390)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1390)\u001b[0m 1 | ar_net        | ModuleList    | 7.4 K \n",
      "\u001b[2m\u001b[36m(pid=1390)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1390)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1390)\u001b[0m 7.4 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1390)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1390)\u001b[0m 7.4 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1390)\u001b[0m 0.030     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1390)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1390)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1390)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1390)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1390)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1390)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1390)\u001b[0m {'n_lags': 20, 'learning_rate': 0.028409750625528703, 'num_hidden_layers': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=1394)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1394)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1394)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[36m(pid=1394)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1394)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1394)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1394)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1394)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1394)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1394)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1394)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1394)\u001b[0m 1 | ar_net        | ModuleList    | 2.0 K \n",
      "\u001b[2m\u001b[36m(pid=1394)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1394)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1394)\u001b[0m 2.0 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1394)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1394)\u001b[0m 2.0 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1394)\u001b[0m 0.008     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1394)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1394)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1394)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1394)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1394)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1394)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1394)\u001b[0m {'n_lags': 30, 'learning_rate': 0.001426319208157316, 'num_hidden_layers': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=1397)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1397)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1397)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1397)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1397)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1397)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1397)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1397)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1397)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1397)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1397)\u001b[0m 1 | ar_net        | ModuleList    | 2.1 K \n",
      "\u001b[2m\u001b[36m(pid=1397)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1397)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1397)\u001b[0m 2.1 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1397)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1397)\u001b[0m 2.1 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1397)\u001b[0m 0.009     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1397)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1397)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1397)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1397)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1397)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1397)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1397)\u001b[0m {'n_lags': 10, 'learning_rate': 0.033561484301400935, 'num_hidden_layers': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=1400)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1400)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1400)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1400)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1400)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1400)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1400)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1400)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1400)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1400)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1400)\u001b[0m 1 | ar_net        | ModuleList    | 3.7 K \n",
      "\u001b[2m\u001b[36m(pid=1400)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1400)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1400)\u001b[0m 3.7 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1400)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1400)\u001b[0m 3.7 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1400)\u001b[0m 0.015     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1400)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1400)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1400)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1400)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1400)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1400)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1400)\u001b[0m {'n_lags': 20, 'learning_rate': 0.0012490061149642395, 'num_hidden_layers': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=1405)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1405)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1405)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1405)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1405)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1405)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1405)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1405)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1405)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1405)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1405)\u001b[0m 1 | ar_net        | ModuleList    | 2.0 K \n",
      "\u001b[2m\u001b[36m(pid=1405)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1405)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1405)\u001b[0m 2.0 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1405)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1405)\u001b[0m 2.0 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1405)\u001b[0m 0.008     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1405)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1405)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1405)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1405)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1405)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1405)\u001b[0m \n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1405)\u001b[0m {'n_lags': 30, 'learning_rate': 0.045559327745567854, 'num_hidden_layers': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1408)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1408)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1408)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1408)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1408)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1408)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1408)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1408)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1408)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1408)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1408)\u001b[0m 1 | ar_net        | ModuleList    | 3.7 K \n",
      "\u001b[2m\u001b[36m(pid=1408)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1408)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1408)\u001b[0m 3.7 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1408)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1408)\u001b[0m 3.7 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1408)\u001b[0m 0.015     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1408)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1408)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1408)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1408)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1408)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1408)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1408)\u001b[0m {'n_lags': 20, 'learning_rate': 0.07548610069902989, 'num_hidden_layers': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1411)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1411)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1411)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1411)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1411)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1411)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1411)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1411)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1411)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1411)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1411)\u001b[0m 1 | ar_net        | ModuleList    | 2.1 K \n",
      "\u001b[2m\u001b[36m(pid=1411)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1411)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1411)\u001b[0m 2.1 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1411)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1411)\u001b[0m 2.1 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1411)\u001b[0m 0.009     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1411)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1411)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1411)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1411)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1411)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1411)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1411)\u001b[0m {'n_lags': 10, 'learning_rate': 0.03685015765889695, 'num_hidden_layers': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "2021-05-11 00:18:24,717\tWARNING util.py:162 -- The `start_trial` operation took 1.031 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=1423)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1423)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1423)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1423)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1423)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1423)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1423)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1423)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1423)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1423)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1423)\u001b[0m 1 | ar_net        | ModuleList    | 2.0 K \n",
      "\u001b[2m\u001b[36m(pid=1423)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1423)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1423)\u001b[0m 2.0 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1423)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1423)\u001b[0m 2.0 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1423)\u001b[0m 0.008     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1423)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1423)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1423)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1423)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1423)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1423)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1423)\u001b[0m {'n_lags': 30, 'learning_rate': 0.0028790267037711727, 'num_hidden_layers': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "2021-05-11 00:18:32,394\tWARNING util.py:162 -- The `start_trial` operation took 1.027 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=1426)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1426)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1426)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1426)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1426)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1426)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1426)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1426)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1426)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1426)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1426)\u001b[0m 1 | ar_net        | ModuleList    | 264   \n",
      "\u001b[2m\u001b[36m(pid=1426)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1426)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1426)\u001b[0m 295       Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1426)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1426)\u001b[0m 295       Total params\n",
      "\u001b[2m\u001b[36m(pid=1426)\u001b[0m 0.001     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1426)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1426)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1426)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1426)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1426)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1426)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1426)\u001b[0m {'n_lags': 10, 'learning_rate': 0.0015994379110577928, 'num_hidden_layers': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=1429)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1429)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1429)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1429)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1429)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1429)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1429)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1429)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1429)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1429)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1429)\u001b[0m 1 | ar_net        | ModuleList    | 924   \n",
      "\u001b[2m\u001b[36m(pid=1429)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1429)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1429)\u001b[0m 955       Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1429)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1429)\u001b[0m 955       Total params\n",
      "\u001b[2m\u001b[36m(pid=1429)\u001b[0m 0.004     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1429)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1429)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1429)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1429)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1429)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1429)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1429)\u001b[0m {'n_lags': 20, 'learning_rate': 0.014524464917818624, 'num_hidden_layers': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[36m(pid=1432)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1432)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1432)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1432)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1432)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1432)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1432)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1432)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1432)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1432)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1432)\u001b[0m 1 | ar_net        | ModuleList    | 2.0 K \n",
      "\u001b[2m\u001b[36m(pid=1432)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1432)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1432)\u001b[0m 2.0 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1432)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1432)\u001b[0m 2.0 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1432)\u001b[0m 0.008     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1432)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1432)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1432)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1432)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1432)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1432)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1432)\u001b[0m {'n_lags': 30, 'learning_rate': 0.00010387147414094625, 'num_hidden_layers': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=1435)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1435)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1435)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1435)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1435)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1435)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1435)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1435)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1435)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1435)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1435)\u001b[0m 1 | ar_net        | ModuleList    | 264   \n",
      "\u001b[2m\u001b[36m(pid=1435)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1435)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1435)\u001b[0m 295       Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1435)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1435)\u001b[0m 295       Total params\n",
      "\u001b[2m\u001b[36m(pid=1435)\u001b[0m 0.001     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1435)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1435)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1435)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1435)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1435)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1435)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1435)\u001b[0m {'n_lags': 10, 'learning_rate': 0.00017305540281073353, 'num_hidden_layers': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "2021-05-11 00:18:59,080\tWARNING util.py:162 -- The `start_trial` operation took 1.023 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=1441)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1441)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1441)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1441)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1441)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1441)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1441)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1441)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1441)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1441)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1441)\u001b[0m 1 | ar_net        | ModuleList    | 924   \n",
      "\u001b[2m\u001b[36m(pid=1441)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1441)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1441)\u001b[0m 955       Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1441)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1441)\u001b[0m 955       Total params\n",
      "\u001b[2m\u001b[36m(pid=1441)\u001b[0m 0.004     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1441)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1441)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1441)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1441)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1441)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1441)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1441)\u001b[0m {'n_lags': 20, 'learning_rate': 0.00043736109202420503, 'num_hidden_layers': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[36m(pid=1444)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1444)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1444)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1444)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1444)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1444)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1444)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1444)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1444)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1444)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1444)\u001b[0m 1 | ar_net        | ModuleList    | 2.0 K \n",
      "\u001b[2m\u001b[36m(pid=1444)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1444)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1444)\u001b[0m 2.0 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1444)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1444)\u001b[0m 2.0 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1444)\u001b[0m 0.008     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1444)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1444)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1444)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1444)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1444)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1444)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1444)\u001b[0m {'n_lags': 30, 'learning_rate': 0.013516924711928327, 'num_hidden_layers': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=1447)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1447)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1447)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1447)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1447)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1447)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1447)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1447)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1447)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1447)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1447)\u001b[0m 1 | ar_net        | ModuleList    | 264   \n",
      "\u001b[2m\u001b[36m(pid=1447)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1447)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1447)\u001b[0m 295       Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1447)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1447)\u001b[0m 295       Total params\n",
      "\u001b[2m\u001b[36m(pid=1447)\u001b[0m 0.001     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1447)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1447)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1447)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1447)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1447)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1447)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1447)\u001b[0m {'n_lags': 10, 'learning_rate': 0.009219320721527435, 'num_hidden_layers': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[36m(pid=1454)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1454)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1454)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1454)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1454)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1454)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1454)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1454)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1454)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1454)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1454)\u001b[0m 1 | ar_net        | ModuleList    | 924   \n",
      "\u001b[2m\u001b[36m(pid=1454)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1454)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1454)\u001b[0m 955       Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1454)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1454)\u001b[0m 955       Total params\n",
      "\u001b[2m\u001b[36m(pid=1454)\u001b[0m 0.004     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1454)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1454)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1454)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1454)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1454)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1454)\u001b[0m \n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1454)\u001b[0m {'n_lags': 20, 'learning_rate': 0.00037104338820677574, 'num_hidden_layers': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-11 00:19:15,866\tWARNING util.py:162 -- The `start_trial` operation took 1.039 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=1461)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1461)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1461)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1461)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1461)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1461)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1461)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1461)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1461)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1461)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1461)\u001b[0m 1 | ar_net        | ModuleList    | 2.0 K \n",
      "\u001b[2m\u001b[36m(pid=1461)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1461)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1461)\u001b[0m 2.0 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1461)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1461)\u001b[0m 2.0 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1461)\u001b[0m 0.008     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1461)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1461)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1461)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1461)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1461)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1461)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1461)\u001b[0m {'n_lags': 30, 'learning_rate': 0.06383437884101383, 'num_hidden_layers': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[36m(pid=1464)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1464)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1464)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1464)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1464)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1464)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1464)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1464)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1464)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1464)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1464)\u001b[0m 1 | ar_net        | ModuleList    | 1.1 K \n",
      "\u001b[2m\u001b[36m(pid=1464)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1464)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1464)\u001b[0m 1.1 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1464)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1464)\u001b[0m 1.1 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1464)\u001b[0m 0.004     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1464)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1464)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1464)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1464)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1464)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1464)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1464)\u001b[0m {'n_lags': 10, 'learning_rate': 0.035178515258132474, 'num_hidden_layers': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=1469)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1469)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1469)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1469)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1469)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1469)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1469)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1469)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1469)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1469)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1469)\u001b[0m 1 | ar_net        | ModuleList    | 7.4 K \n",
      "\u001b[2m\u001b[36m(pid=1469)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1469)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1469)\u001b[0m 7.4 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1469)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1469)\u001b[0m 7.4 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1469)\u001b[0m 0.030     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1469)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1469)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1469)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1469)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1469)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1469)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1469)\u001b[0m {'n_lags': 20, 'learning_rate': 0.045646863993749565, 'num_hidden_layers': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "2021-05-11 00:19:33,186\tWARNING util.py:162 -- The `start_trial` operation took 1.026 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "2021-05-11 00:19:36,951\tWARNING util.py:162 -- The `start_trial` operation took 1.031 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(pid=1475)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1475)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1475)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1475)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1475)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1475)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1475)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1475)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1475)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1475)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1475)\u001b[0m 1 | ar_net        | ModuleList    | 2.0 K \n",
      "\u001b[2m\u001b[36m(pid=1475)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1475)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1475)\u001b[0m 2.0 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1475)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1475)\u001b[0m 2.0 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1475)\u001b[0m 0.008     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1475)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1475)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1475)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1475)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1475)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1475)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1475)\u001b[0m {'n_lags': 30, 'learning_rate': 0.002463013694358461, 'num_hidden_layers': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=1478)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1478)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1478)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1478)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1478)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1478)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1478)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1478)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1478)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1478)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1478)\u001b[0m 1 | ar_net        | ModuleList    | 2.1 K \n",
      "\u001b[2m\u001b[36m(pid=1478)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1478)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1478)\u001b[0m 2.1 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1478)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1478)\u001b[0m 2.1 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1478)\u001b[0m 0.009     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1478)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1478)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1478)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1478)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1478)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1478)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1478)\u001b[0m {'n_lags': 10, 'learning_rate': 0.010595313014019522, 'num_hidden_layers': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "2021-05-11 00:19:44,844\tWARNING util.py:162 -- The `start_trial` operation took 1.030 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=1481)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1481)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1481)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1481)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1481)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1481)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1481)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1481)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1481)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1481)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1481)\u001b[0m 1 | ar_net        | ModuleList    | 7.4 K \n",
      "\u001b[2m\u001b[36m(pid=1481)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1481)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1481)\u001b[0m 7.4 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1481)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1481)\u001b[0m 7.4 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1481)\u001b[0m 0.030     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1481)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1481)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1481)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1481)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1481)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1481)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1481)\u001b[0m {'n_lags': 20, 'learning_rate': 0.0004098794914504848, 'num_hidden_layers': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "2021-05-11 00:19:52,769\tWARNING util.py:162 -- The `start_trial` operation took 1.025 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=1484)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1484)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1484)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1484)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1484)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1484)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1484)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1484)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1484)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1484)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1484)\u001b[0m 1 | ar_net        | ModuleList    | 7.9 K \n",
      "\u001b[2m\u001b[36m(pid=1484)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1484)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1484)\u001b[0m 8.0 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1484)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1484)\u001b[0m 8.0 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1484)\u001b[0m 0.032     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1484)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1484)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1484)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1484)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1484)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1484)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1484)\u001b[0m {'n_lags': 30, 'learning_rate': 0.03208034379901542, 'num_hidden_layers': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=1487)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1487)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1487)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1487)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1487)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1487)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1487)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1487)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1487)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1487)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1487)\u001b[0m 1 | ar_net        | ModuleList    | 264   \n",
      "\u001b[2m\u001b[36m(pid=1487)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1487)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1487)\u001b[0m 295       Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1487)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1487)\u001b[0m 295       Total params\n",
      "\u001b[2m\u001b[36m(pid=1487)\u001b[0m 0.001     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1487)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1487)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1487)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1487)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1487)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1487)\u001b[0m \n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1487)\u001b[0m {'n_lags': 10, 'learning_rate': 0.00011470533686389642, 'num_hidden_layers': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=1491)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1491)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1491)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1491)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1491)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1491)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1491)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1491)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1491)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1491)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1491)\u001b[0m 1 | ar_net        | ModuleList    | 7.4 K \n",
      "\u001b[2m\u001b[36m(pid=1491)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1491)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1491)\u001b[0m 7.4 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1491)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1491)\u001b[0m 7.4 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1491)\u001b[0m 0.030     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1491)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1491)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1491)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1491)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1491)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1491)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1491)\u001b[0m {'n_lags': 20, 'learning_rate': 0.03742043972547689, 'num_hidden_layers': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=1494)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1494)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1494)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1494)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1494)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1494)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1494)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1494)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1494)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1494)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1494)\u001b[0m 1 | ar_net        | ModuleList    | 15.9 K\n",
      "\u001b[2m\u001b[36m(pid=1494)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1494)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1494)\u001b[0m 15.9 K    Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1494)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1494)\u001b[0m 15.9 K    Total params\n",
      "\u001b[2m\u001b[36m(pid=1494)\u001b[0m 0.064     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1494)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1494)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1494)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1494)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1494)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1494)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1494)\u001b[0m {'n_lags': 30, 'learning_rate': 0.029798697918841432, 'num_hidden_layers': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "2021-05-11 00:20:29,506\tWARNING util.py:162 -- The `start_trial` operation took 1.030 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=1497)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1497)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1497)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1497)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1497)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1497)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1497)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1497)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1497)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1497)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1497)\u001b[0m 1 | ar_net        | ModuleList    | 2.1 K \n",
      "\u001b[2m\u001b[36m(pid=1497)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1497)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1497)\u001b[0m 2.1 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1497)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1497)\u001b[0m 2.1 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1497)\u001b[0m 0.009     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1497)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1497)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1497)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1497)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1497)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1497)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1497)\u001b[0m {'n_lags': 10, 'learning_rate': 0.01669240895379309, 'num_hidden_layers': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=1500)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1500)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1500)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1500)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1500)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1500)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1500)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1500)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1500)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1500)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1500)\u001b[0m 1 | ar_net        | ModuleList    | 924   \n",
      "\u001b[2m\u001b[36m(pid=1500)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1500)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1500)\u001b[0m 955       Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1500)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1500)\u001b[0m 955       Total params\n",
      "\u001b[2m\u001b[36m(pid=1500)\u001b[0m 0.004     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1500)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1500)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1500)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1500)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1500)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1500)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1500)\u001b[0m {'n_lags': 20, 'learning_rate': 0.0001293718760964555, 'num_hidden_layers': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=1505)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1505)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1505)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1505)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1505)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1505)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1505)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1505)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1505)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1505)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1505)\u001b[0m 1 | ar_net        | ModuleList    | 15.9 K\n",
      "\u001b[2m\u001b[36m(pid=1505)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1505)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1505)\u001b[0m 15.9 K    Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1505)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1505)\u001b[0m 15.9 K    Total params\n",
      "\u001b[2m\u001b[36m(pid=1505)\u001b[0m 0.064     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1505)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1505)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1505)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1505)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1505)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1505)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1505)\u001b[0m {'n_lags': 30, 'learning_rate': 0.0002683482654028901, 'num_hidden_layers': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "2021-05-11 00:21:13,033\tWARNING util.py:162 -- The `start_trial` operation took 1.053 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "2021-05-11 00:21:16,608\tWARNING util.py:162 -- The `start_trial` operation took 1.029 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(pid=1508)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1508)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1508)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "\u001b[2m\u001b[36m(pid=1510)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1510)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1510)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1508)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1508)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1508)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1508)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1508)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1508)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1508)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1508)\u001b[0m 1 | ar_net        | ModuleList    | 3.7 K \n",
      "\u001b[2m\u001b[36m(pid=1508)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1508)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1508)\u001b[0m 3.7 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1508)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1508)\u001b[0m 3.7 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1508)\u001b[0m 0.015     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1508)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1508)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1508)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1508)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1508)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1508)\u001b[0m \n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1510)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1510)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1510)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1510)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1510)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1510)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1510)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1510)\u001b[0m 1 | ar_net        | ModuleList    | 1.1 K \n",
      "\u001b[2m\u001b[36m(pid=1510)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1510)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1510)\u001b[0m 1.1 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1510)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1510)\u001b[0m 1.1 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1510)\u001b[0m 0.004     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1510)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1510)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1510)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1510)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1510)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1510)\u001b[0m \n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1508)\u001b[0m {'n_lags': 20, 'learning_rate': 0.005557205352136829, 'num_hidden_layers': 8}\n",
      "\u001b[2m\u001b[36m(pid=1510)\u001b[0m {'n_lags': 10, 'learning_rate': 0.05765758454779955, 'num_hidden_layers': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-11 00:21:19,436\tWARNING util.py:162 -- The `start_trial` operation took 1.071 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(pid=1520)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1520)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1520)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1520)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1520)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1520)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1520)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1520)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1520)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1520)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1520)\u001b[0m 1 | ar_net        | ModuleList    | 7.9 K \n",
      "\u001b[2m\u001b[36m(pid=1520)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1520)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1520)\u001b[0m 8.0 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1520)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1520)\u001b[0m 8.0 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1520)\u001b[0m 0.032     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1520)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1520)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1520)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1520)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1520)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1520)\u001b[0m \n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1520)\u001b[0m {'n_lags': 30, 'learning_rate': 0.0033820836122625234, 'num_hidden_layers': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=1527)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1527)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1527)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1527)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1527)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1527)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1527)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1527)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1527)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1527)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1527)\u001b[0m 1 | ar_net        | ModuleList    | 2.1 K \n",
      "\u001b[2m\u001b[36m(pid=1527)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1527)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1527)\u001b[0m 2.1 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1527)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1527)\u001b[0m 2.1 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1527)\u001b[0m 0.009     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1527)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1527)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1527)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1527)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1527)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1527)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1527)\u001b[0m {'n_lags': 10, 'learning_rate': 0.048561914552853885, 'num_hidden_layers': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=1530)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1530)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1530)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1530)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1530)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1530)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1530)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1530)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1530)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1530)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1530)\u001b[0m 1 | ar_net        | ModuleList    | 924   \n",
      "\u001b[2m\u001b[36m(pid=1530)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1530)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1530)\u001b[0m 955       Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1530)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1530)\u001b[0m 955       Total params\n",
      "\u001b[2m\u001b[36m(pid=1530)\u001b[0m 0.004     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1530)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1530)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1530)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1530)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1530)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1530)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1530)\u001b[0m {'n_lags': 20, 'learning_rate': 0.002316793606935643, 'num_hidden_layers': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[36m(pid=1533)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1533)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1533)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1533)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1533)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1533)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1533)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1533)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1533)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1533)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1533)\u001b[0m 1 | ar_net        | ModuleList    | 15.9 K\n",
      "\u001b[2m\u001b[36m(pid=1533)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1533)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1533)\u001b[0m 15.9 K    Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1533)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1533)\u001b[0m 15.9 K    Total params\n",
      "\u001b[2m\u001b[36m(pid=1533)\u001b[0m 0.064     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1533)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1533)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1533)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1533)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1533)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1533)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1533)\u001b[0m {'n_lags': 30, 'learning_rate': 0.09918806929374581, 'num_hidden_layers': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=1536)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1536)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1536)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1536)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1536)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1536)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1536)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1536)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1536)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1536)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1536)\u001b[0m 1 | ar_net        | ModuleList    | 2.1 K \n",
      "\u001b[2m\u001b[36m(pid=1536)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1536)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1536)\u001b[0m 2.1 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1536)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1536)\u001b[0m 2.1 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1536)\u001b[0m 0.009     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1536)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1536)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1536)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1536)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1536)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1536)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1536)\u001b[0m {'n_lags': 10, 'learning_rate': 0.0005224442837534899, 'num_hidden_layers': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=1539)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1539)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1539)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1539)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1539)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1539)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1539)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1539)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1539)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1539)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1539)\u001b[0m 1 | ar_net        | ModuleList    | 3.7 K \n",
      "\u001b[2m\u001b[36m(pid=1539)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1539)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1539)\u001b[0m 3.7 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1539)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1539)\u001b[0m 3.7 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1539)\u001b[0m 0.015     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1539)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1539)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1539)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1539)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1539)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1539)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1539)\u001b[0m {'n_lags': 20, 'learning_rate': 0.056180079321098156, 'num_hidden_layers': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "2021-05-11 00:21:54,037\tWARNING util.py:162 -- The `start_trial` operation took 1.028 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "2021-05-11 00:21:55,327\tWARNING util.py:162 -- The `start_trial` operation took 1.025 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(pid=1550)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1550)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1550)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "\u001b[2m\u001b[36m(pid=1546)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1550)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1550)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1550)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1550)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1550)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1550)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1550)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1550)\u001b[0m 1 | ar_net        | ModuleList    | 1.1 K \n",
      "\u001b[2m\u001b[36m(pid=1550)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1550)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1550)\u001b[0m 1.1 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1550)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1550)\u001b[0m 1.1 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1550)\u001b[0m 0.004     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1550)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1550)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1550)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1550)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1550)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1550)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1546)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1546)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1550)\u001b[0m {'n_lags': 10, 'learning_rate': 0.04023929799588559, 'num_hidden_layers': 8}\n",
      "\u001b[2m\u001b[36m(pid=1546)\u001b[0m {'n_lags': 30, 'learning_rate': 0.0022376604108244676, 'num_hidden_layers': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1546)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1546)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1546)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1546)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1546)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1546)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1546)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1546)\u001b[0m 1 | ar_net        | ModuleList    | 15.9 K\n",
      "\u001b[2m\u001b[36m(pid=1546)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1546)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1546)\u001b[0m 15.9 K    Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1546)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1546)\u001b[0m 15.9 K    Total params\n",
      "\u001b[2m\u001b[36m(pid=1546)\u001b[0m 0.064     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1546)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1546)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1546)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1546)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1546)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1546)\u001b[0m \n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=1555)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1555)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1555)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1555)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1555)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1555)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1555)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1555)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1555)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1555)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1555)\u001b[0m 1 | ar_net        | ModuleList    | 924   \n",
      "\u001b[2m\u001b[36m(pid=1555)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1555)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1555)\u001b[0m 955       Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1555)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1555)\u001b[0m 955       Total params\n",
      "\u001b[2m\u001b[36m(pid=1555)\u001b[0m 0.004     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1555)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1555)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1555)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1555)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1555)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1555)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1555)\u001b[0m {'n_lags': 20, 'learning_rate': 0.00848559263509737, 'num_hidden_layers': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=1558)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1558)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1558)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1558)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1558)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1558)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1558)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1558)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1558)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1558)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1558)\u001b[0m 1 | ar_net        | ModuleList    | 2.0 K \n",
      "\u001b[2m\u001b[36m(pid=1558)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1558)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1558)\u001b[0m 2.0 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1558)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1558)\u001b[0m 2.0 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1558)\u001b[0m 0.008     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1558)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1558)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1558)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1558)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1558)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1558)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1558)\u001b[0m {'n_lags': 30, 'learning_rate': 0.026341342932353157, 'num_hidden_layers': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=1561)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1561)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1561)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1561)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1561)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1561)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1561)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1561)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1561)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1561)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1561)\u001b[0m 1 | ar_net        | ModuleList    | 1.1 K \n",
      "\u001b[2m\u001b[36m(pid=1561)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1561)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1561)\u001b[0m 1.1 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1561)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1561)\u001b[0m 1.1 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1561)\u001b[0m 0.004     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1561)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1561)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1561)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1561)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1561)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1561)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1561)\u001b[0m {'n_lags': 10, 'learning_rate': 0.0688279032805638, 'num_hidden_layers': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=1564)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1564)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1564)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1564)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1564)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1564)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1564)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1564)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1564)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1564)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1564)\u001b[0m 1 | ar_net        | ModuleList    | 3.7 K \n",
      "\u001b[2m\u001b[36m(pid=1564)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1564)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1564)\u001b[0m 3.7 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1564)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1564)\u001b[0m 3.7 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1564)\u001b[0m 0.015     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1564)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1564)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1564)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1564)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1564)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1564)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1564)\u001b[0m {'n_lags': 20, 'learning_rate': 0.00017847584859092435, 'num_hidden_layers': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[36m(pid=1567)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1567)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1567)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1567)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1567)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1567)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1567)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1567)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1567)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1567)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1567)\u001b[0m 1 | ar_net        | ModuleList    | 15.9 K\n",
      "\u001b[2m\u001b[36m(pid=1567)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1567)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1567)\u001b[0m 15.9 K    Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1567)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1567)\u001b[0m 15.9 K    Total params\n",
      "\u001b[2m\u001b[36m(pid=1567)\u001b[0m 0.064     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1567)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1567)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1567)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1567)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1567)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1567)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1567)\u001b[0m {'n_lags': 30, 'learning_rate': 0.0002116310501255022, 'num_hidden_layers': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=1570)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1570)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1570)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1570)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1570)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1570)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1570)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1570)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1570)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1570)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1570)\u001b[0m 1 | ar_net        | ModuleList    | 1.1 K \n",
      "\u001b[2m\u001b[36m(pid=1570)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1570)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1570)\u001b[0m 1.1 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1570)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1570)\u001b[0m 1.1 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1570)\u001b[0m 0.004     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1570)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1570)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1570)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1570)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1570)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1570)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1570)\u001b[0m {'n_lags': 10, 'learning_rate': 0.06190325506076608, 'num_hidden_layers': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=1573)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1573)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1573)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1573)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1573)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1573)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1573)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1573)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1573)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1573)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1573)\u001b[0m 1 | ar_net        | ModuleList    | 3.7 K \n",
      "\u001b[2m\u001b[36m(pid=1573)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1573)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1573)\u001b[0m 3.7 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1573)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1573)\u001b[0m 3.7 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1573)\u001b[0m 0.015     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1573)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1573)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1573)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1573)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1573)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1573)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1573)\u001b[0m {'n_lags': 20, 'learning_rate': 0.05445063155750102, 'num_hidden_layers': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=1576)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1576)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1576)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1576)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1576)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1576)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1576)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1576)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1576)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1576)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1576)\u001b[0m 1 | ar_net        | ModuleList    | 15.9 K\n",
      "\u001b[2m\u001b[36m(pid=1576)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1576)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1576)\u001b[0m 15.9 K    Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1576)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1576)\u001b[0m 15.9 K    Total params\n",
      "\u001b[2m\u001b[36m(pid=1576)\u001b[0m 0.064     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1576)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1576)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1576)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1576)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1576)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1576)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1576)\u001b[0m {'n_lags': 30, 'learning_rate': 0.00012040973931137008, 'num_hidden_layers': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "2021-05-11 00:23:10,472\tWARNING util.py:162 -- The `start_trial` operation took 1.025 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=1582)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1582)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1582)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[36m(pid=1582)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1582)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1582)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1582)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1582)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1582)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1582)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1582)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1582)\u001b[0m 1 | ar_net        | ModuleList    | 264   \n",
      "\u001b[2m\u001b[36m(pid=1582)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1582)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1582)\u001b[0m 295       Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1582)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1582)\u001b[0m 295       Total params\n",
      "\u001b[2m\u001b[36m(pid=1582)\u001b[0m 0.001     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1582)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1582)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1582)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1582)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1582)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1582)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1582)\u001b[0m {'n_lags': 10, 'learning_rate': 0.0012292108159655405, 'num_hidden_layers': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=1585)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1585)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1585)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1585)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1585)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1585)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1585)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1585)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1585)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1585)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1585)\u001b[0m 1 | ar_net        | ModuleList    | 7.4 K \n",
      "\u001b[2m\u001b[36m(pid=1585)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1585)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1585)\u001b[0m 7.4 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1585)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1585)\u001b[0m 7.4 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1585)\u001b[0m 0.030     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1585)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1585)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1585)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1585)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1585)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1585)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1585)\u001b[0m {'n_lags': 20, 'learning_rate': 0.006513599836062066, 'num_hidden_layers': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=1588)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1588)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1588)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1588)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1588)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1588)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1588)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1588)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1588)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1588)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1588)\u001b[0m 1 | ar_net        | ModuleList    | 15.9 K\n",
      "\u001b[2m\u001b[36m(pid=1588)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1588)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1588)\u001b[0m 15.9 K    Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1588)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1588)\u001b[0m 15.9 K    Total params\n",
      "\u001b[2m\u001b[36m(pid=1588)\u001b[0m 0.064     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1588)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1588)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1588)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1588)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1588)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1588)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1588)\u001b[0m {'n_lags': 30, 'learning_rate': 0.025242987417882876, 'num_hidden_layers': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=1591)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1591)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1591)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1591)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1591)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1591)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1591)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1591)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1591)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1591)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1591)\u001b[0m 1 | ar_net        | ModuleList    | 1.1 K \n",
      "\u001b[2m\u001b[36m(pid=1591)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1591)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1591)\u001b[0m 1.1 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1591)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1591)\u001b[0m 1.1 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1591)\u001b[0m 0.004     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1591)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1591)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1591)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1591)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1591)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1591)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1591)\u001b[0m {'n_lags': 10, 'learning_rate': 0.02210921906664524, 'num_hidden_layers': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=1596)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1596)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1596)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1596)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1596)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1596)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1596)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1596)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1596)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1596)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1596)\u001b[0m 1 | ar_net        | ModuleList    | 3.7 K \n",
      "\u001b[2m\u001b[36m(pid=1596)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1596)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1596)\u001b[0m 3.7 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1596)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1596)\u001b[0m 3.7 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1596)\u001b[0m 0.015     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1596)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1596)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1596)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1596)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1596)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1596)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1596)\u001b[0m {'n_lags': 20, 'learning_rate': 0.021099234862400975, 'num_hidden_layers': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "2021-05-11 00:24:44,860\tWARNING util.py:162 -- The `start_trial` operation took 1.041 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=1605)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1605)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1605)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "\u001b[2m\u001b[36m(pid=1608)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1608)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1608)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1605)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1605)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1605)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1605)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1605)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1605)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1605)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1605)\u001b[0m 1 | ar_net        | ModuleList    | 264   \n",
      "\u001b[2m\u001b[36m(pid=1605)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1605)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1605)\u001b[0m 295       Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1605)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1605)\u001b[0m 295       Total params\n",
      "\u001b[2m\u001b[36m(pid=1605)\u001b[0m 0.001     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1605)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1605)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1605)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1605)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1605)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1605)\u001b[0m \n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1608)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1608)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1608)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1608)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1608)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1608)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1608)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1608)\u001b[0m 1 | ar_net        | ModuleList    | 7.9 K \n",
      "\u001b[2m\u001b[36m(pid=1608)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1608)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1608)\u001b[0m 8.0 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1608)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1608)\u001b[0m 8.0 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1608)\u001b[0m 0.032     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1608)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1608)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1608)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1608)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1608)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1608)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1605)\u001b[0m {'n_lags': 10, 'learning_rate': 0.01870858755665602, 'num_hidden_layers': 2}\n",
      "\u001b[2m\u001b[36m(pid=1608)\u001b[0m {'n_lags': 30, 'learning_rate': 0.0002680902740977733, 'num_hidden_layers': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[36m(pid=1617)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1617)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1617)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1617)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1617)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1617)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1617)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1617)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1617)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1617)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1617)\u001b[0m 1 | ar_net        | ModuleList    | 3.7 K \n",
      "\u001b[2m\u001b[36m(pid=1617)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1617)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1617)\u001b[0m 3.7 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1617)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1617)\u001b[0m 3.7 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1617)\u001b[0m 0.015     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1617)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1617)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1617)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1617)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1617)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1617)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1617)\u001b[0m {'n_lags': 20, 'learning_rate': 0.002066996653469397, 'num_hidden_layers': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=1624)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1624)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1624)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1624)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1624)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1624)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1624)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1624)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1624)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1624)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1624)\u001b[0m 1 | ar_net        | ModuleList    | 7.9 K \n",
      "\u001b[2m\u001b[36m(pid=1624)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1624)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1624)\u001b[0m 8.0 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1624)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1624)\u001b[0m 8.0 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1624)\u001b[0m 0.032     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1624)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1624)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1624)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1624)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1624)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1624)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1624)\u001b[0m {'n_lags': 30, 'learning_rate': 0.004599492708758863, 'num_hidden_layers': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "2021-05-11 00:25:09,397\tWARNING util.py:162 -- The `start_trial` operation took 1.029 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(pid=1627)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1627)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1627)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1627)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1627)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1627)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1627)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1627)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1627)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1627)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1627)\u001b[0m 1 | ar_net        | ModuleList    | 1.1 K \n",
      "\u001b[2m\u001b[36m(pid=1627)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1627)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1627)\u001b[0m 1.1 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1627)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1627)\u001b[0m 1.1 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1627)\u001b[0m 0.004     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1627)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1627)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1627)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1627)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1627)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1627)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1627)\u001b[0m {'n_lags': 10, 'learning_rate': 0.00032284975455237756, 'num_hidden_layers': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=1630)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1630)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1630)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1630)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1630)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1630)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1630)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1630)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1630)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1630)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1630)\u001b[0m 1 | ar_net        | ModuleList    | 7.4 K \n",
      "\u001b[2m\u001b[36m(pid=1630)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1630)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1630)\u001b[0m 7.4 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1630)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1630)\u001b[0m 7.4 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1630)\u001b[0m 0.030     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1630)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1630)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1630)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1630)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1630)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1630)\u001b[0m \n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1630)\u001b[0m {'n_lags': 20, 'learning_rate': 0.0011623596498644003, 'num_hidden_layers': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=1633)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1633)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1633)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1633)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1633)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1633)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1633)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1633)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1633)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1633)\u001b[0m 1 | ar_net        | ModuleList    | 15.9 K\n",
      "\u001b[2m\u001b[36m(pid=1633)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1633)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1633)\u001b[0m 15.9 K    Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1633)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1633)\u001b[0m 15.9 K    Total params\n",
      "\u001b[2m\u001b[36m(pid=1633)\u001b[0m 0.064     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1633)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1633)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1633)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1633)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1633)\u001b[0m \n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1633)\u001b[0m {'n_lags': 30, 'learning_rate': 0.035761851225122154, 'num_hidden_layers': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-11 00:25:17,366\tWARNING util.py:162 -- The `start_trial` operation took 1.063 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=1640)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1640)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1640)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "\u001b[2m\u001b[36m(pid=1639)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1639)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1639)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1640)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1640)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1640)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1640)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1640)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1640)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1640)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1640)\u001b[0m 1 | ar_net        | ModuleList    | 924   \n",
      "\u001b[2m\u001b[36m(pid=1640)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1640)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1640)\u001b[0m 955       Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1640)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1640)\u001b[0m 955       Total params\n",
      "\u001b[2m\u001b[36m(pid=1640)\u001b[0m 0.004     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1640)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1640)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1640)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1640)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1640)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1640)\u001b[0m \n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1639)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1639)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1639)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1639)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1639)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1639)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1639)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1639)\u001b[0m 1 | ar_net        | ModuleList    | 1.1 K \n",
      "\u001b[2m\u001b[36m(pid=1639)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1639)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1639)\u001b[0m 1.1 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1639)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1639)\u001b[0m 1.1 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1639)\u001b[0m 0.004     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1639)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1639)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1639)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1639)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1639)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1639)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1640)\u001b[0m {'n_lags': 20, 'learning_rate': 0.0002652473595820322, 'num_hidden_layers': 2}\n",
      "\u001b[2m\u001b[36m(pid=1639)\u001b[0m {'n_lags': 10, 'learning_rate': 0.029070475330501708, 'num_hidden_layers': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=1654)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1654)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1654)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1654)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1654)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1654)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1654)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1654)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1654)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1654)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1654)\u001b[0m 1 | ar_net        | ModuleList    | 15.9 K\n",
      "\u001b[2m\u001b[36m(pid=1654)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1654)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1654)\u001b[0m 15.9 K    Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1654)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1654)\u001b[0m 15.9 K    Total params\n",
      "\u001b[2m\u001b[36m(pid=1654)\u001b[0m 0.064     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1654)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1654)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1654)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1654)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1654)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1654)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1654)\u001b[0m {'n_lags': 30, 'learning_rate': 0.003868677231802383, 'num_hidden_layers': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=1657)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1657)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1657)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1657)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1657)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1657)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1657)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1657)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1657)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1657)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1657)\u001b[0m 1 | ar_net        | ModuleList    | 1.1 K \n",
      "\u001b[2m\u001b[36m(pid=1657)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1657)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1657)\u001b[0m 1.1 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1657)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1657)\u001b[0m 1.1 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1657)\u001b[0m 0.004     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1657)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1657)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1657)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1657)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1657)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1657)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1657)\u001b[0m {'n_lags': 10, 'learning_rate': 0.0010705206166140718, 'num_hidden_layers': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[36m(pid=1660)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1660)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1660)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1660)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1660)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1660)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1660)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1660)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1660)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1660)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1660)\u001b[0m 1 | ar_net        | ModuleList    | 3.7 K \n",
      "\u001b[2m\u001b[36m(pid=1660)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1660)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1660)\u001b[0m 3.7 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1660)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1660)\u001b[0m 3.7 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1660)\u001b[0m 0.015     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1660)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1660)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1660)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1660)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1660)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1660)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1660)\u001b[0m {'n_lags': 20, 'learning_rate': 0.005396661411781699, 'num_hidden_layers': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=1663)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1663)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1663)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1663)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1663)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1663)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1663)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1663)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1663)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1663)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1663)\u001b[0m 1 | ar_net        | ModuleList    | 2.0 K \n",
      "\u001b[2m\u001b[36m(pid=1663)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1663)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1663)\u001b[0m 2.0 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1663)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1663)\u001b[0m 2.0 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1663)\u001b[0m 0.008     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1663)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1663)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1663)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1663)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1663)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1663)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1663)\u001b[0m {'n_lags': 30, 'learning_rate': 0.04241521395689761, 'num_hidden_layers': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[36m(pid=1666)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1666)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1666)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1666)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1666)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1666)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1666)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1666)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1666)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1666)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1666)\u001b[0m 1 | ar_net        | ModuleList    | 1.1 K \n",
      "\u001b[2m\u001b[36m(pid=1666)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1666)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1666)\u001b[0m 1.1 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1666)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1666)\u001b[0m 1.1 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1666)\u001b[0m 0.004     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1666)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1666)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1666)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1666)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1666)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1666)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1666)\u001b[0m {'n_lags': 10, 'learning_rate': 0.03691439572227498, 'num_hidden_layers': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=1669)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1669)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1669)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1669)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1669)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1669)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1669)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1669)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1669)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1669)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1669)\u001b[0m 1 | ar_net        | ModuleList    | 3.7 K \n",
      "\u001b[2m\u001b[36m(pid=1669)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1669)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1669)\u001b[0m 3.7 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1669)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1669)\u001b[0m 3.7 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1669)\u001b[0m 0.015     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1669)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1669)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1669)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1669)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1669)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1669)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1669)\u001b[0m {'n_lags': 20, 'learning_rate': 0.06483226368499202, 'num_hidden_layers': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[36m(pid=1672)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1672)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1672)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1672)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1672)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1672)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1672)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1672)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1672)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1672)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1672)\u001b[0m 1 | ar_net        | ModuleList    | 2.0 K \n",
      "\u001b[2m\u001b[36m(pid=1672)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1672)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1672)\u001b[0m 2.0 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1672)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1672)\u001b[0m 2.0 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1672)\u001b[0m 0.008     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1672)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1672)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1672)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1672)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1672)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1672)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1672)\u001b[0m {'n_lags': 30, 'learning_rate': 0.09713657341523375, 'num_hidden_layers': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "2021-05-11 00:25:56,507\tWARNING util.py:162 -- The `start_trial` operation took 1.034 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=1675)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1675)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1675)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1675)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1675)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1675)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1675)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1675)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1675)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1675)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1675)\u001b[0m 1 | ar_net        | ModuleList    | 1.1 K \n",
      "\u001b[2m\u001b[36m(pid=1675)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1675)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1675)\u001b[0m 1.1 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1675)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1675)\u001b[0m 1.1 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1675)\u001b[0m 0.004     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1675)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1675)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1675)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1675)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1675)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1675)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1675)\u001b[0m {'n_lags': 10, 'learning_rate': 0.00012225972870417005, 'num_hidden_layers': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=1678)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1678)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1678)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1678)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1678)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1678)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1678)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1678)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1678)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1678)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1678)\u001b[0m 1 | ar_net        | ModuleList    | 7.4 K \n",
      "\u001b[2m\u001b[36m(pid=1678)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1678)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1678)\u001b[0m 7.4 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1678)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1678)\u001b[0m 7.4 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1678)\u001b[0m 0.030     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1678)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1678)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1678)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1678)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1678)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1678)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1678)\u001b[0m {'n_lags': 20, 'learning_rate': 0.001761777947113103, 'num_hidden_layers': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=1681)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1681)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1681)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1681)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1681)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1681)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1681)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1681)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1681)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1681)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1681)\u001b[0m 1 | ar_net        | ModuleList    | 15.9 K\n",
      "\u001b[2m\u001b[36m(pid=1681)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1681)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1681)\u001b[0m 15.9 K    Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1681)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1681)\u001b[0m 15.9 K    Total params\n",
      "\u001b[2m\u001b[36m(pid=1681)\u001b[0m 0.064     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1681)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1681)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1681)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1681)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1681)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1681)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1681)\u001b[0m {'n_lags': 30, 'learning_rate': 0.0050837015437768815, 'num_hidden_layers': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=1684)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1684)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1684)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1684)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1684)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1684)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1684)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1684)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1684)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1684)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1684)\u001b[0m 1 | ar_net        | ModuleList    | 1.1 K \n",
      "\u001b[2m\u001b[36m(pid=1684)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1684)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1684)\u001b[0m 1.1 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1684)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1684)\u001b[0m 1.1 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1684)\u001b[0m 0.004     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1684)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1684)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1684)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1684)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1684)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1684)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1684)\u001b[0m {'n_lags': 10, 'learning_rate': 0.003353583964608262, 'num_hidden_layers': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=1687)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1687)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1687)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1687)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1687)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1687)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1687)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1687)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1687)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1687)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1687)\u001b[0m 1 | ar_net        | ModuleList    | 924   \n",
      "\u001b[2m\u001b[36m(pid=1687)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1687)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1687)\u001b[0m 955       Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1687)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1687)\u001b[0m 955       Total params\n",
      "\u001b[2m\u001b[36m(pid=1687)\u001b[0m 0.004     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1687)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1687)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1687)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1687)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1687)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1687)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1687)\u001b[0m {'n_lags': 20, 'learning_rate': 0.00023651654629532675, 'num_hidden_layers': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[36m(pid=1691)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1691)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1691)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1691)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1691)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1691)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1691)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1691)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1691)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1691)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1691)\u001b[0m 1 | ar_net        | ModuleList    | 15.9 K\n",
      "\u001b[2m\u001b[36m(pid=1691)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1691)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1691)\u001b[0m 15.9 K    Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1691)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1691)\u001b[0m 15.9 K    Total params\n",
      "\u001b[2m\u001b[36m(pid=1691)\u001b[0m 0.064     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1691)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1691)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1691)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1691)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1691)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1691)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1691)\u001b[0m {'n_lags': 30, 'learning_rate': 0.00011544538110670798, 'num_hidden_layers': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[36m(pid=1694)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1694)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1694)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1694)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1694)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1694)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1694)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1694)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1694)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1694)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1694)\u001b[0m 1 | ar_net        | ModuleList    | 264   \n",
      "\u001b[2m\u001b[36m(pid=1694)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1694)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1694)\u001b[0m 295       Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1694)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1694)\u001b[0m 295       Total params\n",
      "\u001b[2m\u001b[36m(pid=1694)\u001b[0m 0.001     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1694)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1694)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1694)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1694)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1694)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1694)\u001b[0m \n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1694)\u001b[0m {'n_lags': 10, 'learning_rate': 0.01413295608128677, 'num_hidden_layers': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "2021-05-11 00:27:02,270\tWARNING util.py:162 -- The `start_trial` operation took 1.031 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(pid=1697)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1697)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1697)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1697)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1697)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1697)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1697)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1697)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1697)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1697)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1697)\u001b[0m 1 | ar_net        | ModuleList    | 7.4 K \n",
      "\u001b[2m\u001b[36m(pid=1697)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1697)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1697)\u001b[0m 7.4 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1697)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1697)\u001b[0m 7.4 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1697)\u001b[0m 0.030     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1697)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1697)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1697)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1697)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1697)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1697)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1697)\u001b[0m {'n_lags': 20, 'learning_rate': 0.0002726259415445239, 'num_hidden_layers': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[36m(pid=1700)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1703)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1703)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1703)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "\u001b[2m\u001b[36m(pid=1700)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1700)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1703)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1703)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1703)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1703)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1703)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1703)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1703)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1703)\u001b[0m 1 | ar_net        | ModuleList    | 1.1 K \n",
      "\u001b[2m\u001b[36m(pid=1703)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1703)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1703)\u001b[0m 1.1 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1703)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1703)\u001b[0m 1.1 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1703)\u001b[0m 0.004     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1703)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1703)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1703)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1703)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1703)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1703)\u001b[0m \n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1700)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1700)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1700)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1700)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1700)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1700)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1700)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1700)\u001b[0m 1 | ar_net        | ModuleList    | 15.9 K\n",
      "\u001b[2m\u001b[36m(pid=1700)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1700)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1700)\u001b[0m 15.9 K    Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1700)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1700)\u001b[0m 15.9 K    Total params\n",
      "\u001b[2m\u001b[36m(pid=1700)\u001b[0m 0.064     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1700)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1700)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1700)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1700)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1700)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1700)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1703)\u001b[0m {'n_lags': 10, 'learning_rate': 0.00015206244541322923, 'num_hidden_layers': 8}\n",
      "\u001b[2m\u001b[36m(pid=1700)\u001b[0m {'n_lags': 30, 'learning_rate': 0.0981903400015617, 'num_hidden_layers': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=1711)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1711)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1711)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1711)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1711)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1711)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1711)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1711)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1711)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1711)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1711)\u001b[0m 1 | ar_net        | ModuleList    | 3.7 K \n",
      "\u001b[2m\u001b[36m(pid=1711)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1711)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1711)\u001b[0m 3.7 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1711)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1711)\u001b[0m 3.7 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1711)\u001b[0m 0.015     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1711)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1711)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1711)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1711)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1711)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1711)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1711)\u001b[0m {'n_lags': 20, 'learning_rate': 0.00015428356185342694, 'num_hidden_layers': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "2021-05-11 00:27:22,977\tWARNING util.py:162 -- The `start_trial` operation took 1.025 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(pid=1714)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1714)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1714)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1714)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1714)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1714)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1714)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1714)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1714)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1714)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1714)\u001b[0m 1 | ar_net        | ModuleList    | 15.9 K\n",
      "\u001b[2m\u001b[36m(pid=1714)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1714)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1714)\u001b[0m 15.9 K    Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1714)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1714)\u001b[0m 15.9 K    Total params\n",
      "\u001b[2m\u001b[36m(pid=1714)\u001b[0m 0.064     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1714)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1714)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1714)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1714)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1714)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1714)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1714)\u001b[0m {'n_lags': 30, 'learning_rate': 0.005222360657850001, 'num_hidden_layers': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=1717)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1717)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1717)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1717)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1717)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1717)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1717)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1717)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1717)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1717)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1717)\u001b[0m 1 | ar_net        | ModuleList    | 264   \n",
      "\u001b[2m\u001b[36m(pid=1717)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1717)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1717)\u001b[0m 295       Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1717)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1717)\u001b[0m 295       Total params\n",
      "\u001b[2m\u001b[36m(pid=1717)\u001b[0m 0.001     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1717)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1717)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1717)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1717)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1717)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1717)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1717)\u001b[0m {'n_lags': 10, 'learning_rate': 0.034903049504134226, 'num_hidden_layers': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[36m(pid=1720)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1720)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1720)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1720)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1720)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1720)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1720)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1720)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1720)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1720)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1720)\u001b[0m 1 | ar_net        | ModuleList    | 7.4 K \n",
      "\u001b[2m\u001b[36m(pid=1720)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1720)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1720)\u001b[0m 7.4 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1720)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1720)\u001b[0m 7.4 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1720)\u001b[0m 0.030     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1720)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1720)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1720)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1720)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1720)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1720)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1720)\u001b[0m {'n_lags': 20, 'learning_rate': 0.005398859738994553, 'num_hidden_layers': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=1723)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1723)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1723)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1723)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1723)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1723)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1723)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1723)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1723)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1723)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1723)\u001b[0m 1 | ar_net        | ModuleList    | 15.9 K\n",
      "\u001b[2m\u001b[36m(pid=1723)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1723)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1723)\u001b[0m 15.9 K    Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1723)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1723)\u001b[0m 15.9 K    Total params\n",
      "\u001b[2m\u001b[36m(pid=1723)\u001b[0m 0.064     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1723)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1723)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1723)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1723)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1723)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1723)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1723)\u001b[0m {'n_lags': 30, 'learning_rate': 0.0023791029715434188, 'num_hidden_layers': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "2021-05-11 00:27:33,321\tWARNING worker.py:1115 -- The actor or task with ID ffffffffffffffff5be8e3b82063723da83f2b4c01000000 cannot be scheduled right now. It requires {CPU_group_913787f027b274887b580ae07bd6c596: 1.000000}, {CPU_group_0_913787f027b274887b580ae07bd6c596: 1.000000} for placement, but this node only has remaining {0.000000/8.000000 CPU, 8.406821 GiB/8.406821 GiB memory, 4.203410 GiB/4.203410 GiB object_store_memory, 0.000000/1.000000 CPU_group_cf0cadf206893896133985bd9f1d3727, 0.000000/1.000000 CPU_group_0_4d0acaa788fcfbb91ab146a6746fdb55, 0.000000/1.000000 CPU_group_ee12a2a881b65640e208f205132de7bf, 1.000000/1.000000 CPU_group_0_913787f027b274887b580ae07bd6c596, 0.000000/1.000000 CPU_group_0_1fa184229c97933a04afc0f9957b6b48, 1.000000/1.000000 node:192.168.0.7, 0.000000/1.000000 CPU_group_0_ee12a2a881b65640e208f205132de7bf, 0.000000/1.000000 CPU_group_0_e7f188bb8ad51715aa114289edbc3c39, 0.000000/1.000000 CPU_group_0_cf8228709927a6bfc9962dcf23636cf0, 0.000000/1.000000 CPU_group_4d0acaa788fcfbb91ab146a6746fdb55, 0.000000/1.000000 CPU_group_e7f188bb8ad51715aa114289edbc3c39, 0.000000/1.000000 CPU_group_cf8228709927a6bfc9962dcf23636cf0, 0.000000/1.000000 CPU_group_81ca0b795ed8570310bc6ac096285688, 0.000000/1.000000 CPU_group_0_cf0cadf206893896133985bd9f1d3727, 0.000000/1.000000 CPU_group_0_81ca0b795ed8570310bc6ac096285688, 1.000000/1.000000 CPU_group_913787f027b274887b580ae07bd6c596, 0.000000/1.000000 CPU_group_1fa184229c97933a04afc0f9957b6b48}\n",
      ". In total there are 0 pending tasks and 1 pending actors on this node. This is likely due to all cluster resources being claimed by actors. To resolve the issue, consider creating fewer actors or increase the resources available to this Ray cluster. You can ignore this message if this Ray cluster is expected to auto-scale.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=1726)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1726)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1726)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1726)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1726)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1726)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1726)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1726)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1726)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1726)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1726)\u001b[0m 1 | ar_net        | ModuleList    | 264   \n",
      "\u001b[2m\u001b[36m(pid=1726)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1726)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1726)\u001b[0m 295       Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1726)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1726)\u001b[0m 295       Total params\n",
      "\u001b[2m\u001b[36m(pid=1726)\u001b[0m 0.001     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1726)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1726)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1726)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1726)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1726)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1726)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1726)\u001b[0m {'n_lags': 10, 'learning_rate': 0.0010005397230672265, 'num_hidden_layers': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=1733)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1733)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1733)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1733)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1733)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1733)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1733)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1733)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1733)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1733)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1733)\u001b[0m 1 | ar_net        | ModuleList    | 7.4 K \n",
      "\u001b[2m\u001b[36m(pid=1733)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1733)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1733)\u001b[0m 7.4 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1733)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1733)\u001b[0m 7.4 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1733)\u001b[0m 0.030     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1733)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1733)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1733)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1733)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1733)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1733)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1733)\u001b[0m {'n_lags': 20, 'learning_rate': 0.0021176053683673937, 'num_hidden_layers': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=1736)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1736)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1736)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1736)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1736)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1736)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1736)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1736)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1736)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1736)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1736)\u001b[0m 1 | ar_net        | ModuleList    | 15.9 K\n",
      "\u001b[2m\u001b[36m(pid=1736)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1736)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1736)\u001b[0m 15.9 K    Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1736)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1736)\u001b[0m 15.9 K    Total params\n",
      "\u001b[2m\u001b[36m(pid=1736)\u001b[0m 0.064     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1736)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1736)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1736)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1736)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1736)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1736)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1736)\u001b[0m {'n_lags': 30, 'learning_rate': 0.01647088062064403, 'num_hidden_layers': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=1743)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1743)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1743)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1743)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1743)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1743)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1743)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1743)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1743)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1743)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1743)\u001b[0m 1 | ar_net        | ModuleList    | 7.4 K \n",
      "\u001b[2m\u001b[36m(pid=1743)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1743)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1743)\u001b[0m 7.4 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1743)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1743)\u001b[0m 7.4 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1743)\u001b[0m 0.030     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1743)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1743)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1743)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1743)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1743)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1743)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1748)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1748)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1748)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1743)\u001b[0m {'n_lags': 20, 'learning_rate': 0.0006856005968814729, 'num_hidden_layers': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1748)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1748)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1748)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1748)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1748)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1748)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1748)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1748)\u001b[0m 1 | ar_net        | ModuleList    | 1.1 K \n",
      "\u001b[2m\u001b[36m(pid=1748)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1748)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1748)\u001b[0m 1.1 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1748)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1748)\u001b[0m 1.1 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1748)\u001b[0m 0.004     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1748)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1748)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1748)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1748)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1748)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1748)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1748)\u001b[0m {'n_lags': 10, 'learning_rate': 0.0026654668677205916, 'num_hidden_layers': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[36m(pid=1755)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1755)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1755)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1755)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1755)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1755)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1755)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1755)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1755)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1755)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1755)\u001b[0m 1 | ar_net        | ModuleList    | 7.9 K \n",
      "\u001b[2m\u001b[36m(pid=1755)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1755)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1755)\u001b[0m 8.0 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1755)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1755)\u001b[0m 8.0 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1755)\u001b[0m 0.032     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1755)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1755)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1755)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1755)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1755)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1755)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1755)\u001b[0m {'n_lags': 30, 'learning_rate': 0.00010239614745905216, 'num_hidden_layers': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "2021-05-11 00:28:20,189\tWARNING util.py:162 -- The `start_trial` operation took 1.023 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=1760)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1760)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1760)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1760)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1760)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1760)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1760)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1760)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1760)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1760)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1760)\u001b[0m 1 | ar_net        | ModuleList    | 1.1 K \n",
      "\u001b[2m\u001b[36m(pid=1760)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1760)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1760)\u001b[0m 1.1 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1760)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1760)\u001b[0m 1.1 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1760)\u001b[0m 0.004     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1760)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1760)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1760)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1760)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1760)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1760)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1760)\u001b[0m {'n_lags': 10, 'learning_rate': 0.0005476367531771077, 'num_hidden_layers': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[36m(pid=1763)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1763)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1763)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1763)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1763)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1763)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1763)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1763)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1763)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1763)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1763)\u001b[0m 1 | ar_net        | ModuleList    | 7.9 K \n",
      "\u001b[2m\u001b[36m(pid=1763)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1763)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1763)\u001b[0m 8.0 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1763)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1763)\u001b[0m 8.0 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1763)\u001b[0m 0.032     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1763)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1763)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1763)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1763)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1763)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1763)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1766)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1766)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1766)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1763)\u001b[0m {'n_lags': 30, 'learning_rate': 0.0002384645526381408, 'num_hidden_layers': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1766)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1766)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1766)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1766)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1766)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1766)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1766)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1766)\u001b[0m 1 | ar_net        | ModuleList    | 7.4 K \n",
      "\u001b[2m\u001b[36m(pid=1766)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1766)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1766)\u001b[0m 7.4 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1766)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1766)\u001b[0m 7.4 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1766)\u001b[0m 0.030     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1766)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1766)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1766)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1766)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1766)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1766)\u001b[0m \n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1766)\u001b[0m {'n_lags': 20, 'learning_rate': 0.00036595805240613563, 'num_hidden_layers': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=1781)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1781)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1781)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1781)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1781)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1781)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1781)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1781)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1781)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1781)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1781)\u001b[0m 1 | ar_net        | ModuleList    | 1.1 K \n",
      "\u001b[2m\u001b[36m(pid=1781)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1781)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1781)\u001b[0m 1.1 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1781)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1781)\u001b[0m 1.1 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1781)\u001b[0m 0.004     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1781)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1781)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1781)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1781)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1781)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1781)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1781)\u001b[0m {'n_lags': 10, 'learning_rate': 0.06614176109957487, 'num_hidden_layers': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[36m(pid=1784)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1784)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1784)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1784)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1784)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1784)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1784)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1784)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1784)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1784)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1784)\u001b[0m 1 | ar_net        | ModuleList    | 7.4 K \n",
      "\u001b[2m\u001b[36m(pid=1784)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1784)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1784)\u001b[0m 7.4 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1784)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1784)\u001b[0m 7.4 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1784)\u001b[0m 0.030     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1784)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1784)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1784)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1784)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1784)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1784)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1784)\u001b[0m {'n_lags': 20, 'learning_rate': 0.00022418192183492564, 'num_hidden_layers': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
      "\u001b[2m\u001b[36m(pid=1790)\u001b[0m INFO - (NP.forecaster._handle_missing_data) - 12 NaN values in column y were auto-imputed.\n",
      "\u001b[2m\u001b[36m(pid=1790)\u001b[0m INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "\u001b[2m\u001b[36m(pid=1790)\u001b[0m INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1790)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1790)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(pid=1790)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=1790)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1790)\u001b[0m   | Name          | Type          | Params\n",
      "\u001b[2m\u001b[36m(pid=1790)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1790)\u001b[0m 0 | season_params | ParameterDict | 18    \n",
      "\u001b[2m\u001b[36m(pid=1790)\u001b[0m 1 | ar_net        | ModuleList    | 7.9 K \n",
      "\u001b[2m\u001b[36m(pid=1790)\u001b[0m 2 | loss_func     | SmoothL1Loss  | 0     \n",
      "\u001b[2m\u001b[36m(pid=1790)\u001b[0m ------------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=1790)\u001b[0m 8.0 K     Trainable params\n",
      "\u001b[2m\u001b[36m(pid=1790)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(pid=1790)\u001b[0m 8.0 K     Total params\n",
      "\u001b[2m\u001b[36m(pid=1790)\u001b[0m 0.032     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(pid=1790)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1790)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1790)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1790)\u001b[0m WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\u001b[2m\u001b[36m(pid=1790)\u001b[0m   warnings.warn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1790)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1790)\u001b[0m {'n_lags': 30, 'learning_rate': 0.005619434333669411, 'num_hidden_layers': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "freq = '5min'\n",
    "best_params, results_df = tune_hyperparameters('NP', \n",
    "                                               df,\n",
    "                                               freq, \n",
    "                                               mode = 'manual',\n",
    "                                              config = config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>time_this_iter_s</th>\n",
       "      <th>done</th>\n",
       "      <th>timesteps_total</th>\n",
       "      <th>episodes_total</th>\n",
       "      <th>training_iteration</th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>date</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>time_total_s</th>\n",
       "      <th>pid</th>\n",
       "      <th>hostname</th>\n",
       "      <th>node_ip</th>\n",
       "      <th>time_since_restore</th>\n",
       "      <th>timesteps_since_restore</th>\n",
       "      <th>iterations_since_restore</th>\n",
       "      <th>experiment_tag</th>\n",
       "      <th>config.n_lags</th>\n",
       "      <th>config.learning_rate</th>\n",
       "      <th>config.num_hidden_layers</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trial_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>b82cf_00000</th>\n",
       "      <td>1.084538</td>\n",
       "      <td>1.495492</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>fe661eab9cdb4fbf9eb0e7b57f0ae02a</td>\n",
       "      <td>2021-05-11_00-14-56</td>\n",
       "      <td>1620681296</td>\n",
       "      <td>18.115594</td>\n",
       "      <td>1261</td>\n",
       "      <td>MacBook-Pro-Polina.local</td>\n",
       "      <td>192.168.0.7</td>\n",
       "      <td>18.115594</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0_learning_rate=0.00015557,n_lags=10,num_hidde...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b82cf_00001</th>\n",
       "      <td>0.579620</td>\n",
       "      <td>1.627965</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>2611934321574e2ea23e7ccf6ac19e3c</td>\n",
       "      <td>2021-05-11_00-14-56</td>\n",
       "      <td>1620681296</td>\n",
       "      <td>17.901918</td>\n",
       "      <td>1263</td>\n",
       "      <td>MacBook-Pro-Polina.local</td>\n",
       "      <td>192.168.0.7</td>\n",
       "      <td>17.901918</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1_learning_rate=0.0017272,n_lags=20,num_hidden...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.001727</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b82cf_00002</th>\n",
       "      <td>0.000066</td>\n",
       "      <td>1.588995</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>49432d66f8a748eb8105909f268b6657</td>\n",
       "      <td>2021-05-11_00-16-56</td>\n",
       "      <td>1620681416</td>\n",
       "      <td>137.877947</td>\n",
       "      <td>1267</td>\n",
       "      <td>MacBook-Pro-Polina.local</td>\n",
       "      <td>192.168.0.7</td>\n",
       "      <td>137.877947</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>2_learning_rate=0.012421,n_lags=30,num_hidden_...</td>\n",
       "      <td>30</td>\n",
       "      <td>0.012421</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b82cf_00003</th>\n",
       "      <td>0.000032</td>\n",
       "      <td>2.032028</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>bde5cd3ed5df4f2fab4abfb03e97253f</td>\n",
       "      <td>2021-05-11_00-18-15</td>\n",
       "      <td>1620681495</td>\n",
       "      <td>217.408729</td>\n",
       "      <td>1262</td>\n",
       "      <td>MacBook-Pro-Polina.local</td>\n",
       "      <td>192.168.0.7</td>\n",
       "      <td>217.408729</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>3_learning_rate=0.04564,n_lags=10,num_hidden_l...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.045640</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b82cf_00004</th>\n",
       "      <td>0.429556</td>\n",
       "      <td>1.509781</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>4582d742f14846e99003f8a7596e9083</td>\n",
       "      <td>2021-05-11_00-16-53</td>\n",
       "      <td>1620681413</td>\n",
       "      <td>135.652835</td>\n",
       "      <td>1265</td>\n",
       "      <td>MacBook-Pro-Polina.local</td>\n",
       "      <td>192.168.0.7</td>\n",
       "      <td>135.652835</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>4_learning_rate=0.00097977,n_lags=20,num_hidde...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.000980</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b82cf_00115</th>\n",
       "      <td>0.780160</td>\n",
       "      <td>1.263130</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>e97b876c9c4d453dbc89468805ca85f6</td>\n",
       "      <td>2021-05-11_00-28-46</td>\n",
       "      <td>1620682126</td>\n",
       "      <td>22.238568</td>\n",
       "      <td>1766</td>\n",
       "      <td>MacBook-Pro-Polina.local</td>\n",
       "      <td>192.168.0.7</td>\n",
       "      <td>22.238568</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>115_learning_rate=0.00036596,n_lags=20,num_hid...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b82cf_00116</th>\n",
       "      <td>1.139772</td>\n",
       "      <td>1.367162</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>53c142b7b9d64296b223b82346c6d1f2</td>\n",
       "      <td>2021-05-11_00-28-44</td>\n",
       "      <td>1620682124</td>\n",
       "      <td>20.402098</td>\n",
       "      <td>1763</td>\n",
       "      <td>MacBook-Pro-Polina.local</td>\n",
       "      <td>192.168.0.7</td>\n",
       "      <td>20.402098</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>116_learning_rate=0.00023846,n_lags=30,num_hid...</td>\n",
       "      <td>30</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b82cf_00117</th>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.826584</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>40</td>\n",
       "      <td>8f34ca39e1f54677a6a2e6def368414f</td>\n",
       "      <td>2021-05-11_00-29-16</td>\n",
       "      <td>1620682156</td>\n",
       "      <td>38.893304</td>\n",
       "      <td>1781</td>\n",
       "      <td>MacBook-Pro-Polina.local</td>\n",
       "      <td>192.168.0.7</td>\n",
       "      <td>38.893304</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>117_learning_rate=0.066142,n_lags=10,num_hidde...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.066142</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b82cf_00118</th>\n",
       "      <td>1.040041</td>\n",
       "      <td>1.207639</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>b98e127be6a44ff1a69fe649a6dbec1f</td>\n",
       "      <td>2021-05-11_00-28-54</td>\n",
       "      <td>1620682134</td>\n",
       "      <td>14.523638</td>\n",
       "      <td>1784</td>\n",
       "      <td>MacBook-Pro-Polina.local</td>\n",
       "      <td>192.168.0.7</td>\n",
       "      <td>14.523638</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>118_learning_rate=0.00022418,n_lags=20,num_hid...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b82cf_00119</th>\n",
       "      <td>0.330736</td>\n",
       "      <td>0.939161</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>d5c5b1ecb5424d528cca87d98d3d19f3</td>\n",
       "      <td>2021-05-11_00-29-03</td>\n",
       "      <td>1620682143</td>\n",
       "      <td>19.942769</td>\n",
       "      <td>1790</td>\n",
       "      <td>MacBook-Pro-Polina.local</td>\n",
       "      <td>192.168.0.7</td>\n",
       "      <td>19.942769</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>119_learning_rate=0.0056194,n_lags=30,num_hidd...</td>\n",
       "      <td>30</td>\n",
       "      <td>0.005619</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 loss  time_this_iter_s  done timesteps_total episodes_total  \\\n",
       "trial_id                                                                       \n",
       "b82cf_00000  1.084538          1.495492  True            None           None   \n",
       "b82cf_00001  0.579620          1.627965  True            None           None   \n",
       "b82cf_00002  0.000066          1.588995  True            None           None   \n",
       "b82cf_00003  0.000032          2.032028  True            None           None   \n",
       "b82cf_00004  0.429556          1.509781  True            None           None   \n",
       "...               ...               ...   ...             ...            ...   \n",
       "b82cf_00115  0.780160          1.263130  True            None           None   \n",
       "b82cf_00116  1.139772          1.367162  True            None           None   \n",
       "b82cf_00117  0.000299          0.826584  True            None           None   \n",
       "b82cf_00118  1.040041          1.207639  True            None           None   \n",
       "b82cf_00119  0.330736          0.939161  True            None           None   \n",
       "\n",
       "             training_iteration                     experiment_id  \\\n",
       "trial_id                                                            \n",
       "b82cf_00000                  10  fe661eab9cdb4fbf9eb0e7b57f0ae02a   \n",
       "b82cf_00001                  10  2611934321574e2ea23e7ccf6ac19e3c   \n",
       "b82cf_00002                 100  49432d66f8a748eb8105909f268b6657   \n",
       "b82cf_00003                 100  bde5cd3ed5df4f2fab4abfb03e97253f   \n",
       "b82cf_00004                 100  4582d742f14846e99003f8a7596e9083   \n",
       "...                         ...                               ...   \n",
       "b82cf_00115                  10  e97b876c9c4d453dbc89468805ca85f6   \n",
       "b82cf_00116                  10  53c142b7b9d64296b223b82346c6d1f2   \n",
       "b82cf_00117                  40  8f34ca39e1f54677a6a2e6def368414f   \n",
       "b82cf_00118                  10  b98e127be6a44ff1a69fe649a6dbec1f   \n",
       "b82cf_00119                  20  d5c5b1ecb5424d528cca87d98d3d19f3   \n",
       "\n",
       "                            date   timestamp  time_total_s   pid  \\\n",
       "trial_id                                                           \n",
       "b82cf_00000  2021-05-11_00-14-56  1620681296     18.115594  1261   \n",
       "b82cf_00001  2021-05-11_00-14-56  1620681296     17.901918  1263   \n",
       "b82cf_00002  2021-05-11_00-16-56  1620681416    137.877947  1267   \n",
       "b82cf_00003  2021-05-11_00-18-15  1620681495    217.408729  1262   \n",
       "b82cf_00004  2021-05-11_00-16-53  1620681413    135.652835  1265   \n",
       "...                          ...         ...           ...   ...   \n",
       "b82cf_00115  2021-05-11_00-28-46  1620682126     22.238568  1766   \n",
       "b82cf_00116  2021-05-11_00-28-44  1620682124     20.402098  1763   \n",
       "b82cf_00117  2021-05-11_00-29-16  1620682156     38.893304  1781   \n",
       "b82cf_00118  2021-05-11_00-28-54  1620682134     14.523638  1784   \n",
       "b82cf_00119  2021-05-11_00-29-03  1620682143     19.942769  1790   \n",
       "\n",
       "                             hostname      node_ip  time_since_restore  \\\n",
       "trial_id                                                                 \n",
       "b82cf_00000  MacBook-Pro-Polina.local  192.168.0.7           18.115594   \n",
       "b82cf_00001  MacBook-Pro-Polina.local  192.168.0.7           17.901918   \n",
       "b82cf_00002  MacBook-Pro-Polina.local  192.168.0.7          137.877947   \n",
       "b82cf_00003  MacBook-Pro-Polina.local  192.168.0.7          217.408729   \n",
       "b82cf_00004  MacBook-Pro-Polina.local  192.168.0.7          135.652835   \n",
       "...                               ...          ...                 ...   \n",
       "b82cf_00115  MacBook-Pro-Polina.local  192.168.0.7           22.238568   \n",
       "b82cf_00116  MacBook-Pro-Polina.local  192.168.0.7           20.402098   \n",
       "b82cf_00117  MacBook-Pro-Polina.local  192.168.0.7           38.893304   \n",
       "b82cf_00118  MacBook-Pro-Polina.local  192.168.0.7           14.523638   \n",
       "b82cf_00119  MacBook-Pro-Polina.local  192.168.0.7           19.942769   \n",
       "\n",
       "             timesteps_since_restore  iterations_since_restore  \\\n",
       "trial_id                                                         \n",
       "b82cf_00000                        0                        10   \n",
       "b82cf_00001                        0                        10   \n",
       "b82cf_00002                        0                       100   \n",
       "b82cf_00003                        0                       100   \n",
       "b82cf_00004                        0                       100   \n",
       "...                              ...                       ...   \n",
       "b82cf_00115                        0                        10   \n",
       "b82cf_00116                        0                        10   \n",
       "b82cf_00117                        0                        40   \n",
       "b82cf_00118                        0                        10   \n",
       "b82cf_00119                        0                        20   \n",
       "\n",
       "                                                experiment_tag  config.n_lags  \\\n",
       "trial_id                                                                        \n",
       "b82cf_00000  0_learning_rate=0.00015557,n_lags=10,num_hidde...             10   \n",
       "b82cf_00001  1_learning_rate=0.0017272,n_lags=20,num_hidden...             20   \n",
       "b82cf_00002  2_learning_rate=0.012421,n_lags=30,num_hidden_...             30   \n",
       "b82cf_00003  3_learning_rate=0.04564,n_lags=10,num_hidden_l...             10   \n",
       "b82cf_00004  4_learning_rate=0.00097977,n_lags=20,num_hidde...             20   \n",
       "...                                                        ...            ...   \n",
       "b82cf_00115  115_learning_rate=0.00036596,n_lags=20,num_hid...             20   \n",
       "b82cf_00116  116_learning_rate=0.00023846,n_lags=30,num_hid...             30   \n",
       "b82cf_00117  117_learning_rate=0.066142,n_lags=10,num_hidde...             10   \n",
       "b82cf_00118  118_learning_rate=0.00022418,n_lags=20,num_hid...             20   \n",
       "b82cf_00119  119_learning_rate=0.0056194,n_lags=30,num_hidd...             30   \n",
       "\n",
       "             config.learning_rate  config.num_hidden_layers  \n",
       "trial_id                                                     \n",
       "b82cf_00000              0.000156                         8  \n",
       "b82cf_00001              0.001727                         8  \n",
       "b82cf_00002              0.012421                         2  \n",
       "b82cf_00003              0.045640                        16  \n",
       "b82cf_00004              0.000980                         2  \n",
       "...                           ...                       ...  \n",
       "b82cf_00115              0.000366                        16  \n",
       "b82cf_00116              0.000238                         8  \n",
       "b82cf_00117              0.066142                         8  \n",
       "b82cf_00118              0.000224                        16  \n",
       "b82cf_00119              0.005619                         8  \n",
       "\n",
       "[120 rows x 20 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_lags': 10, 'learning_rate': 0.05765758454779955, 'num_hidden_layers': 8}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
